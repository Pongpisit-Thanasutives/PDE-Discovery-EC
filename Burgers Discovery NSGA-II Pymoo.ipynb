{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8401bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from functools import partial\n",
    "from decimal import Decimal\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import pysindy as ps\n",
    "from tqdm import trange\n",
    "\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.algorithms.moo.dnsga2 import DNSGA2\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from pymoo.core.sampling import Sampling\n",
    "from pymoo.core.crossover import Crossover\n",
    "from pymoo.core.mutation import Mutation\n",
    "from pymoo.core.duplicate import ElementwiseDuplicateElimination\n",
    "from pymoo.termination.default import DefaultMultiObjectiveTermination\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.visualization.scatter import Scatter\n",
    "from pymoo.core.problem import StarmapParallelization\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "from utils import *\n",
    "from skimage.restoration import estimate_sigma\n",
    "import bm3d\n",
    "from okridge.solvel0 import *\n",
    "from solvel0 import solvel0\n",
    "from best_subset import backward_refinement, brute_force_all_subsets\n",
    "from UBIC import *\n",
    "from kneed import KneeLocator\n",
    "from bayesian_model_evidence import log_evidence\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5916f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_poly = 6\n",
    "n_derivatives = 6\n",
    "n_modules = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eaa96d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../PDE-Discovery-EC/Datasets/\"\n",
    "data = sio.loadmat(os.path.join(data_path, \"burgers.mat\"))\n",
    "u_clean = (data['usol']).real; u = u_clean.copy()\n",
    "x = (data['x'][0]).real\n",
    "t = (data['t'][:,0]).real\n",
    "dt = t[1]-t[0]; dx = x[2]-x[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1e0adc",
   "metadata": {},
   "source": [
    "### Add noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "888ee41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise level: 50.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "noise_type = \"gaussian\"\n",
    "noise_lv = float(50)\n",
    "print(\"Noise level:\", noise_lv)\n",
    "noise = 0.01*np.abs(noise_lv)*(u.std())*np.random.randn(u.shape[0],u.shape[1])\n",
    "u = u + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c890b0",
   "metadata": {},
   "source": [
    "### Denoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9754901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading denoised data...\n"
     ]
    }
   ],
   "source": [
    "load_denoised_data = True\n",
    "if load_denoised_data:\n",
    "    print(\"Loading denoised data...\")\n",
    "    u = np.load(f\"./Denoised_data/burgers_{noise_type}{int(noise_lv)}_bm3d.npy\")\n",
    "else:\n",
    "    kernel = RBF(length_scale=1, length_scale_bounds=(1e-2, 1e3)) + \\\n",
    "                    WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e10))\n",
    "    \n",
    "    xx = colvec(x)\n",
    "    u_mean = np.copy(u)\n",
    "    u_std = np.ones(u.shape)\n",
    "    for i in trange(len(t)):    \n",
    "        gpr = GaussianProcessRegressor(kernel=kernel, alpha=0.0, \n",
    "                                       n_restarts_optimizer=10 # 20\n",
    "                                      )\n",
    "    \n",
    "        gpr.fit(xx, u_mean[:, i])\n",
    "        um, ustd = gpr.predict(xx, return_std=True)\n",
    "        u_mean[:, i] = um\n",
    "        u_std[:, i] = ustd\n",
    "    \n",
    "    est_sigma = u_std.mean() # max also works well\n",
    "    # est_sigma = (est_sigma+estimate_sigma(u))/2\n",
    "    u = bm3d.bm3d(u, sigma_psd=est_sigma, \n",
    "                  stage_arg=bm3d.BM3DStages.ALL_STAGES, \n",
    "                  blockmatches=(False, False))\n",
    "\n",
    "    np.save(f\"./Denoised_data/burgers_{noise_type}{int(noise_lv)}_bm3d.npy\", u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9921db4e-3de7-42e2-836a-64a85cea979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = np.array([x.reshape(-1, 1), t.reshape(1, -1)], dtype=object)\n",
    "X, T = np.meshgrid(x, t)\n",
    "XT = np.asarray([X, T]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aaf2666",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_library = ps.PolynomialLibrary(degree=n_poly, include_bias=False)\n",
    "\n",
    "weak_lib = ps.WeakPDELibrary(\n",
    "    function_library=function_library,\n",
    "    derivative_order=n_derivatives,\n",
    "    spatiotemporal_grid=XT,\n",
    "    include_bias=True,\n",
    "    diff_kwargs={\"is_uniform\":True},\n",
    "    K=10000\n",
    ")\n",
    "\n",
    "X_pre = np.array(weak_lib.fit_transform(np.expand_dims(u, -1)))\n",
    "y_pre = weak_lib.convert_u_dot_integral(np.expand_dims(u, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ad9a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_poly = np.array([[p, 0] for p in range(1, n_poly+1)])\n",
    "base_derivative = np.array([[0, d] for d in range(1, n_derivatives+1)])\n",
    "modules = [(0, 0)] if weak_lib.include_bias else []\n",
    "modules += [(p, 0) for p in range(1, n_poly+1)] + \\\n",
    "            [(0, d) for d in range(1, n_derivatives+1)] + \\\n",
    "            [tuple(p+d) for d in base_derivative for p in base_poly]\n",
    "assert len(modules) == len(weak_lib.get_feature_names())\n",
    "base_features = dict(zip(modules, X_pre.T))\n",
    "u_t = y_pre.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bede4c-0838-41ab-9dcb-629f03e4f564",
   "metadata": {},
   "source": [
    "### Straightforward best-subset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acf9148f-099b-4576-872a-50180f02dbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# over 30 minutes for n_poly = 6 and n_derivatives = 6\n",
    "# miosr_subsets = solvel0(X_pre, y_pre, miosr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edfd6955-926c-4674-ab94-4378b6c81e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tau = 3\n",
    "# verbose = True\n",
    "# # scale = 1 <- generalized UBIC\n",
    "# scale = np.log(len(y_pre))\n",
    "# per = 75 # 80\n",
    "\n",
    "# post_means, b_bics, b_uns = baye_uncertainties(miosr_subsets, (X_pre, y_pre), \n",
    "#                                                u_type='cv1', take_sqrt=True, \n",
    "#                                                ridge_lambda=0, \n",
    "#                                                threshold=0)\n",
    "# # b_uns = ard_uns # USE ard_uns INSTEAD\n",
    "# predictions = X_pre@post_means\n",
    "# print(b_bics)\n",
    "# print(b_uns)\n",
    "# b_bics = np.array(b_bics)\n",
    "# max_complexity = len(b_bics)\n",
    "# complexities = np.arange(max_complexity)+1\n",
    "# d_complexities = complexities[decreasing_values_indices(b_bics)]\n",
    "# d_bics = b_bics[decreasing_values_indices(b_bics)]\n",
    "# slopes = np.diff(b_bics)/(np.diff(complexities)*b_bics[:-1])\n",
    "# try:\n",
    "#     thres = np.percentile(np.abs(np.diff(d_bics)/(np.diff(d_complexities)*d_bics[:-1])), per)\n",
    "#     thres = math.ceil(sci_format(thres)[0])*10**sci_format(thres)[1]\n",
    "# except IndexError:\n",
    "#     thres = 1/40\n",
    "# min_thres = 1/40\n",
    "# thres = max(thres, min_thres)\n",
    "# print(\"threshold:\", thres)\n",
    "\n",
    "# lower_bounds = []\n",
    "# for k, efi in enumerate(miosr_subsets):\n",
    "#     # assert len(efi) == np.count_nonzero(post_means[:, k:k+1])\n",
    "#     com = len(efi)\n",
    "#     lower_bound = 2*np.abs(log_like_value(predictions[:, k:k+1], y_pre))-np.log(len(y_pre))*com\n",
    "#     lower_bounds.append(lower_bound)\n",
    "\n",
    "# last_lam = np.log10(max(lower_bounds/(b_uns*scale)))\n",
    "# print(\"max_lam:\", last_lam)\n",
    "# delta = last_lam/tau\n",
    "# now_lam = last_lam-delta\n",
    "# last_ubic = UBIC(b_bics, b_uns, len(y_pre), hyp=10**last_lam, scale=scale)\n",
    "# last_bc = np.argmin(last_ubic)\n",
    "# bc_seq = [last_bc]\n",
    "# while now_lam >= 0:\n",
    "#     now_ubic = UBIC(b_bics, b_uns, len(y_pre), hyp=10**now_lam, scale=scale)\n",
    "#     now_bc = np.argmin(now_ubic)\n",
    "    \n",
    "#     diff_com = now_bc-last_bc\n",
    "#     diff_bic = b_bics[now_bc]-b_bics[last_bc]\n",
    "#     imp = np.nan\n",
    "#     if diff_com != 0:\n",
    "#         imp = abs(diff_bic/(b_bics[last_bc]*diff_com))\n",
    "    \n",
    "#     if verbose:\n",
    "#         print(min(last_bc, now_bc), '<--->', max(last_bc, now_bc), \n",
    "#               np.nan_to_num(imp, nan=np.inf))\n",
    "    \n",
    "#     if (diff_com > 0 and (diff_bic > 0 or imp < thres)) or \\\n",
    "#         (diff_com < 0 and diff_bic > 0 and imp > thres):\n",
    "#         break\n",
    "    \n",
    "#     last_lam = now_lam\n",
    "#     now_lam = round(last_lam-delta, 8)\n",
    "#     last_ubic = now_ubic\n",
    "#     last_bc = now_bc\n",
    "#     if last_bc not in bc_seq:\n",
    "#         bc_seq.append(last_bc)\n",
    "\n",
    "# # best_bc = knee_finder(last_ubic)\n",
    "# best_bc = knee(range(len(last_ubic)), last_ubic, 'linear')\n",
    "# if best_bc == 0 and last_bc != 0 and abs((b_bics[last_bc]-b_bics[0])/(b_bics[0]*last_bc)) > thres:\n",
    "#     best_bc = knee(range(1, len(last_ubic)), last_ubic[1:], 'linear')\n",
    "\n",
    "# if best_bc is None:\n",
    "#     best_bc = last_bc\n",
    "#     alt_bc = bc_seq[-2] if len(bc_seq) > 1 else last_bc-10\n",
    "#     cond = abs((b_bics[last_bc]-b_bics[last_bc-1])/b_bics[last_bc-1]) or \\\n",
    "#             abs((b_bics[last_bc]-b_bics[alt_bc])/(b_bics[alt_bc]*(last_bc-alt_bc)))\n",
    "#     if cond < thres: \n",
    "#         best_bc = np.argmin(last_ubic[:alt_bc+1])\n",
    "    \n",
    "# last_lam = round(last_lam, 8)\n",
    "# print(last_lam, last_ubic, last_bc, best_bc)\n",
    "\n",
    "# plt.plot(last_ubic)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb73e146",
   "metadata": {},
   "source": [
    "### Genetic algorithm with NSGA-II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fa61c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PdeDiscoveryProblem(ElementwiseProblem):\n",
    "    def __init__(self, n_poly, n_derivatives, n_modules, \n",
    "                 base_features, u_t, order_complexity=False, **kwargs):\n",
    "        super().__init__(n_var=1, n_obj=2, n_ieq_constr=0, **kwargs)\n",
    "        self.n_poly = n_poly\n",
    "        self.n_derivatives = n_derivatives\n",
    "        self.n_modules = n_modules\n",
    "        self.base_features = base_features\n",
    "        self.u_t = u_t\n",
    "        self.sample_size = np.prod(self.u_t.shape)\n",
    "        self.order_complexity = order_complexity\n",
    "\n",
    "    def _evaluate(self, X, out, *args, **kwargs):\n",
    "        genome = X[0]\n",
    "        coeff, mse = self.compute_genome_coefficient(genome)\n",
    "        mse = mse/self.sample_size\n",
    "        complexity_penalty = len(genome)\n",
    "        if self.order_complexity:\n",
    "            complexity_penalty += sum(sum(_) for _ in genome)\n",
    "        out[\"F\"] = [mse, complexity_penalty]\n",
    "        \n",
    "    def numericalize_genome(self, genome):\n",
    "        return np.stack([self.base_features[tuple(module)] \n",
    "                         for module in genome], axis=-1)\n",
    "\n",
    "    def compute_genome_coefficient(self, genome):\n",
    "        features = self.numericalize_genome(genome)\n",
    "        features = features.reshape(-1, features.shape[-1])\n",
    "        coeff, error, _, _ = np.linalg.lstsq(features, self.u_t, rcond=None)\n",
    "        return coeff, error[0]\n",
    "    \n",
    "    def generate_module(self):\n",
    "        return (random.randint(0, self.n_poly), random.randint(0, self.n_derivatives))\n",
    "    \n",
    "    def set_epsilon(self, epsilon):\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "class PopulationSampling(Sampling):\n",
    "    def _do(self, problem, n_samples, **kwargs):\n",
    "        X = np.full((n_samples, 1), None, dtype=object)\n",
    "        X_set = set()\n",
    "        i = 0\n",
    "        while i < n_samples:\n",
    "            n_modules = random.randint(1, problem.n_modules)\n",
    "            genome = frozenset(problem.generate_module() for _ in range(n_modules))\n",
    "            if len(genome) > 0 and genome not in X_set:\n",
    "                X_set.add(genome)\n",
    "                X[i, 0] = genome\n",
    "                i += 1\n",
    "        return X\n",
    "    \n",
    "class DuplicateElimination(ElementwiseDuplicateElimination):\n",
    "    def is_equal(self, g1, g2):\n",
    "        return g1.X[0] == g2.X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dea1072",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenomeCrossover(Crossover):\n",
    "    def __init__(self):\n",
    "        # define the crossover: number of parents and number of offsprings\n",
    "        super().__init__(2, 2)\n",
    "\n",
    "    def _do(self, problem, X, **kwargs):\n",
    "        # The input of has the following shape (n_parents, n_matings, n_var)\n",
    "        _, n_matings, n_var = X.shape\n",
    "\n",
    "        # The output owith the shape (n_offsprings, n_matings, n_var)\n",
    "        # Because there the number of parents and offsprings are equal it keeps the shape of X\n",
    "        Y = np.full_like(X, None, dtype=object)\n",
    "        \n",
    "        # for each mating provided\n",
    "        for k in range(n_matings):\n",
    "            # get the first and the second parent          \n",
    "            Y[0, k, 0], Y[1, k, 0] = self.crossover_permutation(X[0, k, 0], X[1, k, 0])\n",
    "            \n",
    "        return Y\n",
    "    \n",
    "    def crossover_permutation(self, genome1, genome2):\n",
    "        collection = list(genome1) + list(genome2)\n",
    "        random.shuffle(collection)\n",
    "        return frozenset(collection[:len(genome1)]), frozenset(collection[len(genome1):])\n",
    "    \n",
    "class GenomeMutation(Mutation):\n",
    "    def __init__(self, add_rate=0.4, del_rate=0.5, order_rate=0.4):\n",
    "        super().__init__()\n",
    "        self.add_rate = add_rate\n",
    "        self.del_rate = del_rate\n",
    "        self.order_rate = order_rate\n",
    "\n",
    "    def _do(self, problem, X, **kwargs):\n",
    "        for i in range(len(X)):\n",
    "            if random.random() < self.add_rate:\n",
    "                X[i, 0] = self.add_mutate(problem, X[i, 0])\n",
    "            if random.random() < self.del_rate:\n",
    "                X[i, 0] = self.del_mutate(problem, X[i, 0])\n",
    "            if random.random() < self.order_rate:\n",
    "                X[i, 0] = self.module_mutate(problem, X[i, 0])\n",
    "        return X\n",
    "    \n",
    "    def add_mutate(self, problem, genome, max_iter=3):\n",
    "        for _ in range(max_iter):\n",
    "            new_module = problem.generate_module()\n",
    "            if new_module not in genome:\n",
    "                return genome.union(frozenset({new_module}))\n",
    "        return genome\n",
    "    \n",
    "    def del_mutate(self, problem, genome, max_iter=3):\n",
    "        genome = list(genome)\n",
    "        lg = len(genome)\n",
    "        if lg > 0:\n",
    "            if lg == 1:\n",
    "                for _ in range(max_iter):\n",
    "                    new_module = problem.generate_module()\n",
    "                    if new_module != genome[0]:\n",
    "                        return frozenset({new_module})\n",
    "            else:\n",
    "                genome.pop(random.randint(0, lg-1))\n",
    "        return frozenset(genome)\n",
    "    \n",
    "    def module_mutate(self, problem, genome):\n",
    "        if len(genome) == 0:\n",
    "            return genome\n",
    "        genome = set(genome)\n",
    "        genome.remove(random.choice(list(genome)))\n",
    "        for _ in range(3):\n",
    "            new_module = problem.generate_module()\n",
    "            if new_module not in genome:\n",
    "                genome.add(new_module)\n",
    "                return frozenset(genome)\n",
    "        return frozenset(genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "263f3258",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_size = 500\n",
    "pool = ThreadPool(4)\n",
    "problem = PdeDiscoveryProblem(n_poly, n_derivatives, n_modules, \n",
    "                              base_features, u_t, order_complexity=False, \n",
    "                              elementwise_runner=StarmapParallelization(pool.starmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296e4b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "n_gen  |  n_eval  | n_nds  |      eps      |   indicator  \n",
      "==========================================================\n",
      "     1 |        9 |      4 |             - |             -\n",
      "     2 |       18 |      6 |  0.6534682698 |         ideal\n",
      "     3 |       27 |      7 |  0.1415900026 |         ideal\n",
      "     4 |       36 |      5 |  0.0593505568 |         nadir\n",
      "     5 |       45 |      5 |  0.2325970042 |         ideal\n",
      "     6 |       54 |      3 |  4.0000000000 |         nadir\n",
      "     7 |       63 |      3 |  0.000000E+00 |             f\n",
      "     8 |       72 |      4 |  8.463450E-06 |             f\n",
      "     9 |       81 |      4 |  8.463450E-06 |             f\n",
      "    10 |       90 |      4 |  0.0000289597 |             f\n",
      "    11 |       99 |      4 |  0.0000289597 |             f\n",
      "    12 |      108 |      4 |  0.0000289597 |             f\n",
      "    13 |      117 |      4 |  0.0000289597 |             f\n",
      "    14 |      126 |      4 |  0.0000289597 |             f\n",
      "    15 |      135 |      4 |  0.0000289597 |             f\n",
      "    16 |      144 |      8 |  7.6495301475 |         ideal\n",
      "    17 |      153 |      8 |  0.000000E+00 |             f\n",
      "    18 |      162 |      8 |  0.000000E+00 |             f\n",
      "    19 |      171 |      8 |  0.000000E+00 |             f\n",
      "    20 |      180 |      8 |  0.0039890827 |         ideal\n",
      "    21 |      189 |      8 |  0.000000E+00 |             f\n",
      "    22 |      198 |      8 |  0.000000E+00 |             f\n",
      "    23 |      207 |      8 |  0.000000E+00 |             f\n",
      "    24 |      216 |      8 |  0.6624970871 |         ideal\n",
      "    25 |      225 |      8 |  0.000000E+00 |             f\n",
      "    26 |      234 |      8 |  0.000000E+00 |             f\n",
      "    27 |      243 |      8 |  0.000000E+00 |             f\n",
      "    28 |      252 |      8 |  0.000000E+00 |             f\n",
      "    29 |      261 |      8 |  0.000000E+00 |             f\n",
      "    30 |      270 |      8 |  0.000000E+00 |             f\n",
      "    31 |      279 |      8 |  0.000000E+00 |             f\n",
      "    32 |      288 |      8 |  0.000000E+00 |             f\n",
      "    33 |      297 |      8 |  0.000000E+00 |             f\n",
      "    34 |      306 |      8 |  0.000000E+00 |             f\n",
      "    35 |      315 |      8 |  0.000000E+00 |             f\n",
      "    36 |      324 |      8 |  0.000000E+00 |             f\n",
      "    37 |      333 |      8 |  0.000000E+00 |             f\n",
      "    38 |      342 |      8 |  0.000000E+00 |             f\n",
      "    39 |      351 |      8 |  0.000000E+00 |             f\n",
      "    40 |      360 |      8 |  0.000000E+00 |             f\n",
      "    41 |      369 |      8 |  0.000000E+00 |             f\n",
      "    42 |      378 |      8 |  0.000000E+00 |             f\n",
      "    43 |      387 |      8 |  0.000000E+00 |             f\n",
      "    44 |      396 |      8 |  0.000000E+00 |             f\n",
      "    45 |      405 |      8 |  0.000000E+00 |             f\n",
      "    46 |      414 |      8 |  0.000000E+00 |             f\n",
      "    47 |      423 |      8 |  0.000000E+00 |             f\n",
      "    48 |      432 |      8 |  0.000000E+00 |             f\n",
      "    49 |      441 |      8 |  0.000000E+00 |             f\n",
      "    50 |      450 |      8 |  0.000000E+00 |             f\n",
      "    51 |      459 |      8 |  0.0000611335 |             f\n",
      "    52 |      468 |      8 |  0.0000611335 |             f\n",
      "    53 |      477 |      8 |  0.0000611335 |             f\n",
      "    54 |      486 |      8 |  0.0000611335 |             f\n",
      "    55 |      495 |      8 |  0.0000611335 |             f\n",
      "    56 |      504 |      8 |  0.0000611335 |             f\n",
      "    57 |      513 |      8 |  0.0000611335 |             f\n",
      "    58 |      522 |      8 |  0.0000611335 |             f\n",
      "    59 |      531 |      8 |  0.0000611335 |             f\n",
      "    60 |      540 |      8 |  0.0000611335 |             f\n",
      "    61 |      549 |      8 |  0.0000611335 |             f\n",
      "    62 |      558 |      8 |  0.0000611335 |             f\n",
      "    63 |      567 |      8 |  0.0000611335 |             f\n",
      "    64 |      576 |      8 |  0.0000611335 |             f\n",
      "    65 |      585 |      8 |  0.0000611335 |             f\n",
      "    66 |      594 |      8 |  0.0000611335 |             f\n",
      "    67 |      603 |      8 |  0.0000611335 |             f\n",
      "    68 |      612 |      8 |  0.0000611335 |             f\n",
      "    69 |      621 |      8 |  0.0000611335 |             f\n",
      "    70 |      630 |      8 |  0.0000611335 |             f\n",
      "    71 |      639 |      8 |  0.0000611335 |             f\n",
      "    72 |      648 |      8 |  0.0000611335 |             f\n",
      "    73 |      657 |      8 |  0.0000611335 |             f\n",
      "    74 |      666 |      8 |  0.0082103999 |         ideal\n",
      "    75 |      675 |      8 |  0.000000E+00 |             f\n",
      "    76 |      684 |      8 |  0.000000E+00 |             f\n",
      "    77 |      693 |      8 |  0.000000E+00 |             f\n",
      "    78 |      702 |      8 |  0.000000E+00 |             f\n",
      "    79 |      711 |      8 |  0.000000E+00 |             f\n",
      "    80 |      720 |      8 |  0.000000E+00 |             f\n",
      "    81 |      729 |      8 |  0.000000E+00 |             f\n",
      "    82 |      738 |      8 |  0.000000E+00 |             f\n",
      "    83 |      747 |      8 |  0.000000E+00 |             f\n",
      "    84 |      756 |      8 |  0.000000E+00 |             f\n",
      "    85 |      765 |      8 |  0.000000E+00 |             f\n",
      "    86 |      774 |      8 |  0.000000E+00 |             f\n",
      "    87 |      783 |      8 |  0.000000E+00 |             f\n",
      "    88 |      792 |      8 |  0.000000E+00 |             f\n",
      "    89 |      801 |      8 |  0.000000E+00 |             f\n",
      "    90 |      810 |      8 |  0.000000E+00 |             f\n",
      "    91 |      819 |      8 |  0.000000E+00 |             f\n",
      "    92 |      828 |      8 |  0.000000E+00 |             f\n",
      "    93 |      837 |      8 |  0.2500000000 |         nadir\n",
      "    94 |      846 |      8 |  0.000000E+00 |             f\n",
      "    95 |      855 |      8 |  0.000000E+00 |             f\n",
      "    96 |      864 |      8 |  0.000000E+00 |             f\n",
      "    97 |      873 |      8 |  0.000000E+00 |             f\n",
      "    98 |      882 |      8 |  0.000000E+00 |             f\n",
      "    99 |      891 |      8 |  0.000000E+00 |             f\n",
      "   100 |      900 |      8 |  0.000000E+00 |             f\n",
      "   101 |      909 |      8 |  0.000000E+00 |             f\n",
      "   102 |      918 |      8 |  0.000000E+00 |             f\n",
      "   103 |      927 |      8 |  0.000000E+00 |             f\n",
      "   104 |      936 |      8 |  0.000000E+00 |             f\n",
      "   105 |      945 |      8 |  0.000000E+00 |             f\n",
      "   106 |      954 |      8 |  0.000000E+00 |             f\n",
      "   107 |      963 |      8 |  0.000000E+00 |             f\n",
      "   108 |      972 |      8 |  0.000000E+00 |             f\n",
      "   109 |      981 |      8 |  0.000000E+00 |             f\n",
      "   110 |      990 |      8 |  0.000000E+00 |             f\n",
      "   111 |      999 |      8 |  0.000000E+00 |             f\n",
      "   112 |     1008 |      8 |  0.000000E+00 |             f\n",
      "   113 |     1017 |      8 |  0.000000E+00 |             f\n",
      "   114 |     1026 |      8 |  0.000000E+00 |             f\n",
      "   115 |     1035 |      8 |  0.000000E+00 |             f\n",
      "   116 |     1044 |      8 |  0.000000E+00 |             f\n",
      "   117 |     1053 |      8 |  0.000000E+00 |             f\n",
      "   118 |     1062 |      8 |  0.000000E+00 |             f\n",
      "   119 |     1071 |      8 |  0.000000E+00 |             f\n",
      "   120 |     1080 |      8 |  0.000000E+00 |             f\n",
      "   121 |     1089 |      8 |  0.000000E+00 |             f\n",
      "   122 |     1098 |      8 |  0.000000E+00 |             f\n",
      "   123 |     1107 |      8 |  0.000000E+00 |             f\n",
      "   124 |     1116 |      8 |  0.000000E+00 |             f\n",
      "   125 |     1125 |      8 |  0.000000E+00 |             f\n",
      "   126 |     1134 |      8 |  0.000000E+00 |             f\n",
      "   127 |     1143 |      8 |  0.000000E+00 |             f\n",
      "   128 |     1152 |      8 |  0.000000E+00 |             f\n",
      "   129 |     1161 |      8 |  0.000000E+00 |             f\n",
      "   130 |     1170 |      8 |  0.000000E+00 |             f\n",
      "   131 |     1179 |      8 |  0.000000E+00 |             f\n",
      "   132 |     1188 |      8 |  0.000000E+00 |             f\n",
      "   133 |     1197 |      8 |  0.000000E+00 |             f\n",
      "   134 |     1206 |      8 |  0.000000E+00 |             f\n",
      "   135 |     1215 |      8 |  0.000000E+00 |             f\n",
      "   136 |     1224 |      8 |  0.0052378520 |         ideal\n",
      "   137 |     1233 |      8 |  0.000000E+00 |             f\n",
      "   138 |     1242 |      8 |  0.000000E+00 |             f\n",
      "   139 |     1251 |      8 |  0.000000E+00 |             f\n",
      "   140 |     1260 |      8 |  0.000000E+00 |             f\n",
      "   141 |     1269 |      8 |  0.000000E+00 |             f\n",
      "   142 |     1278 |      8 |  0.000000E+00 |             f\n",
      "   143 |     1287 |      8 |  0.0120332465 |         ideal\n",
      "   144 |     1296 |      8 |  0.000000E+00 |             f\n",
      "   145 |     1305 |      8 |  0.000000E+00 |             f\n",
      "   146 |     1314 |      8 |  0.000000E+00 |             f\n",
      "   147 |     1323 |      8 |  0.000000E+00 |             f\n",
      "   148 |     1332 |      8 |  0.000000E+00 |             f\n",
      "   149 |     1341 |      8 |  0.000000E+00 |             f\n",
      "   150 |     1350 |      8 |  0.000000E+00 |             f\n",
      "   151 |     1359 |      8 |  0.000000E+00 |             f\n",
      "   152 |     1368 |      8 |  0.000000E+00 |             f\n",
      "   153 |     1377 |      8 |  0.000000E+00 |             f\n",
      "   154 |     1386 |      8 |  0.000000E+00 |             f\n",
      "   155 |     1395 |      8 |  0.000000E+00 |             f\n",
      "   156 |     1404 |      8 |  0.000000E+00 |             f\n",
      "   157 |     1413 |      8 |  0.000000E+00 |             f\n",
      "   158 |     1422 |      8 |  0.000000E+00 |             f\n",
      "   159 |     1431 |      8 |  0.000000E+00 |             f\n",
      "   160 |     1440 |      8 |  0.000000E+00 |             f\n",
      "   161 |     1449 |      8 |  0.000000E+00 |             f\n",
      "   162 |     1458 |      8 |  0.000000E+00 |             f\n",
      "   163 |     1467 |      8 |  0.000000E+00 |             f\n",
      "   164 |     1476 |      8 |  0.000000E+00 |             f\n",
      "   165 |     1485 |      8 |  0.000000E+00 |             f\n",
      "   166 |     1494 |      8 |  0.000000E+00 |             f\n",
      "   167 |     1503 |      8 |  0.000000E+00 |             f\n",
      "   168 |     1512 |      8 |  0.000000E+00 |             f\n",
      "   169 |     1521 |      8 |  0.0003001998 |             f\n",
      "   170 |     1530 |      8 |  0.0003001998 |             f\n",
      "   171 |     1539 |      8 |  0.0003001998 |             f\n",
      "   172 |     1548 |      8 |  0.0003001998 |             f\n",
      "   173 |     1557 |      8 |  0.0003001998 |             f\n",
      "   174 |     1566 |      8 |  0.0003001998 |             f\n",
      "   175 |     1575 |      8 |  0.0003001998 |             f\n",
      "   176 |     1584 |      8 |  0.0003001998 |             f\n",
      "   177 |     1593 |      8 |  0.0003001998 |             f\n",
      "   178 |     1602 |      8 |  0.0003001998 |             f\n",
      "   179 |     1611 |      8 |  0.0003001998 |             f\n",
      "   180 |     1620 |      8 |  0.0003001998 |             f\n",
      "   181 |     1629 |      8 |  0.0003001998 |             f\n",
      "   182 |     1638 |      8 |  0.0003001998 |             f\n",
      "   183 |     1647 |      8 |  0.0003001998 |             f\n",
      "   184 |     1656 |      8 |  0.0003001998 |             f\n",
      "   185 |     1665 |      8 |  0.0003001998 |             f\n",
      "   186 |     1674 |      8 |  0.0003001998 |             f\n",
      "   187 |     1683 |      8 |  0.0003001998 |             f\n",
      "   188 |     1692 |      8 |  0.0003001998 |             f\n",
      "   189 |     1701 |      8 |  0.0003001998 |             f\n",
      "   190 |     1710 |      8 |  0.0003001998 |             f\n",
      "   191 |     1719 |      8 |  0.0003001998 |             f\n",
      "   192 |     1728 |      8 |  0.0003001998 |             f\n",
      "   193 |     1737 |      8 |  0.0003001998 |             f\n",
      "   194 |     1746 |      8 |  0.0003001998 |             f\n",
      "   195 |     1755 |      8 |  0.0003001998 |             f\n",
      "   196 |     1764 |      8 |  0.0003001998 |             f\n",
      "   197 |     1773 |      8 |  0.0003001998 |             f\n",
      "   198 |     1782 |      8 |  0.0003001998 |             f\n",
      "   199 |     1791 |      8 |  0.0003001998 |             f\n",
      "   200 |     1800 |      8 |  0.0003001998 |             f\n",
      "   201 |     1809 |      8 |  0.0003001998 |             f\n",
      "   202 |     1818 |      8 |  0.0003001998 |             f\n",
      "   203 |     1827 |      8 |  0.0003001998 |             f\n",
      "   204 |     1836 |      8 |  0.0003001998 |             f\n",
      "   205 |     1845 |      8 |  0.0003001998 |             f\n",
      "   206 |     1854 |      8 |  0.0003001998 |             f\n",
      "   207 |     1863 |      8 |  0.0003001998 |             f\n",
      "   208 |     1872 |      8 |  0.0003001998 |             f\n",
      "   209 |     1881 |      8 |  0.0003001998 |             f\n",
      "   210 |     1890 |      8 |  0.0003001998 |             f\n",
      "   211 |     1899 |      8 |  0.0003001998 |             f\n",
      "   212 |     1908 |      8 |  0.0003001998 |             f\n",
      "   213 |     1917 |      8 |  0.0003001998 |             f\n",
      "   214 |     1926 |      8 |  0.0003001998 |             f\n",
      "   215 |     1935 |      8 |  0.0003001998 |             f\n",
      "   216 |     1944 |      8 |  0.0003001998 |             f\n",
      "   217 |     1953 |      8 |  0.0003001998 |             f\n",
      "   218 |     1962 |      8 |  0.0003001998 |             f\n",
      "   219 |     1971 |      8 |  0.0003001998 |             f\n",
      "   220 |     1980 |      8 |  0.0003001998 |             f\n",
      "   221 |     1989 |      8 |  0.0003001998 |             f\n",
      "   222 |     1998 |      8 |  0.0003001998 |             f\n",
      "   223 |     2007 |      8 |  0.0003001998 |             f\n",
      "   224 |     2016 |      8 |  0.0003001998 |             f\n",
      "   225 |     2025 |      8 |  0.0003001998 |             f\n",
      "   226 |     2034 |      8 |  0.0003001998 |             f\n",
      "   227 |     2043 |      8 |  0.0003001998 |             f\n",
      "   228 |     2052 |      8 |  0.0003001998 |             f\n",
      "   229 |     2061 |      8 |  0.0003001998 |             f\n",
      "   230 |     2070 |      8 |  0.0003001998 |             f\n",
      "   231 |     2079 |      8 |  0.0003001998 |             f\n",
      "   232 |     2088 |      8 |  0.0003001998 |             f\n",
      "   233 |     2097 |      8 |  0.0003001998 |             f\n",
      "   234 |     2106 |      8 |  0.0003001998 |             f\n",
      "   235 |     2115 |      8 |  0.0003001998 |             f\n",
      "   236 |     2124 |      8 |  0.0003001998 |             f\n",
      "   237 |     2133 |      8 |  0.0003001998 |             f\n",
      "   238 |     2142 |      8 |  0.0003001998 |             f\n",
      "   239 |     2151 |      8 |  0.0003001998 |             f\n",
      "   240 |     2160 |      8 |  0.0003001998 |             f\n",
      "   241 |     2169 |      8 |  0.0003001998 |             f\n",
      "   242 |     2178 |      8 |  0.0003001998 |             f\n",
      "   243 |     2187 |      8 |  0.0003001998 |             f\n",
      "   244 |     2196 |      8 |  0.0003001998 |             f\n",
      "   245 |     2205 |      8 |  0.0003001998 |             f\n",
      "   246 |     2214 |      8 |  0.0003001998 |             f\n",
      "   247 |     2223 |      8 |  0.0003001998 |             f\n",
      "   248 |     2232 |      8 |  0.0003001998 |             f\n",
      "   249 |     2241 |      8 |  0.0003001998 |             f\n",
      "   250 |     2250 |      8 |  0.0003001998 |             f\n",
      "   251 |     2259 |      8 |  0.0003001998 |             f\n",
      "   252 |     2268 |      8 |  0.0003001998 |             f\n",
      "   253 |     2277 |      8 |  0.0003001998 |             f\n",
      "   254 |     2286 |      8 |  0.0003001998 |             f\n",
      "   255 |     2295 |      8 |  0.0003001998 |             f\n",
      "   256 |     2304 |      8 |  0.0003001998 |             f\n",
      "   257 |     2313 |      8 |  0.0003001998 |             f\n",
      "   258 |     2322 |      8 |  0.0003001998 |             f\n",
      "   259 |     2331 |      8 |  0.0003001998 |             f\n",
      "   260 |     2340 |      8 |  0.0003001998 |             f\n",
      "   261 |     2349 |      8 |  0.0003001998 |             f\n",
      "   262 |     2358 |      8 |  0.0003001998 |             f\n",
      "   263 |     2367 |      8 |  0.0003001998 |             f\n",
      "   264 |     2376 |      8 |  0.0003001998 |             f\n",
      "   265 |     2385 |      8 |  0.0003001998 |             f\n",
      "   266 |     2394 |      8 |  0.0003001998 |             f\n",
      "   267 |     2403 |      8 |  0.0091745989 |         ideal\n",
      "   268 |     2412 |      8 |  0.000000E+00 |             f\n",
      "   269 |     2421 |      8 |  0.000000E+00 |             f\n",
      "   270 |     2430 |      8 |  0.000000E+00 |             f\n",
      "   271 |     2439 |      8 |  0.000000E+00 |             f\n",
      "   272 |     2448 |      8 |  0.000000E+00 |             f\n",
      "   273 |     2457 |      8 |  0.000000E+00 |             f\n",
      "   274 |     2466 |      8 |  0.000000E+00 |             f\n",
      "   275 |     2475 |      8 |  0.000000E+00 |             f\n",
      "   276 |     2484 |      8 |  0.000000E+00 |             f\n",
      "   277 |     2493 |      8 |  0.000000E+00 |             f\n",
      "   278 |     2502 |      8 |  0.000000E+00 |             f\n",
      "   279 |     2511 |      8 |  0.000000E+00 |             f\n",
      "   280 |     2520 |      8 |  0.000000E+00 |             f\n",
      "   281 |     2529 |      8 |  0.000000E+00 |             f\n",
      "   282 |     2538 |      8 |  0.000000E+00 |             f\n",
      "   283 |     2547 |      8 |  0.000000E+00 |             f\n",
      "   284 |     2556 |      8 |  0.000000E+00 |             f\n",
      "   285 |     2565 |      8 |  0.000000E+00 |             f\n",
      "   286 |     2574 |      8 |  0.000000E+00 |             f\n",
      "   287 |     2583 |      8 |  0.000000E+00 |             f\n",
      "   288 |     2592 |      8 |  0.000000E+00 |             f\n",
      "   289 |     2601 |      8 |  0.000000E+00 |             f\n",
      "   290 |     2610 |      8 |  0.000000E+00 |             f\n",
      "   291 |     2619 |      8 |  0.000000E+00 |             f\n",
      "   292 |     2628 |      8 |  0.000000E+00 |             f\n",
      "   293 |     2637 |      8 |  0.000000E+00 |             f\n",
      "   294 |     2646 |      8 |  0.000000E+00 |             f\n",
      "   295 |     2655 |      8 |  0.000000E+00 |             f\n",
      "   296 |     2664 |      8 |  0.0127919994 |         ideal\n",
      "   297 |     2673 |      8 |  0.000000E+00 |             f\n",
      "   298 |     2682 |      8 |  0.000000E+00 |             f\n",
      "   299 |     2691 |      8 |  0.000000E+00 |             f\n",
      "   300 |     2700 |      8 |  0.000000E+00 |             f\n",
      "   301 |     2709 |      8 |  0.000000E+00 |             f\n",
      "   302 |     2718 |      8 |  0.000000E+00 |             f\n",
      "   303 |     2727 |      8 |  0.000000E+00 |             f\n",
      "   304 |     2736 |      8 |  0.000000E+00 |             f\n",
      "   305 |     2745 |      8 |  0.000000E+00 |             f\n",
      "   306 |     2754 |      8 |  0.000000E+00 |             f\n",
      "   307 |     2763 |      8 |  0.000000E+00 |             f\n",
      "   308 |     2772 |      8 |  0.000000E+00 |             f\n",
      "   309 |     2781 |      8 |  0.000000E+00 |             f\n",
      "   310 |     2790 |      8 |  0.000000E+00 |             f\n",
      "   311 |     2799 |      8 |  0.000000E+00 |             f\n",
      "   312 |     2808 |      8 |  0.000000E+00 |             f\n",
      "   313 |     2817 |      8 |  0.000000E+00 |             f\n",
      "   314 |     2826 |      8 |  0.000000E+00 |             f\n",
      "   315 |     2835 |      8 |  0.000000E+00 |             f\n",
      "   316 |     2844 |      8 |  0.000000E+00 |             f\n",
      "   317 |     2853 |      8 |  0.000000E+00 |             f\n",
      "   318 |     2862 |      8 |  0.000000E+00 |             f\n",
      "   319 |     2871 |      8 |  0.000000E+00 |             f\n",
      "   320 |     2880 |      8 |  0.000000E+00 |             f\n",
      "   321 |     2889 |      8 |  0.000000E+00 |             f\n",
      "   322 |     2898 |      8 |  0.000000E+00 |             f\n",
      "   323 |     2907 |      8 |  0.000000E+00 |             f\n",
      "   324 |     2916 |      8 |  0.000000E+00 |             f\n",
      "   325 |     2925 |      8 |  0.000000E+00 |             f\n",
      "   326 |     2934 |      8 |  0.000000E+00 |             f\n",
      "   327 |     2943 |      8 |  0.000000E+00 |             f\n",
      "   328 |     2952 |      8 |  0.000000E+00 |             f\n",
      "   329 |     2961 |      8 |  0.000000E+00 |             f\n",
      "   330 |     2970 |      8 |  0.000000E+00 |             f\n",
      "   331 |     2979 |      8 |  0.000000E+00 |             f\n",
      "   332 |     2988 |      8 |  0.000000E+00 |             f\n",
      "   333 |     2997 |      8 |  0.000000E+00 |             f\n",
      "   334 |     3006 |      8 |  0.000000E+00 |             f\n",
      "   335 |     3015 |      8 |  0.000000E+00 |             f\n",
      "   336 |     3024 |      8 |  0.000000E+00 |             f\n",
      "   337 |     3033 |      8 |  0.000000E+00 |             f\n",
      "   338 |     3042 |      8 |  0.000000E+00 |             f\n",
      "   339 |     3051 |      8 |  0.000000E+00 |             f\n",
      "   340 |     3060 |      8 |  0.000000E+00 |             f\n",
      "   341 |     3069 |      8 |  0.000000E+00 |             f\n",
      "   342 |     3078 |      8 |  0.000000E+00 |             f\n",
      "   343 |     3087 |      8 |  0.000000E+00 |             f\n",
      "   344 |     3096 |      8 |  0.000000E+00 |             f\n",
      "   345 |     3105 |      8 |  0.000000E+00 |             f\n",
      "   346 |     3114 |      8 |  0.000000E+00 |             f\n",
      "   347 |     3123 |      8 |  0.000000E+00 |             f\n",
      "   348 |     3132 |      8 |  0.000000E+00 |             f\n",
      "   349 |     3141 |      8 |  0.000000E+00 |             f\n",
      "   350 |     3150 |      8 |  0.000000E+00 |             f\n",
      "   351 |     3159 |      8 |  0.000000E+00 |             f\n",
      "   352 |     3168 |      8 |  0.000000E+00 |             f\n",
      "   353 |     3177 |      8 |  0.000000E+00 |             f\n",
      "   354 |     3186 |      8 |  0.000000E+00 |             f\n",
      "   355 |     3195 |      8 |  0.000000E+00 |             f\n",
      "   356 |     3204 |      8 |  0.000000E+00 |             f\n",
      "   357 |     3213 |      8 |  0.000000E+00 |             f\n",
      "   358 |     3222 |      8 |  0.000000E+00 |             f\n",
      "   359 |     3231 |      8 |  0.000000E+00 |             f\n",
      "   360 |     3240 |      8 |  0.000000E+00 |             f\n",
      "   361 |     3249 |      8 |  0.000000E+00 |             f\n",
      "   362 |     3258 |      8 |  0.000000E+00 |             f\n",
      "   363 |     3267 |      8 |  0.000000E+00 |             f\n",
      "   364 |     3276 |      8 |  0.000000E+00 |             f\n",
      "   365 |     3285 |      8 |  0.000000E+00 |             f\n",
      "   366 |     3294 |      8 |  0.000000E+00 |             f\n",
      "   367 |     3303 |      8 |  0.000000E+00 |             f\n",
      "   368 |     3312 |      8 |  0.000000E+00 |             f\n",
      "   369 |     3321 |      8 |  0.000000E+00 |             f\n",
      "   370 |     3330 |      8 |  0.000000E+00 |             f\n",
      "   371 |     3339 |      8 |  0.000000E+00 |             f\n",
      "   372 |     3348 |      8 |  0.000000E+00 |             f\n",
      "   373 |     3357 |      8 |  0.000000E+00 |             f\n",
      "   374 |     3366 |      8 |  0.000000E+00 |             f\n",
      "   375 |     3375 |      8 |  0.000000E+00 |             f\n",
      "   376 |     3384 |      8 |  0.000000E+00 |             f\n",
      "   377 |     3393 |      8 |  0.000000E+00 |             f\n",
      "   378 |     3402 |      8 |  0.000000E+00 |             f\n",
      "   379 |     3411 |      8 |  0.000000E+00 |             f\n",
      "   380 |     3420 |      8 |  0.000000E+00 |             f\n",
      "   381 |     3429 |      8 |  0.000000E+00 |             f\n",
      "   382 |     3438 |      8 |  0.000000E+00 |             f\n",
      "   383 |     3447 |      8 |  0.000000E+00 |             f\n",
      "   384 |     3456 |      8 |  0.000000E+00 |             f\n",
      "   385 |     3465 |      8 |  0.000000E+00 |             f\n",
      "   386 |     3474 |      8 |  0.000000E+00 |             f\n",
      "   387 |     3483 |      8 |  0.000000E+00 |             f\n",
      "   388 |     3492 |      8 |  0.000000E+00 |             f\n",
      "   389 |     3501 |      8 |  0.000000E+00 |             f\n",
      "   390 |     3510 |      8 |  0.000000E+00 |             f\n",
      "   391 |     3519 |      8 |  0.000000E+00 |             f\n",
      "   392 |     3528 |      8 |  0.000000E+00 |             f\n",
      "   393 |     3537 |      8 |  0.000000E+00 |             f\n",
      "   394 |     3546 |      8 |  0.000000E+00 |             f\n",
      "   395 |     3555 |      8 |  0.000000E+00 |             f\n",
      "   396 |     3564 |      8 |  0.000000E+00 |             f\n",
      "   397 |     3573 |      8 |  0.0476374315 |         ideal\n",
      "   398 |     3582 |      8 |  0.000000E+00 |             f\n",
      "   399 |     3591 |      8 |  0.000000E+00 |             f\n",
      "   400 |     3600 |      8 |  0.000000E+00 |             f\n",
      "   401 |     3609 |      8 |  0.000000E+00 |             f\n",
      "   402 |     3618 |      8 |  0.000000E+00 |             f\n",
      "   403 |     3627 |      8 |  0.000000E+00 |             f\n",
      "   404 |     3636 |      8 |  0.000000E+00 |             f\n",
      "   405 |     3645 |      8 |  0.000000E+00 |             f\n",
      "   406 |     3654 |      8 |  0.000000E+00 |             f\n",
      "   407 |     3663 |      8 |  0.000000E+00 |             f\n",
      "   408 |     3672 |      8 |  0.000000E+00 |             f\n",
      "   409 |     3681 |      8 |  0.000000E+00 |             f\n",
      "   410 |     3690 |      8 |  0.000000E+00 |             f\n",
      "   411 |     3699 |      8 |  0.000000E+00 |             f\n",
      "   412 |     3708 |      8 |  0.000000E+00 |             f\n",
      "   413 |     3717 |      8 |  0.000000E+00 |             f\n",
      "   414 |     3726 |      8 |  0.000000E+00 |             f\n",
      "   415 |     3735 |      8 |  0.000000E+00 |             f\n",
      "   416 |     3744 |      8 |  0.000000E+00 |             f\n",
      "   417 |     3753 |      8 |  0.000000E+00 |             f\n",
      "   418 |     3762 |      8 |  0.000000E+00 |             f\n",
      "   419 |     3771 |      8 |  0.000000E+00 |             f\n",
      "   420 |     3780 |      8 |  0.000000E+00 |             f\n",
      "   421 |     3789 |      8 |  0.000000E+00 |             f\n",
      "   422 |     3798 |      8 |  0.000000E+00 |             f\n",
      "   423 |     3807 |      8 |  0.000000E+00 |             f\n",
      "   424 |     3816 |      8 |  0.000000E+00 |             f\n",
      "   425 |     3825 |      8 |  0.000000E+00 |             f\n",
      "   426 |     3834 |      8 |  0.000000E+00 |             f\n",
      "   427 |     3843 |      8 |  0.000000E+00 |             f\n",
      "   428 |     3852 |      8 |  0.000000E+00 |             f\n",
      "   429 |     3861 |      8 |  0.000000E+00 |             f\n",
      "   430 |     3870 |      8 |  0.000000E+00 |             f\n",
      "   431 |     3879 |      8 |  0.000000E+00 |             f\n",
      "   432 |     3888 |      8 |  0.000000E+00 |             f\n",
      "   433 |     3897 |      8 |  0.000000E+00 |             f\n",
      "   434 |     3906 |      8 |  0.000000E+00 |             f\n",
      "   435 |     3915 |      8 |  0.000000E+00 |             f\n",
      "   436 |     3924 |      8 |  0.000000E+00 |             f\n",
      "   437 |     3933 |      8 |  0.000000E+00 |             f\n",
      "   438 |     3942 |      8 |  0.000000E+00 |             f\n",
      "   439 |     3951 |      8 |  0.000000E+00 |             f\n",
      "   440 |     3960 |      8 |  0.000000E+00 |             f\n",
      "   441 |     3969 |      8 |  0.000000E+00 |             f\n",
      "   442 |     3978 |      8 |  0.000000E+00 |             f\n",
      "   443 |     3987 |      8 |  0.000000E+00 |             f\n",
      "   444 |     3996 |      8 |  0.000000E+00 |             f\n",
      "   445 |     4005 |      8 |  0.000000E+00 |             f\n",
      "   446 |     4014 |      8 |  0.000000E+00 |             f\n",
      "   447 |     4023 |      8 |  0.000000E+00 |             f\n",
      "   448 |     4032 |      8 |  0.000000E+00 |             f\n",
      "   449 |     4041 |      8 |  0.000000E+00 |             f\n",
      "   450 |     4050 |      8 |  0.000000E+00 |             f\n",
      "   451 |     4059 |      8 |  0.000000E+00 |             f\n",
      "   452 |     4068 |      8 |  0.000000E+00 |             f\n",
      "   453 |     4077 |      8 |  0.000000E+00 |             f\n",
      "   454 |     4086 |      8 |  0.000000E+00 |             f\n",
      "   455 |     4095 |      8 |  0.000000E+00 |             f\n",
      "   456 |     4104 |      8 |  0.000000E+00 |             f\n",
      "   457 |     4113 |      8 |  0.000000E+00 |             f\n",
      "   458 |     4122 |      8 |  0.000000E+00 |             f\n",
      "   459 |     4131 |      8 |  0.000000E+00 |             f\n",
      "   460 |     4140 |      8 |  0.000000E+00 |             f\n",
      "   461 |     4149 |      8 |  0.000000E+00 |             f\n",
      "   462 |     4158 |      8 |  0.000000E+00 |             f\n",
      "   463 |     4167 |      8 |  0.000000E+00 |             f\n",
      "   464 |     4176 |      8 |  0.000000E+00 |             f\n",
      "   465 |     4185 |      8 |  0.000000E+00 |             f\n",
      "   466 |     4194 |      8 |  0.000000E+00 |             f\n",
      "   467 |     4203 |      8 |  0.000000E+00 |             f\n",
      "   468 |     4212 |      8 |  0.000000E+00 |             f\n",
      "   469 |     4221 |      8 |  0.000000E+00 |             f\n",
      "   470 |     4230 |      8 |  0.000000E+00 |             f\n",
      "   471 |     4239 |      8 |  0.000000E+00 |             f\n",
      "   472 |     4248 |      8 |  0.000000E+00 |             f\n",
      "   473 |     4257 |      8 |  0.000000E+00 |             f\n",
      "   474 |     4266 |      8 |  0.000000E+00 |             f\n",
      "   475 |     4275 |      8 |  0.000000E+00 |             f\n",
      "   476 |     4284 |      8 |  0.000000E+00 |             f\n",
      "   477 |     4293 |      8 |  0.000000E+00 |             f\n",
      "   478 |     4302 |      8 |  0.000000E+00 |             f\n",
      "   479 |     4311 |      8 |  0.000000E+00 |             f\n",
      "   480 |     4320 |      8 |  0.000000E+00 |             f\n",
      "   481 |     4329 |      8 |  0.000000E+00 |             f\n",
      "   482 |     4338 |      8 |  0.000000E+00 |             f\n",
      "   483 |     4347 |      8 |  0.000000E+00 |             f\n",
      "   484 |     4356 |      8 |  0.000000E+00 |             f\n",
      "   485 |     4365 |      8 |  0.000000E+00 |             f\n",
      "   486 |     4374 |      8 |  0.000000E+00 |             f\n",
      "   487 |     4383 |      8 |  0.000000E+00 |             f\n",
      "   488 |     4392 |      8 |  0.000000E+00 |             f\n",
      "   489 |     4401 |      8 |  0.000000E+00 |             f\n",
      "   490 |     4410 |      8 |  0.000000E+00 |             f\n",
      "   491 |     4419 |      8 |  0.000000E+00 |             f\n",
      "   492 |     4428 |      8 |  0.000000E+00 |             f\n",
      "   493 |     4437 |      8 |  0.000000E+00 |             f\n",
      "   494 |     4446 |      8 |  0.000000E+00 |             f\n",
      "   495 |     4455 |      8 |  0.000000E+00 |             f\n",
      "   496 |     4464 |      8 |  0.000000E+00 |             f\n",
      "   497 |     4473 |      8 |  0.000000E+00 |             f\n",
      "   498 |     4482 |      8 |  0.000000E+00 |             f\n",
      "   499 |     4491 |      8 |  0.000000E+00 |             f\n",
      "   500 |     4500 |      8 |  0.000000E+00 |             f\n",
      "   501 |     4509 |      8 |  0.000000E+00 |             f\n",
      "   502 |     4518 |      8 |  0.000000E+00 |             f\n"
     ]
    }
   ],
   "source": [
    "load_pareto_front = False\n",
    "\n",
    "if not load_pareto_front:\n",
    "    ### DNSGA2 ###\n",
    "    # termination = DefaultMultiObjectiveTermination(\n",
    "    #     xtol=1e-8,\n",
    "    #     cvtol=1e-6,\n",
    "    #     ftol=1e-8,\n",
    "    #     period=50,\n",
    "    #     n_max_gen=100,\n",
    "    #     n_max_evals=100000\n",
    "    # )\n",
    "    # algorithm = DNSGA2(pop_size=pop_size,\n",
    "    #                 sampling=PopulationSampling(),\n",
    "    #                 crossover=GenomeCrossover(),\n",
    "    #                 mutation=GenomeMutation(),\n",
    "    #                 eliminate_duplicates=DuplicateElimination(),\n",
    "    #                 )\n",
    "\n",
    "    ### MOEAD ###\n",
    "    from pymoo.algorithms.moo.moead import MOEAD\n",
    "    from pymoo.util.ref_dirs import get_reference_directions\n",
    "    termination = DefaultMultiObjectiveTermination(\n",
    "        xtol=1e-10,\n",
    "        cvtol=1e-8,\n",
    "        ftol=1e-10,\n",
    "        period=100,\n",
    "        n_max_gen=1000,\n",
    "        n_max_evals=1000000\n",
    "    )\n",
    "    algorithm = MOEAD(\n",
    "        ref_dirs=get_reference_directions(\"uniform\", 2, n_partitions=8),\n",
    "        n_neighbors=4,\n",
    "        prob_neighbor_mating=0.9,\n",
    "        sampling=PopulationSampling(),\n",
    "        crossover=GenomeCrossover(),\n",
    "        mutation=GenomeMutation()\n",
    "    )\n",
    "\n",
    "    res = minimize(problem,\n",
    "                algorithm,\n",
    "                termination=termination,\n",
    "                verbose=True)\n",
    "    \n",
    "    pareto_optimal_models = res.X\n",
    "    np.save(f\"./Cache/pf_MOEAD_burgers_noise{int(noise_lv)}.npy\", pareto_optimal_models)\n",
    "\n",
    "else:\n",
    "    pareto_optimal_models = np.load(f\"pf_MOEAD_burgers_noise{int(noise_lv)}.npy\", allow_pickle=True)\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66468fa3-d3a1-45f6-9c8f-d89b0d723713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[frozenset({(0, 1)})],\n",
       "       [frozenset({(1, 1), (0, 2)})],\n",
       "       [frozenset({(1, 1), (0, 2), (0, 4)})],\n",
       "       [frozenset({(1, 1), (0, 2), (4, 6), (0, 4)})],\n",
       "       [frozenset({(0, 4), (4, 3), (1, 1), (4, 6), (0, 2)})],\n",
       "       [frozenset({(0, 4), (4, 3), (1, 1), (4, 6), (1, 4), (0, 2)})]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OPTIONAL ###\n",
    "from operator import itemgetter\n",
    "\n",
    "effective_candidates = frozenset()\n",
    "for i in range(len(pareto_optimal_models)):\n",
    "    effective_candidates = effective_candidates.union(pareto_optimal_models[i][0])\n",
    "effective_candidates = sorted(effective_candidates)\n",
    "\n",
    "new_pareto_optimal_models = []\n",
    "for bs in backward_refinement([sorted([effective_candidates.index(_) for _ in list(pm[0])]) for pm in pareto_optimal_models], \n",
    "                              (problem.numericalize_genome(effective_candidates), y_pre)).get_best_subsets():\n",
    "    bs = itemgetter(*bs)(effective_candidates)\n",
    "    if type(bs[0]) is not tuple:\n",
    "        bs = (bs,)\n",
    "    new_pareto_optimal_models.append([frozenset(bs)])\n",
    "pareto_optimal_models = np.array(new_pareto_optimal_models)\n",
    "del new_pareto_optimal_models\n",
    "pareto_optimal_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f259f587",
   "metadata": {},
   "source": [
    "### Compromise programming ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93233d48-b471-4484-8819-2c3f03f474d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pymoo.decomposition.asf import ASF\n",
    "# import mcdm\n",
    "\n",
    "# est_complexities = {}\n",
    "# F = problem.evaluate(pareto_optimal_models)\n",
    "# nF = (F - F.min(axis=0))/(F.max(axis=0) - F.min(axis=0))\n",
    "# for weights in np.arange(0.1, 1, 0.1):\n",
    "#     decomp = ASF()\n",
    "#     # est_complexity = int(F[decomp.do(nF, 1/np.array([1-weights, weights])).argmin()][1])\n",
    "#     # est_complexity = mcdm.rank(nF, alt_names=list(map(int, F[:, 1].astype(np.int32))), is_benefit_x=[False, False], \n",
    "#     #                            n_method=None, w_vector=[1-weights, weights], s_method=\"mTOPSIS\")[0][0]    \n",
    "#     est_complexity = mcdm.rank(F, alt_names=list(map(int, F[:, 1].astype(np.int32))), is_benefit_x=[False, False], \n",
    "#                                n_method=\"linear2\", w_vector=[1-weights, weights], s_method=\"mTOPSIS\")[0][0]\n",
    "#     if est_complexity not in est_complexities:\n",
    "#         est_complexities[est_complexity] = 1\n",
    "#     else:\n",
    "#         est_complexities[est_complexity] += 1\n",
    "        \n",
    "# est_complexities = sorted(est_complexities.items(), key=lambda _: (_[1], -_[0]), reverse=True)\n",
    "# est_complexities = [_[0] for _ in est_complexities]\n",
    "# min_ss = min(est_complexities)\n",
    "# max_ss = max(est_complexities)\n",
    "# if max_ss == min_ss:\n",
    "#     max_ss += 1\n",
    "\n",
    "# # epsilon = 10**sci_format(np.median(res.F[:, 0:1]))[1]\n",
    "# # pareto_optimal_models = res.X[np.argsort(res.F[:, 0]+epsilon*res.F[:, 1])]\n",
    "# keep_indices = [i for i in range(len(pareto_optimal_models)) if min_ss <= len(pareto_optimal_models[i][0]) <= max_ss]\n",
    "# pareto_optimal_models = pareto_optimal_models[keep_indices]\n",
    "\n",
    "# est_complexities, pareto_optimal_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdf1495e-4126-4fc4-9fec-0a71ad6cb539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymcdm.methods import TOPSIS, MABAC, COMET, SPOTIS\n",
    "from pymcdm import weights as obj_w\n",
    "from pymcdm.helpers import rrankdata\n",
    "from pymcdm.methods.comet_tools import MethodExpert\n",
    "from pymcdm import visuals\n",
    "\n",
    "F = problem.evaluate(pareto_optimal_models)\n",
    "nF = (F - F.min(axis=0))/(F.max(axis=0) - F.min(axis=0))\n",
    "\n",
    "obj_weights = obj_w.entropy_weights(F)\n",
    "types = [-1, -1]\n",
    "cvalues = COMET.make_cvalues(F)\n",
    "expert_function = MethodExpert(TOPSIS(), obj_weights, types)\n",
    "bounds = SPOTIS.make_bounds(F)\n",
    "\n",
    "method_names = ['TOPSIS', 'MABAC', 'COMET', 'SPOTIS']\n",
    "methods = [\n",
    "    TOPSIS(),\n",
    "    MABAC(),\n",
    "    COMET(cvalues, expert_function),\n",
    "    SPOTIS(bounds)\n",
    "]\n",
    "\n",
    "ranks = [method.rank(method(F, obj_weights, types)) for method in methods]\n",
    "est_complexities = sorted(set(np.argsort(ranks)[:, 0]))\n",
    "min_ss = min(est_complexities)\n",
    "max_ss = max(est_complexities)\n",
    "if max_ss == min_ss:\n",
    "    max_ss += 1\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(7, 3), dpi=300, tight_layout=True)\n",
    "# visuals.ranking_bar(ranks, labels=method_names, ax=ax)\n",
    "# plt.show()\n",
    "\n",
    "pareto_optimal_models = pareto_optimal_models[est_complexities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5351d69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fe7f4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [0, 2]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significance_threshold = None # 0.95\n",
    "\n",
    "effective_candidates = frozenset()\n",
    "for i in range(len(pareto_optimal_models)):\n",
    "    effective_candidates = effective_candidates.union(pareto_optimal_models[i][0])\n",
    "effective_candidates = sorted(effective_candidates)\n",
    "\n",
    "effective_candidates = {_: 0.0 for _ in effective_candidates}\n",
    "for i in range(len(pareto_optimal_models)):\n",
    "    potential_pde = list(pareto_optimal_models[i][0])\n",
    "    important_scores = shap_linear_importance(problem.numericalize_genome(potential_pde), \n",
    "                                              y_pre, scale=True)\n",
    "    for j in range(len(potential_pde)):\n",
    "        effective_candidates[potential_pde[j]] += important_scores[j]\n",
    "        \n",
    "total_score = sum(effective_candidates.values())\n",
    "for _ in effective_candidates:\n",
    "    effective_candidates[_] = effective_candidates[_]/total_score\n",
    "    \n",
    "effective_candidates = sorted(effective_candidates.items(), key=lambda _: _[1], reverse=True)\n",
    "X_pre_effective = problem.numericalize_genome([_[0] for _ in effective_candidates])\n",
    "\n",
    "cum_sum = 0\n",
    "cum_sums = []\n",
    "top_candidates = []\n",
    "for i in range(len(effective_candidates)):\n",
    "    cum_sum += effective_candidates[i][1]\n",
    "    cum_sums.append(cum_sum)\n",
    "    top_candidates.append(effective_candidates[i][0])\n",
    "if significance_threshold is not None:\n",
    "    top_candidates = top_candidates[:np.argmax((np.array(cum_sums) > significance_threshold).astype(np.int8))+1]\n",
    "else:\n",
    "    top_candidates = top_candidates[:knee(range(0, len(cum_sums)), cum_sums, S=1, direction='increasing')+1]\n",
    "\n",
    "if len(top_candidates) > max_ss:\n",
    "    top_candidates = np.array(top_candidates)[np.nonzero(linear_model.ARDRegression(max_iter=500, fit_intercept=False).fit(problem.numericalize_genome(top_candidates), y_pre.ravel()).coef_)[0]]\n",
    "else:\n",
    "    top_candidates = np.array(top_candidates)\n",
    "X_pre_top = problem.numericalize_genome(top_candidates)\n",
    "\n",
    "top_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8757b32",
   "metadata": {},
   "source": [
    "### Best-subset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5dc727d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2026-04-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2/2 [00:00<00:00, 73.31it/s]\n",
      "100%|| 2/2 [00:00<00:00, 1076.98it/s]\n"
     ]
    }
   ],
   "source": [
    "best_subsets = solvel0(X_pre_top, y_pre, miosr=True, refine=True)\n",
    "\n",
    "# _, best_subsets = okridge_solvel0_full(X_pre_top, y_pre, \n",
    "#                                        k=X_pre_top.shape[-1], norm='l2')\n",
    "# best_subsets = backward_refinement(best_subsets, (X_pre_top, y_pre), \n",
    "#                                    ic_type='bic', verbose=False).get_best_subsets()\n",
    "\n",
    "best_subsets = [tuple(best_subsets[-1][_] for _ in bs) \n",
    "                for bs in brute_force_all_subsets(X_pre_top[:, best_subsets[-1]], y_pre)[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259fb918",
   "metadata": {},
   "source": [
    "### Model selection using UBIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96a6c77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2, "
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.33323565, 1.        ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Calculate post_means for ARDRegression as well (Implement the ard_uncertainties function)\n",
    "ard_uns = []\n",
    "threshold_lambda = 5e5 # must pass assert \n",
    "for bs in best_subsets:\n",
    "    ard = linear_model.ARDRegression(fit_intercept=False, \n",
    "                                     compute_score=True,\n",
    "                                     threshold_lambda=threshold_lambda)\n",
    "    ard.fit(X_pre_top[:, bs], y_pre.ravel())\n",
    "    print(len(bs), end=', ')\n",
    "    assert len(bs) == len(np.nonzero(ard.coef_)[0])\n",
    "    pde_uncert = np.sqrt(np.diag(ard.sigma_)).sum()\n",
    "    ard_uns.append(pde_uncert)\n",
    "ard_uns = np.array(ard_uns)\n",
    "ard_uns = ard_uns/min(ard_uns)\n",
    "ard_uns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "548e4fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-79555.66805059963, -89773.43439679421]\n",
      "[1.60628311 1.        ]\n",
      "threshold: 0.2\n",
      "max_lam: 3.988872159961028\n",
      "1 <---> 1 inf\n",
      "1 <---> 1 inf\n",
      "1 <---> 1 inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.0, array([-79540.87363639, -89764.22405642]), 1, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau = 3\n",
    "verbose = True\n",
    "# scale = 1 <- generalized UBIC\n",
    "scale = np.log(len(y_pre))\n",
    "per = 75 # 80\n",
    "\n",
    "post_means, b_bics, b_uns = baye_uncertainties(best_subsets, (X_pre_top, y_pre), \n",
    "                                               u_type='cv1', take_sqrt=True, \n",
    "                                               ridge_lambda=0, \n",
    "                                               threshold=0)\n",
    "# b_uns = ard_uns # USE ard_uns INSTEAD\n",
    "predictions = X_pre_top@post_means\n",
    "print(b_bics)\n",
    "print(b_uns)\n",
    "b_bics = np.array(b_bics)\n",
    "max_complexity = len(b_bics)\n",
    "complexities = np.arange(max_complexity)+1\n",
    "d_complexities = complexities[decreasing_values_indices(b_bics)]\n",
    "d_bics = b_bics[decreasing_values_indices(b_bics)]\n",
    "slopes = np.diff(b_bics)/(np.diff(complexities)*b_bics[:-1])\n",
    "try:\n",
    "    thres = np.percentile(np.abs(np.diff(d_bics)/(np.diff(d_complexities)*d_bics[:-1])), per)\n",
    "    thres = math.ceil(sci_format(thres)[0])*10**sci_format(thres)[1]\n",
    "except IndexError:\n",
    "    thres = 1/40\n",
    "min_thres = 1/40\n",
    "thres = max(thres, min_thres)\n",
    "print(\"threshold:\", thres)\n",
    "\n",
    "lower_bounds = []\n",
    "for k, efi in enumerate(best_subsets):\n",
    "    # assert len(efi) == np.count_nonzero(post_means[:, k:k+1])\n",
    "    com = len(efi)\n",
    "    lower_bound = 2*np.abs(log_like_value(predictions[:, k:k+1], y_pre))-np.log(len(y_pre))*com\n",
    "    lower_bounds.append(lower_bound)\n",
    "\n",
    "last_lam = np.log10(max(lower_bounds/(b_uns*scale)))\n",
    "print(\"max_lam:\", last_lam)\n",
    "delta = last_lam/tau\n",
    "now_lam = last_lam-delta\n",
    "last_ubic = UBIC(b_bics, b_uns, len(y_pre), hyp=10**last_lam, scale=scale)\n",
    "last_bc = np.argmin(last_ubic)\n",
    "bc_seq = [last_bc]\n",
    "while now_lam >= 0:\n",
    "    now_ubic = UBIC(b_bics, b_uns, len(y_pre), hyp=10**now_lam, scale=scale)\n",
    "    now_bc = np.argmin(now_ubic)\n",
    "    \n",
    "    diff_com = now_bc-last_bc\n",
    "    diff_bic = b_bics[now_bc]-b_bics[last_bc]\n",
    "    imp = np.nan\n",
    "    if diff_com != 0:\n",
    "        imp = abs(diff_bic/(b_bics[last_bc]*diff_com))\n",
    "    \n",
    "    if verbose:\n",
    "        print(min(last_bc, now_bc), '<--->', max(last_bc, now_bc), \n",
    "              np.nan_to_num(imp, nan=np.inf))\n",
    "    \n",
    "    if (diff_com > 0 and (diff_bic > 0 or imp < thres)) or \\\n",
    "        (diff_com < 0 and diff_bic > 0 and imp > thres):\n",
    "        break\n",
    "    \n",
    "    last_lam = now_lam\n",
    "    now_lam = round(last_lam-delta, 8)\n",
    "    last_ubic = now_ubic\n",
    "    last_bc = now_bc\n",
    "    if last_bc not in bc_seq:\n",
    "        bc_seq.append(last_bc)\n",
    "\n",
    "# best_bc = knee_finder(last_ubic)\n",
    "best_bc = knee(range(len(last_ubic)), last_ubic, 0.95, 'linear', direction='decreasing')\n",
    "if best_bc == 0 and last_bc != 0 and b_bics[last_bc] < b_bics[0] and \\\n",
    "                                    abs((b_bics[last_bc]-b_bics[0])/(b_bics[0]*last_bc)) > thres:\n",
    "    best_bc = knee(range(1, len(last_ubic)), last_ubic[1:], 0.95, 'linear')\n",
    "if best_bc is None:\n",
    "    best_bc = knee_finder(last_ubic)\n",
    "    \n",
    "last_lam = round(last_lam, 8)\n",
    "last_lam, last_ubic, last_bc, best_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ea07764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "complexity_axis = [len(bs) for bs in best_subsets]\n",
    "with plt.style.context(['science']):\n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "    ax2 = ax.twinx()\n",
    "    ax.set_zorder(ax2.get_zorder()+1)\n",
    "    ax.patch.set_visible(False)\n",
    "    \n",
    "    l1, = ax.plot(complexity_axis, last_ubic, 'o-', c='black', markerfacecolor='none', label=f\"$\\lambda = {abs(last_lam)}$\")\n",
    "    ax.set_xticks(complexity_axis)\n",
    "    ax.set_ylabel(\"$\\\\textrm{UBIC}$\", fontsize=12)\n",
    "    ax.set_xlabel(\"Support size\", fontsize=12)\n",
    "    ax.vlines(best_bc+1, min(last_ubic), max(last_ubic), linestyles='--', color='red')\n",
    "    ax.text(best_bc+1, np.mean(last_ubic), 'Knee', color='red', rotation=90, verticalalignment='center')\n",
    "    l2, = ax2.plot(complexity_axis, b_uns, 'o--', c='blue', markerfacecolor='none', label=\"Uncertainty $\\\\textrm{U}^{k}$\")\n",
    "    s1 = ax2.scatter(complexity_axis[np.argmin(b_uns)], b_uns[np.argmin(b_uns)], c='blue')\n",
    "    ax2.tick_params(axis='y', labelcolor='blue')\n",
    "    ax.legend([l1, l2, s1], [f\"UBIC with $\\lambda = {round(abs(last_lam), 2)}$\", \"Uncertainty $\\\\textrm{U}^{k}$\", \"Min $\\\\textrm{U}^{k}$\"], \n",
    "              labelcolor='linecolor', loc='lower left', fontsize=11)\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f\"Figures/ubic_burgers_noise{int(noise_lv)}.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3a233a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Some ideas\n",
    "# Better knee detection algorithm\n",
    "\n",
    "import kneeliverse.kneedle as kneedle\n",
    "import kneeliverse.lmethod as lmethod\n",
    "import kneeliverse.menger as menger\n",
    "import kneeliverse.zmethod as zmethod\n",
    "\n",
    "print(knee_finder(last_ubic))\n",
    "\n",
    "# print(kneedle.knee(np.vstack([range(0, len(last_ubic)), \n",
    "#                               last_ubic]).T[decreasing_values_indices(last_ubic)], t=0.1))\n",
    "\n",
    "# print(lmethod.knee(np.vstack([range(0, len(last_ubic)), \n",
    "#                               last_ubic]).T[decreasing_values_indices(last_ubic)]))\n",
    "\n",
    "# print(menger.knee(np.vstack([range(0, len(last_ubic)), \n",
    "#                              last_ubic]).T[decreasing_values_indices(last_ubic)]))\n",
    "\n",
    "# abs((b_bics[2]-b_bics[1])/(b_bics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320e3fe7-e3f4-4abb-af2f-1e3dc361eb83",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise Exception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f7fbbc-bce9-423e-a852-eff481081970",
   "metadata": {},
   "source": [
    "### Visualization ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9c36f3-a3ab-4b73-afff-e4c2128112fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import CubicSpline, PchipInterpolator\n",
    "if load_pareto_front:\n",
    "    pareto_front = np.load(f\"./Cache/pf_burgers_noise{int(noise_lv)}.npy\", allow_pickle=True)\n",
    "    pareto_front = problem.evaluate(pareto_front)\n",
    "else:\n",
    "    pareto_front = res.F\n",
    "pareto_front = pareto_front[np.argsort(pareto_front[:, 1])]\n",
    "spline = PchipInterpolator(pareto_front[:, 1], pareto_front[:, 0])\n",
    "x_plot = np.linspace(pareto_front[:, 1].min(), pareto_front[:, 1].max(), len(pareto_front[:, 1])*100)\n",
    "\n",
    "bg_color = 'pink'\n",
    "with plt.style.context(['science']):\n",
    "    plt.rcParams['axes.facecolor'] = bg_color\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.plot(x_plot, spline(x_plot), color='blue')\n",
    "    plt.scatter(pareto_front[:, 1], pareto_front[:, 0], facecolor='None', edgecolors='black')\n",
    "    plt.scatter([_ for _ in est_complexities], pareto_front[:, 0][[_-1 for _ in est_complexities]])\n",
    "    plt.ylabel(\"Mean squared error\")\n",
    "    plt.xlabel(\"Support size\")\n",
    "    plt.title(\"Pareto front by NSGA-II\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"Figures/pf_burgers_noise{int(noise_lv)}.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bf8235-8c77-4dec-ab23-254efebdb143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy\n",
    "def show_polynomial_derivative(p: int, d: int):\n",
    "    if p < 0 or d < 0:\n",
    "        raise ValueError(\"Polynomial degree and derivative order must be non-negative integers.\")\n",
    "    polynomial_part = sympy.Symbol('u') if p == 1 else sympy.Symbol(f\"u^{p}\") if p > 0 else sympy.Integer(1)    \n",
    "    derivative_part = f\"u_{'x'*d}\" if d > 0 else ''\n",
    "    if len(derivative_part) < 1:\n",
    "        return sympy.simplify(polynomial_part)\n",
    "    derivative_part = sympy.Symbol(derivative_part)\n",
    "    return sympy.simplify(polynomial_part*derivative_part)\n",
    "effective_candidates_name = ['$'+sympy.latex(show_polynomial_derivative(_[0][0], _[0][1]))+'$' for _ in effective_candidates]\n",
    "with plt.style.context(['science']):\n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "    bars = ax.bar(effective_candidates_name, [_[1] for _ in effective_candidates])\n",
    "    for i, bar in enumerate(bars):\n",
    "        if i < len(top_candidates):\n",
    "            bar.set_hatch('/')\n",
    "    ax.set_ylabel(\"Candidate importance\")\n",
    "    plt.savefig(f\"Figures/importance_burgers_noise{int(noise_lv)}.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c32c7c4-73e1-4e01-a01c-eefec2992d54",
   "metadata": {},
   "source": [
    "### Bayesian model evidence ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3641c55-3194-467e-a59c-c0bc76f6a94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 1e-2\n",
    "while 1:\n",
    "    bme = [log_evidence(X_pre_top, y_pre, effective_indices=bs, v=v) for bs in best_subsets]\n",
    "    if np.argmax(bme) >= knee_finder(b_bics): break\n",
    "    else: v *= 10\n",
    "bme_knee = knee(range(len(bme)), bme, 0.95, 'linear', direction='increasing')\n",
    "bme, np.argmax(bme), bme_knee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9248151-600d-449c-9b64-31ba31a932c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(['science']):\n",
    "    plt.rcParams['axes.facecolor'] = 'pink'\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.plot(range(1, len(bme)+1), bme, color='black')\n",
    "    plt.scatter(range(1, len(bme)+1), bme, facecolor='None', edgecolors='black')\n",
    "    plt.scatter(np.argmax(bme)+1, bme[np.argmax(bme)], label='Max', color='black')\n",
    "    plt.vlines(bme_knee+1, min(bme), max(bme), linestyles='--', color='red')\n",
    "    plt.xlabel(\"Support size\")\n",
    "    plt.ylabel(\"Bayesian model evidence\")\n",
    "    plt.xticks(range(1, len(bme)+1))\n",
    "    plt.text(bme_knee+1, np.mean(bme), 'Knee', color='red', rotation=90, verticalalignment='center')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"Figures/bme_burgers_noise{int(noise_lv)}.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feca64c-c52a-4c42-a3c1-3de46720af75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cad4a6-087e-42f1-9aad-8cff1d2fa9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sindy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
