{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8401bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from functools import partial\n",
    "from decimal import Decimal\n",
    "import numpy as np\n",
    "from sklearnex import patch_sklearn; patch_sklearn()\n",
    "import scipy.io as sio\n",
    "import pysindy as ps\n",
    "from tqdm import trange\n",
    "\n",
    "# NSGA2, DNSGA2, SMSEMOA, AGEMOEA2\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.algorithms.moo.dnsga2 import DNSGA2\n",
    "from pymoo.algorithms.moo.sms import SMSEMOA\n",
    "from pymoo.algorithms.moo.age2 import AGEMOEA2\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from pymoo.core.sampling import Sampling\n",
    "from pymoo.core.crossover import Crossover\n",
    "from pymoo.core.mutation import Mutation\n",
    "from pymoo.core.duplicate import ElementwiseDuplicateElimination\n",
    "from pymoo.termination.default import DefaultMultiObjectiveTermination\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.visualization.scatter import Scatter\n",
    "\n",
    "from utils import *\n",
    "from skimage.restoration import estimate_sigma\n",
    "import bm3d\n",
    "from okridge.solvel0 import *\n",
    "from best_subset import backward_refinement, brute_force_all_subsets\n",
    "from UBIC import *\n",
    "from kneed import KneeLocator\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5916f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_poly = 4\n",
    "n_derivatives = 5\n",
    "n_modules = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eaa96d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['KdV_sine_rep_big.mat', 'kuramoto_sivishinky.mat', 'KdV_rudy.mat', 'burgers.mat']\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../PDE-Discovery-EC/Datasets/\"\n",
    "print(os.listdir(data_path))\n",
    "data = sio.loadmat(os.path.join(data_path, \"kuramoto_sivishinky.mat\"))\n",
    "u_clean = (data['uu']).real; u = u_clean.copy()\n",
    "x = data['x'].ravel()\n",
    "t = data['tt'].ravel()\n",
    "dt = t[1]-t[0]; dx = x[2]-x[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1e0adc",
   "metadata": {},
   "source": [
    "### Add noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "888ee41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise level: 50.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "noise_lv = float(50)\n",
    "print(\"Noise level:\", noise_lv)\n",
    "noise = 0.01*np.abs(noise_lv)*(u.std())*np.random.randn(u.shape[0],u.shape[1])\n",
    "u = u + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f675560",
   "metadata": {},
   "source": [
    "### Gaussian process\n",
    "    - removing entries in x that show high std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3b809d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|█| 25/25 [00:08<00:00,  3.12it/s, 7 steps of size 4.83e-02. acc. pr\n",
      "sample: 100%|█| 25/25 [00:08<00:00,  2.87it/s, 7 steps of size 4.83e-02. acc. pr\n",
      "sample: 100%|█| 25/25 [00:09<00:00,  2.76it/s, 7 steps of size 4.83e-02. acc. pr\n",
      "sample: 100%|█| 25/25 [00:08<00:00,  3.07it/s, 7 steps of size 4.83e-02. acc. pr\n",
      "sample: 100%|█| 25/25 [00:12<00:00,  1.93it/s, 7 steps of size 4.83e-02. acc. pr\n",
      "sample: 100%|█| 25/25 [00:09<00:00,  2.68it/s, 7 steps of size 4.83e-02. acc. pr\n",
      "sample: 100%|█| 25/25 [00:07<00:00,  3.37it/s, 7 steps of size 4.83e-02. acc. pr\n",
      "sample: 100%|█| 25/25 [00:09<00:00,  2.65it/s, 7 steps of size 4.83e-02. acc. pr\n",
      "sample: 100%|█| 25/25 [00:19<00:00,  1.29it/s, 23 steps of size 4.83e-02. acc. p\n",
      "sample: 100%|█| 25/25 [00:09<00:00,  2.64it/s, 7 steps of size 4.83e-02. acc. pr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5564492114412133 0.9466760754585266\n"
     ]
    }
   ],
   "source": [
    "import gpax\n",
    "\n",
    "n_sampled_t = 10\n",
    "xx = colvec(x)\n",
    "u_std = np.ones((u.shape[0], n_sampled_t))\n",
    "for i in range(n_sampled_t):\n",
    "    rng_key_train, rng_key_predict = gpax.utils.get_keys()\n",
    "\n",
    "    gp_model = gpax.ExactGP(1, kernel='RBF')\n",
    "    gp_model.fit(rng_key_train, xx, u[:, np.random.choice(len(t))], \n",
    "                 num_warmup=5, num_samples=20, jitter=1e-6, \n",
    "                 chain_method='parallel', print_summary=False)\n",
    "\n",
    "    posterior_mean, f_samples = gp_model.predict(rng_key_predict, xx)\n",
    "    u_std[:, i] = np.std(f_samples[:, 0, :], axis=0)\n",
    "\n",
    "cutoff_ws = 0\n",
    "print(u_std.mean(), u_std.max())\n",
    "est_sigma = u_std.mean() # max also works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9754901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_sampled_t = 10\n",
    "\n",
    "# kernel = RBF(length_scale=1, length_scale_bounds=(1e-2, 1e3)) + \\\n",
    "#         WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e10))\n",
    "\n",
    "# xx = colvec(x)\n",
    "# u_std = np.ones((u.shape[0], n_sampled_t))\n",
    "# for i in trange(n_sampled_t):    \n",
    "#     gpr = GaussianProcessRegressor(kernel=kernel, alpha=0.0, \n",
    "#                                    n_restarts_optimizer=10 # 20\n",
    "#                                   )\n",
    "\n",
    "#     gpr.fit(xx, u[:, np.random.choice(len(t))])\n",
    "#     _, ustd = gpr.predict(xx, return_std=True)\n",
    "#     u_std[:, i] = ustd\n",
    "    \n",
    "# est_sigma = u_std.mean() # max also works well\n",
    "# cutoff_ws = knee(range(21), \n",
    "#                  [u_std.std()]+[u_std[ws:-ws, :].std() for ws in range(1, 21)], \n",
    "#                  'linear')\n",
    "# if cutoff_ws > 0:\n",
    "#     u = u[cutoff_ws:-cutoff_ws, :]\n",
    "#     x = x[cutoff_ws:-cutoff_ws]\n",
    "    \n",
    "# est_sigma, cutoff_ws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c890b0",
   "metadata": {},
   "source": [
    "### Denoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f3d31a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = bm3d.bm3d(u, sigma_psd=est_sigma, \n",
    "              stage_arg=bm3d.BM3DStages.ALL_STAGES, \n",
    "              blockmatches=(False, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05a04eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = np.array([x.reshape(-1, 1), t.reshape(1, -1)], dtype=object)\n",
    "X, T = np.meshgrid(x, t)\n",
    "XT = np.asarray([X, T]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aaf2666",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_library = ps.PolynomialLibrary(degree=n_poly, include_bias=False)\n",
    "\n",
    "weak_lib = ps.WeakPDELibrary(\n",
    "    function_library=function_library,\n",
    "    derivative_order=n_derivatives,\n",
    "    spatiotemporal_grid=XT,\n",
    "    include_bias=True,\n",
    "    K=10000\n",
    ")\n",
    "\n",
    "X_pre = np.array(weak_lib.fit_transform(np.expand_dims(u, -1)))\n",
    "y_pre = weak_lib.convert_u_dot_integral(np.expand_dims(u, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ad9a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_poly = np.array([[p, 0] for p in range(1, n_poly+1)])\n",
    "base_derivative = np.array([[0, d] for d in range(1, n_derivatives+1)])\n",
    "modules = [(0, 0)] if weak_lib.include_bias else []\n",
    "modules += [(p, 0) for p in range(1, n_poly+1)] + \\\n",
    "            [(0, d) for d in range(1, n_derivatives+1)] + \\\n",
    "            [tuple(p+d) for d in base_derivative for p in base_poly]\n",
    "assert len(modules) == len(weak_lib.get_feature_names())\n",
    "base_features = dict(zip(modules, X_pre.T))\n",
    "u_t = y_pre.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb73e146",
   "metadata": {},
   "source": [
    "### Genetic algorithm with NSGA-II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fa61c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PdeDiscoveryProblem(ElementwiseProblem):\n",
    "    def __init__(self, n_poly, n_derivatives, n_modules, \n",
    "                 base_features, u_t, epsilon=0):\n",
    "        super().__init__(n_var=1, n_obj=2, n_ieq_constr=0)\n",
    "        self.n_poly = n_poly\n",
    "        self.n_derivatives = n_derivatives\n",
    "        self.n_modules = n_modules\n",
    "        self.base_features = base_features\n",
    "        self.u_t = u_t\n",
    "        self.epsilon = epsilon\n",
    "        self.sample_size = np.prod(self.u_t.shape)\n",
    "\n",
    "    def _evaluate(self, X, out, *args, **kwargs):\n",
    "        genome = X[0]\n",
    "        coeff, mse = self.compute_genome_coefficient(genome)\n",
    "        mse = mse/self.sample_size\n",
    "        complexity_penalty = self.epsilon*len(genome)\n",
    "        out[\"F\"] = [mse, complexity_penalty]\n",
    "        \n",
    "    def numericalize_genome(self, genome):\n",
    "        return np.stack([self.base_features[tuple(module)] \n",
    "                         for module in genome], axis=-1)\n",
    "\n",
    "    def compute_genome_coefficient(self, genome):\n",
    "        features = self.numericalize_genome(genome)\n",
    "        features = features.reshape(-1, features.shape[-1])\n",
    "        coeff, error, _, _ = np.linalg.lstsq(features, self.u_t, rcond=None)\n",
    "        return coeff, error[0]\n",
    "    \n",
    "    def generate_module(self, n_poly, n_derivatives):\n",
    "        return (random.randint(0, n_poly), random.randint(0, n_derivatives))\n",
    "    \n",
    "    def set_epsilon(self, epsilon):\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "class PopulationSampling(Sampling):\n",
    "    def _do(self, problem, n_samples, **kwargs):\n",
    "        X = np.full((n_samples, 1), None, dtype=object)\n",
    "        X_set = set()\n",
    "        i = 0\n",
    "        while i < n_samples:\n",
    "            n_modules = random.randint(1, problem.n_modules)\n",
    "            genome = frozenset(problem.generate_module(problem.n_poly, problem.n_derivatives) for _ in range(n_modules))\n",
    "            if len(genome) > 0 and genome not in X_set:\n",
    "                X_set.add(genome)\n",
    "                X[i, 0] = genome\n",
    "                i += 1\n",
    "        return X\n",
    "    \n",
    "class DuplicateElimination(ElementwiseDuplicateElimination):\n",
    "    def is_equal(self, g1, g2):\n",
    "        return g1.X[0] == g2.X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dea1072",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenomeCrossover(Crossover):\n",
    "    def __init__(self):\n",
    "        # define the crossover: number of parents and number of offsprings\n",
    "        super().__init__(2, 2)\n",
    "\n",
    "    def _do(self, problem, X, **kwargs):\n",
    "        # The input of has the following shape (n_parents, n_matings, n_var)\n",
    "        _, n_matings, n_var = X.shape\n",
    "\n",
    "        # The output owith the shape (n_offsprings, n_matings, n_var)\n",
    "        # Because there the number of parents and offsprings are equal it keeps the shape of X\n",
    "        Y = np.full_like(X, None, dtype=object)\n",
    "        \n",
    "        # for each mating provided\n",
    "        for k in range(n_matings):\n",
    "            # get the first and the second parent          \n",
    "            Y[0, k, 0], Y[1, k, 0] = self.crossover_permutation(X[0, k, 0], X[1, k, 0])\n",
    "            \n",
    "        return Y\n",
    "    \n",
    "    def crossover_permutation(self, genome1, genome2):\n",
    "        collection = list(genome1) + list(genome2)\n",
    "        random.shuffle(collection)\n",
    "        return frozenset(collection[:len(genome1)]), frozenset(collection[len(genome1):])\n",
    "    \n",
    "class GenomeMutation(Mutation):\n",
    "    def __init__(self, add_rate=0.4, del_rate=0.5, order_rate=0.4):\n",
    "        super().__init__()\n",
    "        self.add_rate = add_rate\n",
    "        self.del_rate = del_rate\n",
    "        self.order_rate = order_rate\n",
    "\n",
    "    def _do(self, problem, X, **kwargs):\n",
    "        for i in range(len(X)):\n",
    "            if random.random() < self.add_rate:\n",
    "                X[i, 0] = self.add_mutate(problem, X[i, 0])\n",
    "            if random.random() < self.del_rate:\n",
    "                X[i, 0] = self.del_mutate(problem, X[i, 0])\n",
    "            if random.random() < self.order_rate:\n",
    "                X[i, 0] = self.module_mutate(problem, X[i, 0])\n",
    "        return X\n",
    "    \n",
    "    def add_mutate(self, problem, genome, max_iter=3):\n",
    "        for _ in range(max_iter):\n",
    "            new_module = problem.generate_module(problem.n_poly, problem.n_derivatives)\n",
    "            if new_module not in genome:\n",
    "                return genome.union(frozenset({new_module}))\n",
    "        return genome\n",
    "    \n",
    "    def del_mutate(self, problem, genome, max_iter=3):\n",
    "        genome = list(genome)\n",
    "        lg = len(genome)\n",
    "        if lg > 0:\n",
    "            if lg == 1:\n",
    "                for _ in range(max_iter):\n",
    "                    new_module = problem.generate_module(problem.n_poly, problem.n_derivatives)\n",
    "                    if new_module != genome[0]:\n",
    "                        return frozenset({new_module})\n",
    "            else:\n",
    "                genome.pop(random.randint(0, lg-1))\n",
    "        return frozenset(genome)\n",
    "    \n",
    "    def module_mutate(self, problem, genome):\n",
    "        if len(genome) == 0:\n",
    "            return genome\n",
    "        genome = set(genome)\n",
    "        genome.remove(random.choice(list(genome)))\n",
    "        for _ in range(3):\n",
    "            new_module = problem.generate_module(problem.n_poly, problem.n_derivatives)\n",
    "            if new_module not in genome:\n",
    "                genome.add(new_module)\n",
    "                return frozenset(genome)\n",
    "        return frozenset(genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "263f3258",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_size = 500\n",
    "problem = PdeDiscoveryProblem(n_poly, n_derivatives, n_modules, \n",
    "                              base_features, u_t, 0)\n",
    "pop = PopulationSampling().do(problem, pop_size)\n",
    "pop = [[pop[i].X[0]] for i in range(len(pop))]\n",
    "epi = 10**(sci_format(np.median(problem.evaluate(pop)[:, 0]))[1])\n",
    "problem.set_epsilon(epi)\n",
    "del pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "296e4b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "n_gen  |  n_eval  | n_nds  |      eps      |   indicator  \n",
      "==========================================================\n",
      "     1 |      500 |      7 |             - |             -\n",
      "     2 |     1550 |      8 |  0.4403153440 |         ideal\n",
      "     3 |     2600 |      8 |  0.1250000000 |         nadir\n",
      "     4 |     3650 |      6 |  0.1071333406 |             f\n",
      "     5 |     4700 |      7 |  0.1428571429 |         nadir\n",
      "     6 |     5750 |      6 |  0.0000104536 |             f\n",
      "     7 |     6800 |      7 |  0.1250000000 |         nadir\n",
      "     8 |     7850 |      9 |  0.1111111111 |         nadir\n",
      "     9 |     8900 |      9 |  5.856930E-06 |             f\n",
      "    10 |     9950 |     11 |  0.1000000000 |         nadir\n",
      "    11 |    11000 |     11 |  1.729681E-06 |             f\n",
      "    12 |    12050 |     10 |  0.1111111111 |         nadir\n",
      "    13 |    13100 |     10 |  0.000000E+00 |             f\n",
      "    14 |    14150 |     11 |  0.1000000000 |         nadir\n",
      "    15 |    15200 |     11 |  1.199835E-06 |             f\n",
      "    16 |    16250 |     11 |  2.574691E-06 |             f\n",
      "    17 |    17300 |     11 |  2.574691E-06 |             f\n",
      "    18 |    18350 |     11 |  2.574691E-06 |             f\n",
      "    19 |    19400 |     11 |  2.574691E-06 |             f\n",
      "    20 |    20450 |     11 |  4.378218E-06 |             f\n",
      "    21 |    21500 |     11 |  6.916109E-06 |             f\n",
      "    22 |    22550 |     11 |  8.326343E-06 |             f\n",
      "    23 |    23600 |     11 |  0.0000140762 |             f\n",
      "    24 |    24650 |     11 |  0.0000204512 |             f\n",
      "    25 |    25700 |     11 |  0.0000255024 |             f\n",
      "    26 |    26750 |     11 |  0.0000305883 |             f\n",
      "    27 |    27800 |     11 |  0.0000305883 |             f\n",
      "    28 |    28850 |     11 |  0.0000307001 |             f\n",
      "    29 |    29900 |     12 |  0.0909090909 |         nadir\n",
      "    30 |    30950 |     12 |  3.331941E-07 |             f\n",
      "    31 |    32000 |     12 |  3.331941E-07 |             f\n",
      "    32 |    33050 |     13 |  0.1538461538 |         nadir\n",
      "    33 |    34100 |     14 |  0.0714285714 |         nadir\n",
      "    34 |    35150 |     15 |  0.0047619048 |             f\n",
      "    35 |    36200 |     15 |  3.184094E-06 |             f\n",
      "    36 |    37250 |     16 |  0.0666666667 |         nadir\n",
      "    37 |    38300 |     16 |  3.745658E-09 |             f\n",
      "    38 |    39350 |     16 |  3.745658E-09 |             f\n",
      "    39 |    40400 |     16 |  2.021359E-07 |             f\n",
      "    40 |    41450 |     16 |  2.021359E-07 |             f\n",
      "    41 |    42500 |     16 |  2.021359E-07 |             f\n",
      "    42 |    43550 |     15 |  0.0714285714 |         nadir\n",
      "    43 |    44600 |     15 |  1.227958E-06 |             f\n",
      "    44 |    45650 |     15 |  1.273722E-06 |             f\n",
      "    45 |    46700 |     15 |  2.372416E-06 |             f\n",
      "    46 |    47750 |     15 |  2.948597E-06 |             f\n",
      "    47 |    48800 |     15 |  3.788188E-06 |             f\n",
      "    48 |    49850 |     16 |  0.0666666667 |         nadir\n",
      "    49 |    50900 |     16 |  0.000000E+00 |             f\n",
      "    50 |    51950 |     16 |  8.177176E-07 |             f\n",
      "    51 |    53000 |     16 |  1.623874E-06 |             f\n",
      "    52 |    54050 |     16 |  1.623874E-06 |             f\n",
      "    53 |    55100 |     15 |  0.0714285714 |         nadir\n",
      "    54 |    56150 |     15 |  3.064634E-06 |             f\n",
      "    55 |    57200 |     15 |  5.210000E-06 |             f\n",
      "    56 |    58250 |     15 |  5.210000E-06 |             f\n",
      "    57 |    59300 |     15 |  5.210000E-06 |             f\n",
      "    58 |    60350 |     15 |  5.271997E-06 |             f\n",
      "    59 |    61400 |     15 |  5.541201E-06 |             f\n",
      "    60 |    62450 |     16 |  0.1764705882 |         nadir\n",
      "    61 |    63500 |     16 |  0.000000E+00 |             f\n",
      "    62 |    64550 |     17 |  0.0034602076 |             f\n",
      "    63 |    65600 |     17 |  0.000000E+00 |             f\n",
      "    64 |    66650 |     16 |  1.659151E-06 |             f\n",
      "    65 |    67700 |     16 |  1.659151E-06 |             f\n",
      "    66 |    68750 |     16 |  1.659151E-06 |             f\n",
      "    67 |    69800 |     16 |  1.659151E-06 |             f\n",
      "    68 |    70850 |     16 |  1.659151E-06 |             f\n",
      "    69 |    71900 |     16 |  1.659151E-06 |             f\n",
      "    70 |    72950 |     16 |  1.813988E-06 |             f\n",
      "    71 |    74000 |     17 |  0.0034628236 |             f\n",
      "    72 |    75050 |     17 |  1.608676E-07 |             f\n",
      "    73 |    76100 |     17 |  1.608676E-07 |             f\n",
      "    74 |    77150 |     17 |  1.608676E-07 |             f\n",
      "    75 |    78200 |     16 |  0.0625000000 |         nadir\n",
      "    76 |    79250 |     15 |  3.757628E-07 |             f\n",
      "    77 |    80300 |     15 |  4.251391E-07 |             f\n",
      "    78 |    81350 |     15 |  1.226567E-06 |             f\n",
      "    79 |    82400 |     15 |  1.226567E-06 |             f\n",
      "    80 |    83450 |     16 |  0.0588235294 |         nadir\n",
      "    81 |    84500 |     16 |  6.464030E-07 |             f\n",
      "    82 |    85550 |     16 |  6.464030E-07 |             f\n",
      "    83 |    86600 |     16 |  2.158970E-06 |             f\n",
      "    84 |    87650 |     16 |  2.158970E-06 |             f\n",
      "    85 |    88700 |     16 |  2.618888E-06 |             f\n",
      "    86 |    89750 |     16 |  2.618888E-06 |             f\n",
      "    87 |    90800 |     17 |  0.0034626724 |             f\n",
      "    88 |    91850 |     17 |  0.000000E+00 |             f\n",
      "    89 |    92900 |     17 |  7.608680E-07 |             f\n",
      "    90 |    93950 |     17 |  7.608680E-07 |             f\n",
      "    91 |    95000 |     17 |  7.608680E-07 |             f\n",
      "    92 |    96050 |     17 |  7.608680E-07 |             f\n",
      "    93 |    97100 |     18 |  0.0032686925 |             f\n",
      "    94 |    98150 |     18 |  0.000000E+00 |             f\n",
      "    95 |    99200 |     18 |  3.135050E-07 |             f\n",
      "    96 |   100250 |     18 |  3.135050E-07 |             f\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[frozenset({(3, 1)})],\n",
       "       [frozenset({(3, 1), (3, 0)})],\n",
       "       [frozenset({(1, 1), (0, 4), (0, 2)})],\n",
       "       [frozenset({(1, 1), (3, 3), (0, 4), (0, 2)})],\n",
       "       [frozenset({(0, 4), (1, 1), (4, 2), (0, 2), (3, 3)})],\n",
       "       [frozenset({(0, 4), (3, 4), (1, 1), (1, 4), (0, 2), (3, 3)})],\n",
       "       [frozenset({(0, 4), (3, 4), (1, 1), (1, 4), (4, 2), (0, 2), (3, 3)})],\n",
       "       [frozenset({(2, 4), (4, 0), (0, 4), (3, 4), (1, 1), (0, 2), (3, 3), (2, 2)})],\n",
       "       [frozenset({(2, 4), (4, 0), (0, 4), (3, 4), (1, 1), (1, 4), (0, 2), (3, 3), (2, 2)})],\n",
       "       [frozenset({(2, 4), (4, 0), (0, 4), (3, 4), (1, 1), (1, 4), (2, 3), (0, 2), (3, 3), (2, 2)})],\n",
       "       [frozenset({(2, 4), (4, 0), (0, 4), (3, 4), (1, 1), (1, 4), (0, 2), (3, 3), (2, 2), (3, 2), (4, 1)})],\n",
       "       [frozenset({(2, 4), (4, 0), (0, 4), (3, 4), (4, 3), (1, 1), (1, 4), (0, 2), (3, 3), (2, 2), (3, 2), (4, 1)})],\n",
       "       [frozenset({(2, 4), (4, 0), (0, 4), (3, 4), (3, 1), (1, 1), (1, 4), (2, 3), (4, 5), (3, 3), (0, 2), (2, 2), (3, 2)})],\n",
       "       [frozenset({(2, 4), (4, 0), (0, 4), (3, 4), (1, 5), (1, 1), (2, 0), (1, 4), (2, 3), (4, 5), (0, 2), (3, 3), (2, 2), (3, 2)})],\n",
       "       [frozenset({(2, 4), (4, 0), (0, 4), (3, 4), (1, 5), (1, 1), (2, 0), (1, 4), (2, 3), (4, 5), (0, 2), (3, 3), (2, 2), (3, 2), (3, 5)})]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_optimal_models = 15\n",
    "\n",
    "termination = DefaultMultiObjectiveTermination(\n",
    "    xtol=1e-8,\n",
    "    cvtol=1e-6,\n",
    "    ftol=1e-8,\n",
    "    period=50,\n",
    "    n_max_gen=100,\n",
    "    n_max_evals=100000\n",
    ")\n",
    "\n",
    "algorithm = DNSGA2( \n",
    "                   pop_size=pop_size,\n",
    "                   sampling=PopulationSampling(),\n",
    "                   crossover=GenomeCrossover(),\n",
    "                   mutation=GenomeMutation(),\n",
    "                   eliminate_duplicates=DuplicateElimination())\n",
    "\n",
    "res = minimize(problem,\n",
    "               algorithm,\n",
    "               termination=termination,\n",
    "               verbose=True)\n",
    "\n",
    "pareto_optimal_models = res.X[np.argsort(res.F[:, 0]+res.F[:, 1])][:n_optimal_models]\n",
    "support_sizes = [len(pareto_optimal_models[i][0]) for i in range(len(pareto_optimal_models))]\n",
    "max_ss = max(support_sizes); min_ss = min(support_sizes)\n",
    "pareto_optimal_models[:n_optimal_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fe7f4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 2), (0, 4), (1, 1), (3, 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significance_threshold = 0.95\n",
    "\n",
    "effective_candidates = frozenset()\n",
    "for i in range(len(pareto_optimal_models)):\n",
    "    effective_candidates = effective_candidates.union(pareto_optimal_models[i][0])\n",
    "    \n",
    "effective_candidates = {_: 0.0 for _ in effective_candidates}\n",
    "for i in range(len(pareto_optimal_models)):\n",
    "    potential_pde = list(pareto_optimal_models[i][0])\n",
    "    important_scores = shap_linear_importance(problem.numericalize_genome(potential_pde), \n",
    "                                              y_pre, scale=True)\n",
    "    for j in range(len(potential_pde)):\n",
    "        effective_candidates[potential_pde[j]] += important_scores[j]\n",
    "        \n",
    "total_score = sum(effective_candidates.values())\n",
    "for _ in effective_candidates:\n",
    "    effective_candidates[_] = effective_candidates[_]/total_score\n",
    "    \n",
    "effective_candidates = sorted(effective_candidates.items(), key=lambda _: _[1], reverse=True)\n",
    "cumulative_sum = 0\n",
    "top_candidates = []\n",
    "for i in range(len(effective_candidates)):\n",
    "    cumulative_sum += effective_candidates[i][1]\n",
    "    top_candidates.append(effective_candidates[i][0])\n",
    "    if cumulative_sum > significance_threshold:\n",
    "        break\n",
    "\n",
    "if len(top_candidates) > max_ss:\n",
    "    top_candidates = np.array(top_candidates)[np.nonzero(linear_model.ARDRegression(max_iter=500, fit_intercept=False).fit(problem.numericalize_genome(top_candidates), y_pre.ravel()).coef_)[0]]\n",
    "X_pre_top = problem.numericalize_genome(top_candidates)\n",
    "\n",
    "top_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8757b32",
   "metadata": {},
   "source": [
    "### Best-subset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dc727d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [00:02<00:00,  1.75it/s]\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 507.89it/s]\n"
     ]
    }
   ],
   "source": [
    "_, best_subsets = okridge_solvel0_full(X_pre_top, y_pre, \n",
    "                                       k=X_pre_top.shape[-1], norm='l2')\n",
    "best_subsets = backward_refinement(best_subsets, (X_pre_top, y_pre), \n",
    "                                   ic_type='bic', verbose=False).get_best_subsets()\n",
    "best_subsets = [tuple(best_subsets[-1][_] for _ in bs) \n",
    "                for bs in brute_force_all_subsets(X_pre_top[:, best_subsets[-1]], y_pre)[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259fb918",
   "metadata": {},
   "source": [
    "### Model selection using UBIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96a6c77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2, 3, 4, "
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 2.37108781, 2.61516731, 3.97397262])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Calculate post_means for ARDRegression as well (Implement the ard_uncertainties function)\n",
    "ard_uns = []\n",
    "threshold_lambda = 5e5 # must pass assert \n",
    "for bs in best_subsets:\n",
    "    ard = linear_model.ARDRegression(fit_intercept=False, \n",
    "                                     compute_score=True,\n",
    "                                     threshold_lambda=threshold_lambda)\n",
    "    ard.fit(X_pre_top[:, bs], y_pre.ravel())\n",
    "    print(len(bs), end=', ')\n",
    "    assert len(bs) == len(np.nonzero(ard.coef_)[0])\n",
    "    pde_uncert = np.sqrt(np.diag(ard.sigma_)).sum()\n",
    "    ard_uns.append(pde_uncert)\n",
    "ard_uns = np.array(ard_uns)\n",
    "ard_uns = ard_uns/min(ard_uns)\n",
    "ard_uns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "548e4fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28281.554071388484, 25358.900495594116, -6071.6204169508965, -6062.670775653767]\n",
      "[7.87582894 7.3847923  1.         1.6777799 ]\n",
      "threshold: 1.0\n",
      "max_lam: 2.819028932666227\n",
      "2 <---> 2 inf\n",
      "2 <---> 2 inf\n",
      "2 <---> 2 inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.0,\n",
       " array([28354.09313666, 25426.91694623, -6062.41007658, -6047.2178517 ]),\n",
       " 2,\n",
       " 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau = 3\n",
    "verbose = True\n",
    "# scale = 1 <- generalized UBIC\n",
    "scale = np.log(len(y_pre))\n",
    "per = 75 # 80\n",
    "\n",
    "post_means, b_bics, b_uns = baye_uncertainties(best_subsets, (X_pre_top, y_pre), \n",
    "                                               u_type='cv1', take_sqrt=True, \n",
    "                                               ridge_lambda=0, \n",
    "                                               threshold=0)\n",
    "# b_uns = ard_uns # USE ard_uns INSTEAD\n",
    "predictions = X_pre_top@post_means\n",
    "print(b_bics)\n",
    "print(b_uns)\n",
    "b_bics = np.array(b_bics)\n",
    "max_complexity = len(b_bics)\n",
    "complexities = np.arange(max_complexity)+1\n",
    "d_complexities = complexities[decreasing_values_indices(b_bics)]\n",
    "d_bics = b_bics[decreasing_values_indices(b_bics)]\n",
    "slopes = np.diff(b_bics)/(np.diff(complexities)*b_bics[:-1])\n",
    "try:\n",
    "    thres = np.percentile(np.abs(np.diff(d_bics)/(np.diff(d_complexities)*d_bics[:-1])), per)\n",
    "    thres = math.ceil(sci_format(thres)[0])*10**sci_format(thres)[1]\n",
    "except IndexError:\n",
    "    thres = 1/40\n",
    "min_thres = 1/40\n",
    "thres = max(thres, min_thres)\n",
    "print(\"threshold:\", thres)\n",
    "\n",
    "lower_bounds = []\n",
    "for k, efi in enumerate(best_subsets):\n",
    "    # assert len(efi) == np.count_nonzero(post_means[:, k:k+1])\n",
    "    com = len(efi)\n",
    "    lower_bound = 2*np.abs(log_like_value(predictions[:, k:k+1], y_pre))-np.log(len(y_pre))*com\n",
    "    lower_bounds.append(lower_bound)\n",
    "\n",
    "last_lam = np.log10(max(lower_bounds/(b_uns*scale)))\n",
    "print(\"max_lam:\", last_lam)\n",
    "delta = last_lam/tau\n",
    "now_lam = last_lam-delta\n",
    "last_ubic = UBIC(b_bics, b_uns, len(y_pre), hyp=10**last_lam, scale=scale)\n",
    "last_bc = np.argmin(last_ubic)\n",
    "bc_seq = [last_bc]\n",
    "while now_lam >= 0:\n",
    "    now_ubic = UBIC(b_bics, b_uns, len(y_pre), hyp=10**now_lam, scale=scale)\n",
    "    now_bc = np.argmin(now_ubic)\n",
    "    \n",
    "    diff_com = now_bc-last_bc\n",
    "    diff_bic = b_bics[now_bc]-b_bics[last_bc]\n",
    "    imp = np.nan\n",
    "    if diff_com != 0:\n",
    "        imp = abs(diff_bic/(b_bics[last_bc]*diff_com))\n",
    "    \n",
    "    if verbose:\n",
    "        print(min(last_bc, now_bc), '<--->', max(last_bc, now_bc), \n",
    "              np.nan_to_num(imp, nan=np.inf))\n",
    "    \n",
    "    if (diff_com > 0 and (diff_bic > 0 or imp < thres)) or \\\n",
    "        (diff_com < 0 and diff_bic > 0 and imp > thres):\n",
    "        break\n",
    "    \n",
    "    last_lam = now_lam\n",
    "    now_lam = round(last_lam-delta, 8)\n",
    "    last_ubic = now_ubic\n",
    "    last_bc = now_bc\n",
    "    if last_bc not in bc_seq:\n",
    "        bc_seq.append(last_bc)\n",
    "\n",
    "# best_bc = knee_finder(last_ubic)\n",
    "best_bc = knee(range(0, len(last_ubic)), last_ubic, 'linear')\n",
    "if best_bc == 0 and last_bc != 0 and abs((b_bics[last_bc]-b_bics[0])/(b_bics[0]*last_bc)) > thres:\n",
    "    best_bc = knee(range(1, len(last_ubic)), last_ubic[1:], 'linear')\n",
    "\n",
    "if best_bc is None:\n",
    "    best_bc = last_bc\n",
    "    alt_bc = bc_seq[-2] if len(bc_seq) > 1 else last_bc-10\n",
    "    cond = abs((b_bics[last_bc]-b_bics[last_bc-1])/b_bics[last_bc-1]) or \\\n",
    "            abs((b_bics[last_bc]-b_bics[alt_bc])/(b_bics[alt_bc]*(last_bc-alt_bc)))\n",
    "    if cond < thres: \n",
    "        best_bc = np.argmin(last_ubic[:alt_bc+1])\n",
    "    \n",
    "last_lam = round(last_lam, 8)\n",
    "last_lam, last_ubic, last_bc, best_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ea07764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD+CAYAAAAEet/LAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOlFJREFUeJzt3Xt8U/X9P/BX2gItIpwWtCCibUBBoIOmrWNMFCSV+VWg35rCig8vU0lUnBOExAo454WSAKLOfSWpc6g/7WgCMmQ6SRQmE9Q2wQvOS82hOrFMJQ2g3Gz7+f3x4aRJe9JrkpO07+fj0Uea8zmXd0J555PP+VxUjDEGQgghMZekdACEENJXUQImhBCFUAImhBCFUAImhBCFpMTqQi6XCwDg9/tRXV2N+fPnQ6PRAABEUYTD4YBarYYoitDr9RAEIWplhBASF1iMCILA3G43Y4wxq9XK1Gp1oEyj0QR+93q9TKfTRbWMEELiQcyaIOx2e6DGCyCkphpMrVYHasvRKCOEkHgRswSs1WoDv9vtdhgMBgC8aSIjIyNk34yMDHg8nqiUEUJIvIhZGzAAeDwebNq0CYWFhdDr9QB4m7Acn88XlTI5AwYMQHp6enuhhzh58iRSU1M7vX80zqH08RRD/MTQG15DosbQ0NCAU6dOdft6MU3AGo0GarUaJpMJDocDOp0u7L7hkmg0ytLS0nDppZcGnpeWlqK0tDTseebMmYNt27aFLe+Mnp5D6eMphviJoTe8hkSNYfjw4bLbRRFwuYCMDP67Tgeo1W33i2kCBnjbb0lJCQoLC9HQ0ABBENrUTH0+HwRBiEqZnNTU1B7/w3VVewk+EY6P1DmUjiEe3gd6H+MnhkhxOACjseW5wQBYrTI7xuJOn9PpZIIgBJ57vV4GgLndbub1ekN6LDDGe0w0NDREpUxOZmZml17P7Nmzu7Q/kUfvY2TQ+xg5XX0vw+WOVumH6fXyx8ekBpyRkRFyE87j8UAQhJBeERJRFJGfnx+oyUa6LBLi6ZM2kdH7GBn0PkZOpN7LjAwgLw+w23kTRGGh/H4qxmIzG5rD4Qg0CzidTpjNZqjPNIqIogir1YqCggJUV1ejrKwspJtapMtaGz58OA4dOtThazh9ugn/93+74fXWY/ToEbjzzmno3z+5R+8LISRxhcsdfj8wcybg8QB6fZjmB8QwAcezziRgo3EL1q+/F42NdYFtKSlZWLx4HSyW4ihHSAiJB5WVlaisrAw8f+utt2Rv7jscgCDw2q/B0E4S7lKDRy/VURvwsmWbGaBimZmzWUXFXlZff4xVVOxlmZmzGaBiy5ZtjlGkhJB4Ipc7vF7GjMbQ54LAH1ujGjDarwGfPt2Es84ag6FDc/D111tx+PB3UKnScO65g9HY2Izzzy/C4cP78eOPtdQcQUgfI5c7HA7+GNzL1mIBtFqg9W0vmg2tA//3f7vR2FiHRx65HykpSXjggQeQmTkEKSljMHLkfAwceB4aGw9gxYqtSodKCIkDGg1QXR267fDhtskXUKAfcKLxeusBANdeOxEAsGTJvVCppsLj2YcDB95HXd0OAMCaNTo8/3wm0tIm4/TpXFx8cS7y8yfjssvG4NJLkzBihGIvgfRm9fW8cdFgAP2RxQe1mvd6sFh4OzDA/3nkUBME+OCQyy+/XHYE3OOP78LixTNQUbEXt902pc2xNtseGAy/xE03/QGjRv2E7dv34fPP38fx4wfP7DEIWVmTcM01k3HWWbnYty8Xl146ATk5AzBuHHDxxUBaWgxeJOmdPB7e38ntlq9ikajqbA+qcCgBo2ttwCkpLa027bUBf/vtt9i373289db7+OSTffj3v/fh888/B3+7UwCMB5CLMWMm45lncjF+/GRYLENwySXAuHHAJZcAXZiegvRVlIAV1dMETE0QHejfPxmLF6/DmjU6nH9+ER56qAzXXjsR27fvxwMPlOO//92OZcscbW7AnXvuuZg16yrMmnVVYNuPP/6IDz/8EPv27cO7776P997bB1H8K6ZP55N5pKSo0dg4GUAugMk455xcfPXVeUhNVWHbNmDgQJ6cR44EVKrYvQeEkCiJRteMRNOZocjLlm1mKSlZDEDgJyUlu8dd0E6fPs0++ugj9vzzz7PFixezK66Ywc4+Wwhc45xzzmGFhYUsPd3IgEoGfMoGDWpkBQWMvfsuP8eBA4x99hljP/3Uo1Biwuv1MrPZzARBYGq1mpnN5pAh4kajkQmCwHQ6XWCoutFoZAAC+5vNZmY0GplOp2Nmsznk/G63u835vTL9f4xGIzMajcxsNjOr1crsdntge6y53W6m1WrbDJ/v5MGMAYy53Uyv1ysSf1/W1WkMWqMEzDr/Jp461cjWr9/J7rrrJbZ+/U526lRjVOJpbm5mBw4cYC+//DJ74IEH2OzZs9moUaMCSbl//7PYOef8gi1YcCez2WyspKSaASdY//6MTZjAmE7H2OYznwsnTzL2449RCbNHNBoN04cZIC+XRLRarez2cOcJt93tdjONRsOcTmfIdmnVlOCVWnpK+pBozWq1ttnmdDq7d+2gBMwYC8yxEkvSh5jVam3zgRjJY+JRTxMwNUF0Qf/+ybjnnulRv45KpUJWVhaysrJQVFQU2P7999/j/fffx/vvv499+/Zh376d+OtfN6C5uRlJSckYOvQS/PRTLt5/PxcjR07GjBmT8c476bjmGuDCC3m78tixTRg0aDfGj6/HiBEjMG3aNCQnx77/cusJ84ONHj260+cxGAwwGAywthpmFO78JSUlsFqtIXOTAHzVFOlckVJYWCg7SsrpdAbmw+4o3q7S6XSwWq1t3o9osVgsABB4PS6XS/bfo6fH9FaUgBPIsGHDoNVqQ5LH8ePH8dFHH2Hfvn2BxPzhh3Y88cRJPPEEMGpUFiZPnoyBA3Px+ecnsGPHi2hq+k/g+OTkLIwduw7TphXjkkt4kr7iCmDAACVeYXSZTCYAaJN8JVqtNjA/SSTIXcdms7VZMiuSDAZD4EMmFsrLy3HgwIHAc61Wi8LCwnav351jeitKwAlu4MCB+PnPf46f//zngW2NjY34/PPPz9SSeWJ+9901+OGHHwAAgwcPhkajwbnnnoe33voU//63Dj/8UIWNG3U4dYpPJDJgALB0KfDf/yKQmC+5BBg9GujXr2cxNzUBDQ3AF18Au3YB06YB3a2Em81mGIMnXm2Hw+EIm3wlUpKWO1Yqs1qtEEURZrMZgiDAbrcjIyMDM2fOhN/vh91uD5xLFEV4vV4AvKbndDohimKgFtg6do/HA1EUIYoiDh8+DLPZ3KnXJpFen8fjkZ1tMJJEUYTf75ed5Mrlcsm+1905pjejBNwLpaSkYPz48Rg/fjyuv/56NDU1YcyYMZgyZQoWLVqEDz744ExPjLdx6NCXAID//Gce8vMLcNFFGvz1r5ORm5uLlJQceL1p2L6dJ2UAePFFYMECwOnkyVNKzOPGAWed1XFsW7YA994L1NXx52++CWRlAevWAcUdzGnk8XjgODPOUxRFOJ1OmEymNl/nwxFFscPmjXAJQKfTwefzwW63B/bx+/04fPhwoNZcVlYWWPUF4B8OJSUlbc4tiqLsh4bP54PP5wusFDN69GjMnz+/y4l03rx5MWmGCFeTFwQh7Ooz3TmmN6MEnGCOHz+OTz/9tEvH1NTUoK6uDg8++CAuuOACXHDBBZg9ezYA4MiRI3jttdewZs0aqFTAO+/swF//akNzc3OgLfoXvxiHUaPGYuDAsUhNHQuPZwjeeAN4/vlxqK8fGLjOokXAU08BPh8fDy/1Zz7nHF6+ZQsfH3/NNU1ITW1AZuYXmDdvF157bRp0umQ4HO0nYY1GE7KMlVarhclkglqtjknNad68eW3aiB0OR6CW6vP5etSE4ff7Q16HWq2GKIpdTsCCIMBms3WYgDvb3p2Xl9fpDzmAt2eHW38xkscoSZoV7eTJkz06DyXgBPPpp58iLy+vW8fefPPN7Za/9957Ic8ZYzhw4MCZ9rrXAACPP95SrtfrMX36/2DgwMloaLgAo0bxzsmffALccQfQ3Mz3GzoUuPRSvj0vbwtqau7FoUN1+PRT4J//fBNZWVnIy1uHpUuLMXdu++v6BdNoNDCbzcjLy4PX6+0w+anV6kBzQDiiKIY9j7SIgLSeYfDc05FoO259DrmltTpis9lQWFgIm83W4Vf6aNWQu5NIEyn5Ai3rRoZbE66zKAGDr4Q6Z86cDhfjjAfjxo2D2+3u0jE1NTUwGAzYuHEjcnJy2pR/+OGH+M1vfgOr1Yr8/HzZczQ1NeGrr77CZ599FvjZvHkzbDYbAF6DmTx5Ml59lTdf1NTkIilpLGprU/DJJ8DnnwN1dVvw5Zc6qFTXApiEtLSj2L59FR5/fBW2b9eBMQd27+7a3MpS7dBqtXbYXqrT6QJNGOG4XK52a3vz58/Hpk2boNFokJ+fD4PBEGhb7k4tPFLJG+C1cakWPW/evJDmkmgIF7ff7w9b1p1jejNKwFBmUc7uGjhwYJe/kk6aNAnl5eXYvHkzbrjhBiQltQynbm5uxoMPPojs7Gzceuut7XZJKygoCHnOGMPBgweDusXtw5YtW/DYY48B4O9rTk7OmfbkSQAeQWHh1Xj66a3YsGEL1qwxYd++Kdi6dSuuvbYIr722FAcPzu3Sa5MMHTq0w33MZjMcDkfYmqHf7++wO5hOp4PJZEJhYSH0ej0EQUBhYSEEQejS13SJx+OJSOJxuFzYVF0duAFoMBgwc+bMdmu5PW2CUKvVEARB9kMkXOLvzjG9WkR6Iye4nnamTgSbN29mKpWKzZ49m+3Zs4cdPXqU7dmzh82ePZupVCq2eXPkJpVvaGhgO3fuZI899hi78cYbWU5ODlOpkhgAplKp2CWXXMJKS0uZIExggwdb2YkTjFmtexgAdu21etnFU8MNxJBGzrU+pqsDMRoaGjo9IECj0YTEIo24k7tW68EVXq83sECt1+sNjNKT21er1coO2mh1EeYEmGbcuDZFgiC0eZ2RJg2okNjt9pD3XRr52JVjEgmNhIuAvpCAGeNJOCsrdDh1dnZ2RJNvOM8+u5EBYBMm/JHdeeciVlBQwACwq6++iy1damRjxz7EALDHHlsfclxHQ5F1Ol3IUGO5ochyCb31UOQOE10Qs9kcMtpMbriz2+1mOp2OAWiTgKRrS9eU21d6DRqNJjBMWpbbzTQAa9i1SzZOuZF4kWY2m5ndbmd2u73Nh6TVapUd4dfeMYmkp7mDZkNDz2c0SiRNTU3YvXs36utjOxJu165dmDFjBoC9mD17CozGJtxyywRkZl6M9PRteOWVvQCmYufOnZg+fXrU4+k1aDY0RdF0lBHQlxKwUqS+yMOG5eC777biyy+TALwA4EYMGODGiBEPQqXaj9raWkWGRicsSsCK6mnuoCWJSEwkJydj3bp1cLu3IyenCE89tRc227UYNmwkgGtRV7cdFstaSr6kT6FeECRmiouL4XA4cO+992L79qmtStejublrXdAISXRUAyYxVVxcjC+++AI7d+7ESy+9hB07dmDUqFHIzHwXjz4KUIMY6UuoBkxiLjk5OeRGW1lZGRYtWgS//0F88slYjB+vXGyExBLVgInibrnlFpx33nkoKlpFyZf0KZSA0TIUubKyUulQ+qQBAwbAaDTC4XgRH34oImiqWELiUmVlJebMmdPjyXioGxqoG1o8OHHiBLKzs5GcPBsXX1yBnTuVjihBUDc0RVE3NNIrpKWlYenSpfj22+ewa9eXePttpSMiJPooAZO4cfvtt2PIkMFITzfj0UeVjoaQ6KMETOLGoEGDsGTJEhw79me89tpBeDxKR0RIdFECJnHlrrvuwqBBA3HxxWvQ1KR0NH2HKPKm5CiuF0pkUAImcWXw4MG455578NVXVlxwwX+VDqfPUKv5un99cE50RVECJnHn7rvvRr9+/bBkyTqsXat0NH2DKAIyCxWTKKMETGJKFAGLBUhP50vcWywtKy4DgMkEqNXpGDnybVRVvQ2j8Xt0sIwbaaUz73F6OlBSgkA7u8sFSAtSOBzAmZWmSJRRAu5jmpr4cvKVlfwx1u2sajVgNPJHrZb/HlzzMpsBvR7YvXsEBgz4AGlp69HBUm9R050kZDLxxBar68np7Htst7d0HXa7gYICnny1WsDpjEwspH2UgPuQLVuAMWOAGTOABQv445gxfHustbf02ujRwLBhw3DHHXegqemP+MtfGvD117GLTdKdJFRYCMyfH7vrtaej9ziYywVs2sSTtiDw5EyijxIw+sZQ5C1bAJ0OyMkB9u4Fjh3jjzk5fLsSSbgjS5cuhUr1E1JSnsT69bG9ts3WvR4BWi1/P2N1vUjw+1uS7sKFPA7qDREbNBsaEmtV5O5oagLuvRe49lpg61ZAWhR5yhT+vKgIWLoUmDsXiKf50DMzM3H11evwt79NxY4dTfB4kgPJ4fBhtGmaaP0VPnghX4uF1+5EkT/qdLzWx9ucAYOhpQZaWMh/l9pSAf41HuDJymbjxzid/Djpa7zHw88nigi0W0vXAICKCsjG73LJX8/hAMrL+Xa7nSd3UeTxqdWA1QpEotNCTU1Lrd1g4PHk50fgxKRjPV6VrhdItEU5v/mGMbc79EcUedmJE23LrFbGAMb27mXs00/blv/jH7z85Zfbln3+OT9vY2Po9m++6dlr0GoZC7cQbvD6mF9//TVLSfkVy8jwsX/8o2W7Ws3jkJjNjAWv7Wi38x/GGNPpWn6Xri0da7czptEw5nTybdI5nE6+vTWjkbHg9TfVasaC1/x0u/m2YE4n3xa8QHHr+MNdTzo2WMgan243/8cLPlnQ6+zMe0y67qWXXmKzZ89mQ4YM6dF5KAGzxEvAv/89/z8X/HP99bystrZtmfRz7BhjU6a03W6z8cebb25bdtVV/LxHjoRu//3ve/YaupIcdLpVDGDsvPOOMZ+v5XgpqTY08JiCE6FOxxOV18vLWp9furbT2bZc2i6XEHW60PiC42BMPgFLOTJY6+PCXY8xxgQhNL+GLJJMCVhRPc0d1ASRgAwGYM6c0G3p6fzx/PP5He1gNTX8mP37gY0bgR9/DC3/7jv+OHcu8NvfhpadfTZ/POus0POOGNGjl9Cu4C5TAHDzzTfD4fDi229fxlNPLcXKlbzN0ufj5TU1/HnwnX7pJpLNxre7XC1lXm9oG2dXBh9I5/X7+Tl8vpY42tP6GsHxd0Sv5zfINJrQ7mI90fo9JsqIWQL2eDxwnflfUF1djYqKCghn/seIogiHwwG1Wg1RFKHX66NaluhGjAifAFNT285KOGkSb0tctSq0DRgAmpt5G3B2NjB7dvg24OTkyM52KLXHdsaIESNw9tnfoqlpLdavX4TFi9NCyttLJtLoruCk1TqBdebPQmo79nj4e1lYCMybF72RY9L1AN4+O3MmbzMWxc4n4K68x0QZMUvALpcLxjN3MiwWC2bOnAn3mSpVSUlJ4HdRFLFw4ULYz1Q1olHW1yQnA+vW8RtPRUVAWRkwcSKvEZeXA9u38xs+sbwBV1jYcnOqMwQhHd988z1OnqzAhg13h5RpNPJJ2O/nZeXl8mVd+Tz2eHi3rpkzgTfeaPkwkq4bnDAjweNpOZ9Gw6/tcLTftay1rr7HJPZi0g3N4/GgPOh/gU6ng8fjgSiKEFt9RKvV6kBNORplfVVxMf8P/NFHwNSpwODB/HH/fr69OMYLEut0PMG07rlgsYT2XpD069cP119/PVJTLaipORWScKVeDVIPAoAnxqoqXlvMz+evMVhVVfvxBdceRZEnQVFsSeoSqRmhqzO3tf7AkLteMIOBdxHrShe3rr7HJPZiUgPWaDSoqKgIPPef+evLyMhAVVUVMlp9rGdkZMDj8aCmpibiZZo+vGpAcTFv5929G6iv580Y06Yp1/XM6eTJwGQChg7l23S60Jqp9JVfFIHi4rU4cSITp0/vQ03NFPh8vEao0/G2WZOppbuZz9eSZJxOXibtD/Ayl6vla73F0pKwAP6o1/PjRo9uOZfRyLcVFvLn0nXnzw+N1WLh+8pts1h4u3Vw/OGuJ9HpgOrq6LzHRDkxa4LQBX10b9q0CVqtFoIgBJJxaz6fLyplfV1yMhC0ILHipP614Wg0waOyzsHXX8/Hnj3z8eKLtdBq+6N//5Z92xuyLFem1bbfnip3jNy24Jat1q1cofFzRqP8624v/owMXgvujo7eY6KcmI+E8/v9cDgcHbbHhkui0SiTRsJJP715RFyiW758Ob766itcc80LePFFpaOJruA/V6k5hfQuMe+GZjKZ4HQ6Az0SBEFoUzP1+XwQBCEqZXJ6+0i43mTixIkoLi7GP/6xCqtW3YQbb0yJq9F7kWQy8UnS9fqu3Xwj8cHlCr05K/cBGtMasMVigclkglqtht/vh9/vhzbMx3p+fn5UykjiW7FiBY4fF/HFF5W9etIYqcnBZuve/BJEOS4Xb3rS61uGusuJWQ3Y4XBAo9EEkm9VVZVs31xRFJGfnx+oyUa6jCS+3NxczJ49G2+++SgefXQB5s1LDunb3FtoNLTSfKIyGFoGLknzhsiJSQIWRRElrSZJFQQB+jO3eu12O0wmEwoKClBdXR3SPhyNMpL4Vq5ciVdeuRQ5OQ40Ns4PuRlHiJKkEZKC0NKfO1wfcRVjjMU0ujg0fPhwHDp0SOkwSBf96le/wsGDB/HBBx8gqTdWgTvD4+ENxW43VZcVIJc7HA7efm8283ZfafY8uWYkmguCJKyVK1fisssuQ1HRVtxzTzGuvFLpiEhvV1lZGdJL6uTJk2328flahowLAm8HTk/n01i1RjVgUA04kV155ZV4910/8vLceOstldLhxB7VgBUllztcLr4sVUNDyzaVSv6fqI9+byO9xcqVK3H8+D7s3v13/Otf0b2WKPJcRxPckPZ0ZU4QSsAkoU2fPh2XXXYZ0tIexiOPRPfLnFrdMrsaIeGo1Xz+kdYTNcl9QaEETBKaSqXCypUrceLEe3j9dSdqa6N3LVGkORRI50hzhNhs/GZcuG5olIDRNxbljBeiyP8w09Pbrszb2ujRfD+Tqf05fwsLC1FQcCkmT34IY8Z0rhYsTY4jxWGxhF5DirGkpGWms+DJ0B2OyC0jT3ofQeBr9un1Z9buC/etKQKrciS8RFuSqDcwm9sutRPM6eTL/7ReUsdo5Ntbe+WVVxgA5nK9yY4c6XwcGk34ZXuC15hjjO8nrTXX0CAfR8y1syQRib6e5g6qAfcxTU3Arl1AZSV/bGpSJg5B4CtKWK3y5eFqvIWFLSv4BrvmmmuQm5uL+fMfxh13dD6O9uZYaF1Dd7n40kBqdcsy7oT0BCXgPmTLFiArC5gxA1iwgD9mZfHtSjAY5CdGb+9Gl1Yr36FdpVJhxYoVOHx4Jyor38YXX0Q01MAKGnY7nxhdWl6ekJ6gBNxHbNnCE9fXX4duP3iQb1ciCQcvtROspkb+jrHHw2vAwTVTl4t3DcvLAy64oAjnn78YSUmf4LrrIhtrTU1Lzdtg4NelhS1JT1EC7gOamoDf/U5+JI607Z57lGmO0On41/pg4RKbRtN20nKtlm/z+wG/Pwlr1/4cTU0L8eGHJ/Hqq5GLU6ttmdhcr+c/NO6B9BQl4D5g9+62Nd9gjAH/+Q/fL9YMBl4DDu4z2dXElpHRMvRTp9PhoovGIjn5024t4UNILFEC7gPq6yO7XyRJHdSltuDg1YC7eh4ASE5OxsqVy9HUVIuffvqqR7FREwOJNkrAfcCIEZHdL9IMhpbeEJEY6FBaWoqzzhqErVtfxdat7e8bvBoxIZ1VWVmJOXPmyE7G0xWUgPuAadOA88/nE4LIUamAUaP4fkqYN4/XfB0OPoSzp1JSUjBu3Dh8/LEHCxbsR3trsRYWUgImXVdaWopt27YhNTW1R+ehBNwHJCcDTzzBf2+dhKXnjz8e2+Xpvd6W3wWBt99u2hS5ob5DhlwIQRiKU6cexR//GH4/aUn41qPaLJa2S8MTEmmUgNE3hiIXF/Ma5siRodvPP59vLy6OTRyiyJscLBb+KNU+DYaWbl5+Py93ufiPNEzY4wHKy1uGEQPy2ywWwONJwtlnL0FzcyMee+wzHDsWPiank5/fZOLHWiw8MdO8DyTaaD5g9K35gJuaeG+H+nre5jttWmxrvrF06tQpZGWNxn//OxOrVz8X6EbWq9B8wIrqae6gGnAfk5wMTJ8OlJbyx96afAFgwIABKCszQqV6ET/7mbfjAwiJMUrApFdbuHAhzjlnGByOcqVDIaQNSsCkV0tLS8PSpUuxceNzmDr1S5w+rXREhLSQTcD33XcfLrroIlx00UWYNWsW3nzzzUDZgQMHUFFRgS1KzeBCSBfdfvvtGDxYwN69ZrzwgtLRENJCNgGvXr0aubm52LBhA15//XVcGbTcbHZ2NhYuXIiZM2di7dq1MQuUkO4aNGgQli1bgqSkP+Phhw+isVHpiAjhZBPwli1bYDabMXPmzLAHDhkyBAsXLsQzzzwTteAIiZRFixZh0KCz8OWXa2SnwCRECbIJ2OfzITs7u8ODhwwZAurFRhLB4MGDsWTJ75CUZMWzz/aNLock/skmYH8XZiE5cuRIpGIhJKruvvtuDBzYD5MmrVM6FEIAhEnAhw8f7vQJurJvvOoLI+EIkJ6ejrvv/i2s1qfhdn8vOz8yIZ0R1cl4GGMhPR/CefPNN3tFE0Rqaiq2bduG0tJSpUMhUbZ48WI0NwP5+euxY4fS0ZBEFdXJeFavXg2j0YidO3eGPfCNN96AyWTC6tWrexQAIbE0bNgwLFp0J5KS/ogHH2xQOhzSx6WEK7DZbJg3bx5UKhW0Wi1Gn1mIy+v1wuVyAQCq6HYySUBLl96LJ598Cu+88yTeeuv3uPxypSMifVXYkXAajQZffPEFiouL4XQ6YTQaYTQa4XQ6cd1116G2tha5ubmxjJWQiMjMzMTtt+uRlPQ4/vCHo0qHQ/owmg0NfWs2NMIdPHgQWVlqTJr0e+zdez/69VM6om6i2dAUFZXZ0Orq6jp9gqNHqQZBEs/IkSOxcOGtqKt7DKdO/aB0OKSPkk3ADoej0yewtV5KgJAEYTKZcOTIEdx44wZ8/LHS0ZC+SPYm3IYNG+D1dm7+VJfLhaVLl0Y0KEJi4cILL8SNN96MjRvXIiVlEaqq0pQOifQxsgnY5/OhuroaGRkZ7R7s8/nga2/FQ0Li3PLlZdi48S9wOCpQW3s3LrpI6YhIXyKbgMvKyrBs2bJOnWDNmjURDYiQWFKr1SgtvR6VlWY88ogezz3Xs471hHSFbBuwVqvt9Am6sm+8oqHIfdvKlfeDsXr8v//3F/znP0pHQ/oS6oYG6oZGgJKSUuzatQdffVWLtLT+SofTedQNTVExX5Szrq4OZWVlWLduHXVBI73G73+/HN9//xVeeukFmqSHxEzYBHzHHXcgOTkZycnJuP/++wHw+R/UajXMZjOWLVuG7OzsLvUZJiReTZw4Eddddx3uuWcVTCZaMoO0L6qzoa1ZswbV1dXYsGEDnn76aVRVVeGZZ56B2WyG2+1Gc3Mzmpubcdttt8FkMvUoAELixYoVK/DDDyKefLIS1LmHtCdSs6HJ9oKoqalBTU1N4Ller8dVV10Fi8WCyZMnB7abzWbMmzevUxfyeDxYuHAh3G53yHZRFOFwOKBWqyGKIvR6PQRBiFoZIeFMnjwZs2bNxo4dj+LxxxfgoYeSlQ6J9HZMhslkarPNYrHI7Sq7b2t2u5253W4mdzmNRhP43ev1Mp1OF9UyOZmZmR2+BtI3vPfeewwAGziwkh05onQ0neB2MwbwRxJzPc0dsk0QQ4cObbNNrVbLJnC5fVvT6XTQyNyhFUWxzTWkqS6jUUZIRwoKCnDFFbNw8uQj2LOnWelwSC8nm4BVKlWntrW3vTNcLleb0XYZGRnweDxRKSOkMx59dCWamz/G8eNblQ6F9HKybcBWq7XNWm8ejwfV1dVt9nU4HN2eCyLc4p8+ny8qZYR0xi9/+UtceeWVeOihR5Cd/b/Ize1+JYOQ9sgmYK/X2+ZmGQDZba2/8kdCe6syR6OMkNZWrlyJGTNmQKv9O7755loMGKB0RKQ3kk3ARqOx02u93Xfffd2+uCAIbWqmPp8PgiBEpSwcaSiypLS0lBbo7OOuuOIKaDSXweN5GM89dw30eqoFk+4xmYCyMkA2BcndmRNFsdN38bqyb+vLeb3ekB4LjDEmCAJraGiISlk41AuCyHn99dcZADZ8+D/YTz8pHU0Y1AtCUR3lDumfJ1z6kb0Jd+TIkU5n9+zs7C59GgQ3BbTuWSGKIvLz8yEIQlTKCOmKwsJCTJx4KQ4dehiVlTQ+mXSdKAJhOpABCNMEUV5ejk2bNkUsCJfLBafTGTh3QUEBdDodAMBut8NkMqGgoADV1dWw2+2B46JRRkhnqVQqlJevxOzZs/Hdd7sAzFA6JJJAHA5Ap+NNEOHIzoaWkZEBg8GA0aNHgzEW6GrGGAvUYFUqFfR6PQYPHhyV4GOJZkMj4TDGkJeXB0EQ8OabbyodTls0G5qiwuUOvx+oqQG0WmD0aP7PI/clXLYGrNfrUV5e3uHF16xZg5KSEmRlZXUxbEISg0qlwsqVK1FcXAyd7m3Y7b9ED7q+kwRXWVkZMm94uMl4qqoAvb7j8/V4PuC1a9cm/JpwVAMm7WlubsaYMZNw4MBIvPrqP3D11UpHFIRqwIqSyx0uF5Cf31Ljba8G3OX5gAnpa5KSkrBq1QoAr8Nkeo/mCyYdqqoCbDb+I4pAeTn/rGxNtgni6NGjnW7bbT1ijpDeqKREh6VLx+Kjjx7GP//5CqZPVzoiEq9ar9JmMPAfud4QsjVgm83WqQs988wzHa6cTEhvkJycjFWrlgPYjgce2Kd0OCQB+P2AxcJ/N5vla8CybcBjxoxBYWFh2BOLoghRFKFWq/H6669HKl7FCIKAyy+/nEbAkXY1NjZCrR6Hn/1sErZv36x0OBy1ASuqp/ePZJsgfD4fqqurw9Zu1Wo19Ho9rrvuum5fOJ6kpqZi27ZtSodB4lxKSgoefPB+3Hrrraip2Y/8/IlKh0QSnGwCLisrw7Jly2IdCyFx74YbbsCKFQ9h6tRHUVNTiZ/9TOmISCKTbQOWRqkRQkL169cPy5ffh59+2oT77vtU6XBIgpNNwF2d34GQvuS2234DQTgPr722Cp99pnQ0JJFRP2BCumjAgAFYscII4CXcf79X6XBIAqMETEg33HnnQpx99jC88045mpqUjoYkKkrAhHRDWloaHnhgGb799jl8/fWXSodDEhQlYEK66Y47bocgCPjtb82or1c6GpKIKAET0k1nnXUWFi1aglde+TMefPCg0uGQGKqsrMScOXPCzobWWT2eDa03oNnQSHcdPXoUmZlZaGy8AfX1T2DYsBgHQCPhFNXT3EE1YLQsyhk8zychnTF48GDcfffv0Nhow6OP0oc46RqqAYNqwKRnGhoaMHz4hQAM+PbbNRgyJIYXpxqwoqgGTIjC0tPTcfvtdwN4Gg0N3ysdDkkglIAJiYCVK+9Bv35ARcV6pUMhCYQSMCERMGzYMNxxx51Yu/aPWL/ep3Q4JEFQAiYkQpYuvRdNTY144IEnceqU0tGQREAJmJAIyczMxPXX6/HDD09gw4ajSodDEgAlYEIiaNWqZUhKOo4//OEpNDYqHQ2Jd5SACYmgkSNH4rrrbkVDw2P4+99/UDocEucoARMSYWvX3od+/Y6itnaD0qGQOEcJmJAIu+CCC3DTTTdhzZo1qKs7rnQ4JI5RAgYNRSaRV1ZWhu++O4zLLqsAjTXtfWgyngiiocgkGmbNugk7drjw8steFBWlRuciNBRZUTQUmZA49cQT9wOox5Ilf6FaMJFFCZiQKBk3biwuv3w+DhxYDafztNLhkDhECZiQKPrTn1YA+Apbt76gdCgkDlECJiSKJk6cgOuuuw6vv74KjTQyg7RCCZiQKFuxYgVEUcTChS8pHQqJM5SACYmyyZMnIzd3NjZufBQeD61hT1pQAiYkBv70p5UAPseiRXalQyFxhBIwITHwi18UYPz4WXjnnUfw7383Kx0OiROUgEEj4Uhs/OlPDwD4GIsWbVU6FBInUpQOIB6kpqZi27ZtSodBernp06di0qQrUV//MBj7X6hUKqVDIgqjGjAhMfT44yvx2WfvY/v27UqHQuIAJWBCYuiKK66ARnMZfv3rh/H11zQ+OVFFajIeSsCExJBKpcKKFStx/Hg17r57h9LhkG4qLS3Ftm3bkJras0mWKAETEmNFRYU477xL8be/PYzvvqNacF/WaxOwKIqwWCxwOBywWCzw+/1Kh0QIAF4LXrv2ATQ3v43Fi3cpHQ5RUK/tBVFSUgK32w0AZ4aBLoTdTp3gSXz49a//B4sXa7B160Nobp6BpF5bFSLt6ZX/7KIohjxXq9VwuVwKRUNIWyqVCo89tgI//rgLe/b8S+lwiEJ6ZQJ2uVzIyMgI2ZaRkQGPx6NQRIS09etfz8XEiRNx//0P48cflY6GKKFXJuBw7b0+ny+2gRDSjqSkJNxzzwrs3r0Dy5e/p3Q4RAG9MgGHEy4xS0ORpR8akkxi5eabdRgyZCw2bHgYPexSSuKIxwNYLPynpAQI1wegV96EEwShTW3X5/NBEATZ/WkoMlFKcnIyli9fAaPxBjz00D6sWpWrdEgkAlwuwGjkv1sswMyZfN3U1nplDVir1cpuz8/Pj3EkhHRs8eJfY9Cg0Xj88Yfx009KR0N6yuMBystbnut0fFurvgEAemkCVqvVIc9FUUR+fn7YGjAhSkpJScHSpffjxImX8d57HykdDukhjQaoqGh5LjU/tOoXAKCXJmAAsNvtMJlMcDgcsFqt1AeYxLX7778BF154If74x0eVDoVEgE7X8vumTYBWC8jV/1SMsT4/FnL48OE4dOiQ0mGQPu7ppzdg0aI7YbX+GwsXjuvcQR4PkJfHGxg1mugGSNroKHf4/S3/PHIJuNfWgAlJNLfc8hv0738eTKZVoGpRfJJmQZN+OpoNzWQCnE755AtQAiYkbgwYMAB6vRENDS+houILpcMhMqRZ0KSf9mZDs1h4AlareU1YrisaJWBC4sjq1QvRr98wrFhRTrXgBOZw8BYhKflWVVETBCFxb+DANNx00zJ8993z2LSpTulw+oymJmDXLqCykj82NXX/XKLIB18UFgIqFZCezmvCcigBExJn1q+/HYMHC9i506x0KH3Cli3AmDHAjBnAggX8ccwYvr071GqAsdCfhgb5fSkBg1ZFJvFl0KCzcN99S7Bx47P48suDSofTq23ZwruM5eQAe/cCx47xx5wcvr27SbizqBsaqBsaiT9Hjx5FZmYWhg+/AQcOPBF+R+qG1m1NTbymm5MDbN2KkDmZm5uBoiJg/36gthZITpY/R09zB9WACYlDgwcPxv/8z+9QV2fDjh1UOYiG3buBujrg3nuBd97hzyVJSUBZGXDgQOj2SKMETEic2rDhbqhU/XHXXWuVDqXXYIwnXcaA+nq+TasFfvlL4OGHQ/edOJE/SvtFAyVgQuLUOeek4+qrf4va2qfx9tvfKR1OQmIM+Oc/AbOZNymMGAFkZwNeL/8dAH73O96C8/e/hx67fz9/lPaLBkrAhMQxm+0eqFQqlJevVzqUuMcY8MUXwAsvhNZmS0uBRx4BfvgBuO024JVXeFKdNg3IygI+/xyYPBno16/lmOZmPqNZdjbfL1p65XzAhPQWI0cOw+LFd6Ki4in4fEvbLLXVlzU18Ztj9fXAwoW8HffwYV42fjzve9u/P98+cqT8jbR163hvh6Ii3uY7cSKv+ZaXA9u38wEV4W7ARQLVgAmJc0bjvWhsbMTixU8qHYpimpuBTz4Bnn0W0OuBn/0MuOYaXpaRwcvvugt47TXA5wM+/pgnXwC44ILwSbS4mCfZjz4Cpk4FBg/mj/v38+3FxdF9XVQDJiTOZWZmIj9fj+effwL33bcYl1wyROmQoq6hAXjvPZ5cCwqAbduA//1fPrJswgTgF7/gAyYAYMAA4NVXu3+t4mJg7lze26G+vqV5or2ab2VlJSorKzucjKcj1A8Y1A+YxL/PPvsG48apMXXqSrz99vKWgl7UD3jXLuD553mTwSef8G16PWC18vkUamp4Mh4SR58/1A84AmgkHIl3Y8eeh/z8W7Fnz3ocOPCD0uH0yPff8/bVFSv4WmlS7bW2Fti3D5g+HXjuOX5zbMMGXiYIvLtYPCXfSKAmCNCinCQxPPOMCZMnV+DWW5/Gm28uUzqcTmls5O2rEybwNtmbb+bJFQDOPZc3JQwcyJ8vXMh/+hJKwIQkiEmTLsDUqTdh3761OH58EQZKmSvObNsG7NnD51SoqQGOH+e/T5nCZwm76iqeeLOyeJtuX0ZNEIQkkBdeKMOxY4dREbzqo0JOn+Y3yp54AjAYEJi/ePly3hf3nHOAhx4C/vUv3s8W4D0XFizg/Wv7evIFqAZMSEJRq9WYM+d6lJVZcP31BgyL4bWPHQPOPpv3ULj2Wn7f79Qp3rSQl8fLBw8G3n6bP5KOUQ2YkATz29/ejxMnDsFg+EvUrnHqFG9GeOwx3mwwahS/OQbwG2JjxwKrV/MeC0eP8n2lpEvJt/OoBkxIgpkxYyzU6vl4+eVVeLi5DCsBrDbX4HcbJyEtrevDthgDvvySt9NmZACzZgHvvgtccQWQlsa7fi1YwCesAXjTwbPPRvY1Ka2pqQm7d+9GfX09RowYgWnTpiE5mkPgJIywzMxMpUMgpEumTFnPALDcM4su5AIMyGJz527u9DneeIOxuXMZy8xsWbvhllt42YkTjLndjJ0+HZ3448nmzZtZVlYWAxD4ycrKYps3d/xe9jR3UBMEIQmmqGgL3nlnCYARQKAVeCOAHPztbzoUFbUs4xA8Qc2iRbytduNGXnbsGG8+uPVW3nPh22+BP/+Zl6Wm8nEdwRPU9EZbtmyBTqdDTk4O9u7di2PHjmHv3r3IycmBTqfDligviUEj4UAj4UjiOHGiCQMHjgGQA+BB5CIPHgAauLEPkwEUAdiPQ4dqkZmZjFtvbWkuGDeOdwW7+WbevNDXNTU1YcyYMcjJycHWrVuRFLQkRnNzM4qKirB//37U1taGbY7oae6gNmBCEsiyZbsB1AGoBKABMA3AbgB/B/AxgMkAXsGsWSuwZMklGDmSr/iQnc0waBA/R10dcOBAaL2rdT2sp8+jcc5Ix1BbW4u6ujrMnTsXTz7JJzoqLCzEhAkTkJSUhLKyMkydOhW7d+/GdOkOZIRRAkbLUOTS0lKUlpYqHQ4hYdXWSssz8OUa6rEcD2IO6vFAyH4ffLAaN90U4+CCqII6+apadfiNl+eNjY0AgGeeeSawLSMjAxMmTAAATDyzJEa9zJIYkZqMhxIwaCgySRwXXTQCO3YAwH4AU3AIs/AH/ACg+cwe7wCYjttv34EnnmhpZ4h2UktEu3btwowZM+ByuTBlypQ25fvPLIkxQmZJDKmyNnz48B7FQG3AoDZgkjhC24C3IrQrfzOkNuDjx2u71SWtL4mHNmDqBUFIAklLS8bcuesAbAdPtnsBHDvzWARgO+bOXUvJtxOSk5Oxbt06bN++HUVFRSG9IIqKirB9+3asXbs2uv2Be9SJrZegfsAk0cydu5kBoX1Xgewu9QMmnFw/4Ozs7Jj0A6YmCFATBElMJ040Ydmy3aitrcdFF43AmjXTqObbTd0dCUdNEAqgidsjg97HnklLS8ZTT03HzTcDTz01nZJvDyQnJwe6mk2fPj02w5BBCbhbKHFEBr2PkUHvY+TE+r2kBKyQnv5DK318pM6hdAzx8D7Q+xg/McQaJWCFKP3HFg//YSKhN7wP9D7GTwyxRjfhAAwYMADp6emd3v/kyZNITU3t0TV7eg6lj6cY4ieG3vAaEjWGhoYGnDp1qtvXowRMCCEKoSYIQghRCCVgQghRCCXgLvB4PMjLy1M6jITn8XhgsVhgsVhQUlICv9+vdEgJyeVyweVyweFwwGQywePxKB1SwjOZTDH9e6QE3EkOhwMA6I88AlwuF4xGI4xGIwoKCjBz5kylQ0pIJSUlyMjIgE6nw+jRo1FSUqJ0SAlNqhjEEiXgTtLpdNBoNEqHkfA8Hg/Ky8sDz3U6HTweD0RRVDCqxGS320P+JgVBUC6YXkAURajV6phekxIwiSmNRoOKiorAc+nrXkZGhkIRJS6tVhv43W63w2AwKBhNYnM4HNDpdDG/Lk3ITmIu+A9906ZN0Gq1VHvrJo/Hg02bNqGwsBB6vV7pcBKS3+9X7O+PasBEMX6/Hw6HA3a7XelQEpZGo0FZWRm8Xm/gPgXpmqqqqpBvE7FECZgoxmQywel0Uu23hwRBQElJCfUo6QaXy4V58+Ypdn1KwEQRFosFJpMJarUafr+fEkcXuVyukOHz0s0jupnZdVVVVbDZbLDZbBBFEeXl5THr7URtwN2gZJtRb+BwOKDRaALJt6qqitovuygjIyPka7PH44EgCNRTp4taNz0YDAYYDIaY9YagBNxJLpcLTqcTAFBeXo6CggJF7pomOlEU2/RXFQSBEnAXaTQazJ8/HzabDQDgdDrhdrsVjipx+f3+wHtpNpthMBhi8mFGk/EQQohCqA2YEEIUQgmYEEIUQgmYEEIUQgmYEEIUQgmYEEIUQgmYEEIUQv2AiSKC5109fPgwDAYDHA4HjEajglEREluUgEnMSaONgju6J+pk4jabLSKDSEwmE0RRpImJ+hhqgiAxV1VV1WaUUfAcwYlEGh3ZU4WFhZg/f35EzkUSB9WAScz5/f42qw8IgoCCggIFo+o6afKWSFBqOkSiLBqKTGIuLy8Pfr8fVqtVNvF4PJ7AV3Kv1wuAf0W32Wwwm83Q6/VwuVwwmUzIyMgINF/4/X4cPnwYZrMZADq1j8RisYTMKCa1RUvnUKvVMBgMgRpvYWEhrFYrXC4XysrKAKBT7dc2my0wCZEoihAEAfn5+W1eryiKyMvLQ1lZGdRqNXw+X+D60nsmxSx9mNHcJAmIERJjXq+XqdVqBoABYFqtljmdzpB9nE4nU6vVIdu0Wi2zWq2B53a7nQFgXq83sM1oNDK9Xt+lfXQ6Xcj1vV4v02q1IefQaDTM6XQyt9vNjEZjIEaNRtPp122320Pi93q9gedutzvk9brd7pCYjEYj0+l0ITHb7fbAc61Wy9xud6djIfGBEjBRjNPpZEajkWk0GgYgJKG0TkiM8aQTnMDkEmBDQ0NIwu1oH7fbzQRBaBOblHClc8jVVbqTgLVaLWtoaAh5nXKv1+l0BvaTYpSee73eNvFYrdaQDxWSGOgmHFGMVquF2WyG2+2G0WjEwoULe3xOQRAgCEK7E2oH71NTUyM796tarQ65wRaJ+WGlJoL09HTk5eXBYrGEnfIweJ28kpISmM3mwHOXywVBEOByuQI/Xq+XJmNPQHQTjsSU3++Hy+Vq015pNpthsVjanew+GqtmdPacnZmAvzPLmjudTng8HrhcLlitVgDttx1L7bxSVzdRFOH3+6FWq0Paz+kmXmKiGjCJuerqatntarW63UTn8/k6PLe0vFF7k2kH76PVamVrjqIodrlXRkfL2EgTfms0GhiNRrjdbmzatCns/qIowmQyBRI1wGu/Go1GNmZa1inxUAImMWez2eByuUK2ta4VS3f3JVKvgdZJxuPxhGwrLy+HXq8PqYm2t4+UhIPjkRJpR70KgmMURbHDFRSCV10IPkc4UtODtI/H4wksRZSfn99mFeSqqqp2r0/iDzVBkJiTuoAFD0cO3g7wr/xSs4SUgLRaLaxWa0iXK41GE2gT9Xg8GDp0aJsuZh3tY7fbA93AAMDr9QaW93G5XDCbzRBFERaLBTqdLhCP1DRgMpkwevToDkfESbV7KXGKooiKigp4PB6Ul5cHrmE0GmGz2eDxeAJDtKXFIqWRck6nEyaTCT6fDxkZGQBAyzolIOoHTBKW1Ee3vbXQOrMPIUqhJghCCFEIJWBCCFEIJWCSkKS2WY/H06YtuSv7EKIkagMmhBCFUA2YEEIUQgmYEEIUQgmYEEIUQgmYEEIU8v8Bk3LHP/g3RX8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 350x262.5 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "complexity_axis = [len(bs) for bs in best_subsets]\n",
    "with plt.style.context(['science']):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax2 = ax.twinx()\n",
    "    ax.set_zorder(ax2.get_zorder()+1)\n",
    "    ax.patch.set_visible(False)\n",
    "    \n",
    "    l1, = ax.plot(complexity_axis, last_ubic, 'o-', c='black', markerfacecolor='none', label=f\"$\\lambda = {abs(last_lam)}$\")\n",
    "    ax.set_xticks(complexity_axis)\n",
    "    ax.set_ylabel(\"$\\\\textrm{UBIC}$\", fontsize=12)\n",
    "    ax.set_xlabel(\"Support size\", fontsize=12)\n",
    "    ax.vlines(best_bc+1, min(last_ubic), max(last_ubic), color='red')\n",
    "    \n",
    "    l2, = ax2.plot(complexity_axis, b_uns, 'o--', c='blue', markerfacecolor='none', label=\"Uncertainty $\\\\textrm{U}^{k}$\")\n",
    "    s1 = ax2.scatter(complexity_axis[np.argmin(b_uns)], b_uns[np.argmin(b_uns)], c='blue')\n",
    "    ax2.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "    ax.legend([l1, l2, s1], [f\"UBIC with $\\lambda = {round(abs(last_lam), 2)}$\", \"Uncertainty $\\\\textrm{U}^{k}$\", \"Min $\\\\textrm{U}^{k}$\"], \n",
    "              labelcolor='linecolor', loc='upper center', fontsize=12)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa3a233a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.239427589457429"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some ideas\n",
    "# Better knee detection algorithm\n",
    "\n",
    "import kneeliverse.kneedle as kneedle\n",
    "import kneeliverse.lmethod as lmethod\n",
    "import kneeliverse.menger as menger\n",
    "import kneeliverse.zmethod as zmethod\n",
    "\n",
    "print(kneedle.knee(np.vstack([range(0, len(last_ubic)), \n",
    "                              last_ubic]).T, t=0.1))\n",
    "\n",
    "print(lmethod.knee(np.vstack([range(0, len(last_ubic)), \n",
    "                              last_ubic]).T))\n",
    "\n",
    "print(menger.knee(np.vstack([range(0, len(last_ubic)), \n",
    "                             last_ubic]).T))\n",
    "\n",
    "print(knee_finder(last_ubic))\n",
    "\n",
    "abs((b_bics[2]-b_bics[1])/(b_bics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ffc512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e1ff74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pysr_latest]",
   "language": "python",
   "name": "conda-env-pysr_latest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
