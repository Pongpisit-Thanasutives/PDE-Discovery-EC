{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8401bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from functools import partial\n",
    "from decimal import Decimal\n",
    "import numpy as np\n",
    "from sklearnex import patch_sklearn; patch_sklearn()\n",
    "import scipy.io as sio\n",
    "import pysindy as ps\n",
    "from tqdm import trange\n",
    "\n",
    "# NSGA2, DNSGA2, SMSEMOA, AGEMOEA2\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.algorithms.moo.dnsga2 import DNSGA2\n",
    "from pymoo.algorithms.moo.sms import SMSEMOA\n",
    "from pymoo.algorithms.moo.age2 import AGEMOEA2\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from pymoo.core.sampling import Sampling\n",
    "from pymoo.core.crossover import Crossover\n",
    "from pymoo.core.mutation import Mutation\n",
    "from pymoo.core.duplicate import ElementwiseDuplicateElimination\n",
    "from pymoo.termination.default import DefaultMultiObjectiveTermination\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.visualization.scatter import Scatter\n",
    "\n",
    "from utils import *\n",
    "from skimage.restoration import estimate_sigma\n",
    "import bm3d\n",
    "from okridge.solvel0 import *\n",
    "from best_subset import backward_refinement, brute_force_all_subsets\n",
    "from UBIC import *\n",
    "from kneed import KneeLocator\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5916f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_poly = 4\n",
    "n_derivatives = 5\n",
    "n_modules = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eaa96d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['KdV_sine_rep_big.mat', 'kuramoto_sivishinky.mat', 'KdV_rudy.mat', 'burgers.mat']\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../PDE-Discovery-EC/Datasets/\"\n",
    "print(os.listdir(data_path))\n",
    "data = sio.loadmat(os.path.join(data_path, \"kuramoto_sivishinky.mat\"))\n",
    "u_clean = (data['uu']).real; u = u_clean.copy()\n",
    "x = data['x'].ravel()\n",
    "t = data['tt'].ravel()\n",
    "dt = t[1]-t[0]; dx = x[2]-x[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1e0adc",
   "metadata": {},
   "source": [
    "### Add noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "888ee41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise level: 50.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "noise_lv = float(50)\n",
    "print(\"Noise level:\", noise_lv)\n",
    "noise = 0.01*np.abs(noise_lv)*(u.std())*np.random.randn(u.shape[0],u.shape[1])\n",
    "u = u + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f675560",
   "metadata": {},
   "source": [
    "### Gaussian process\n",
    "    - removing entries in x that show high std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3b809d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|█████████████████████████████████████| 25/25 [00:08<00:00,  3.01it/s, 7 steps of size 4.83e-02. acc. prob=0.95]\n",
      "sample: 100%|█████████████████████████████████████| 25/25 [00:07<00:00,  3.55it/s, 7 steps of size 4.83e-02. acc. prob=0.94]\n",
      "sample: 100%|█████████████████████████████████████| 25/25 [00:08<00:00,  2.99it/s, 7 steps of size 4.83e-02. acc. prob=0.95]\n",
      "sample: 100%|█████████████████████████████████████| 25/25 [00:07<00:00,  3.17it/s, 7 steps of size 4.83e-02. acc. prob=0.95]\n",
      "sample: 100%|█████████████████████████████████████| 25/25 [00:12<00:00,  1.99it/s, 7 steps of size 4.83e-02. acc. prob=0.97]\n",
      "sample: 100%|█████████████████████████████████████| 25/25 [00:08<00:00,  2.80it/s, 7 steps of size 4.83e-02. acc. prob=0.93]\n",
      "sample: 100%|█████████████████████████████████████| 25/25 [00:07<00:00,  3.38it/s, 7 steps of size 4.83e-02. acc. prob=0.90]\n",
      "sample: 100%|█████████████████████████████████████| 25/25 [00:09<00:00,  2.72it/s, 7 steps of size 4.83e-02. acc. prob=0.94]\n",
      "sample: 100%|████████████████████████████████████| 25/25 [00:18<00:00,  1.36it/s, 23 steps of size 4.83e-02. acc. prob=0.96]\n",
      "sample: 100%|█████████████████████████████████████| 25/25 [00:09<00:00,  2.70it/s, 7 steps of size 4.83e-02. acc. prob=0.94]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5564682458512834, 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gpax\n",
    "\n",
    "n_sampled_t = 10\n",
    "xx = colvec(x)\n",
    "u_std = np.ones((u.shape[0], n_sampled_t))\n",
    "for i in range(n_sampled_t):\n",
    "    rng_key_train, rng_key_predict = gpax.utils.get_keys()\n",
    "\n",
    "    gp_model = gpax.ExactGP(1, kernel='RBF')\n",
    "    gp_model.fit(rng_key_train, xx, u[:, np.random.choice(len(t))], \n",
    "                 num_warmup=5, num_samples=20, jitter=0.0, \n",
    "                 chain_method='parallel', print_summary=False)\n",
    "\n",
    "    posterior_mean, f_samples = gp_model.predict(rng_key_predict, xx)\n",
    "    u_std[:, i] = np.std(f_samples[:, 0, :], axis=0)\n",
    "\n",
    "cutoff_ws = 0\n",
    "est_sigma = u_std.mean() # max also works well\n",
    "est_sigma, cutoff_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9754901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_sampled_t = 10\n",
    "\n",
    "# kernel = RBF(length_scale=1, length_scale_bounds=(1e-2, 1e3)) + \\\n",
    "#         WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e10))\n",
    "\n",
    "# xx = colvec(x)\n",
    "# u_std = np.ones((u.shape[0], n_sampled_t))\n",
    "# for i in trange(n_sampled_t):    \n",
    "#     gpr = GaussianProcessRegressor(kernel=kernel, alpha=0.0, \n",
    "#                                    n_restarts_optimizer=10 # 20\n",
    "#                                   )\n",
    "\n",
    "#     gpr.fit(xx, u[:, np.random.choice(len(t))])\n",
    "#     _, ustd = gpr.predict(xx, return_std=True)\n",
    "#     u_std[:, i] = ustd\n",
    "    \n",
    "# est_sigma = u_std.mean() # max also works well\n",
    "# cutoff_ws = knee(range(21), \n",
    "#                  [u_std.std()]+[u_std[ws:-ws, :].std() for ws in range(1, 21)], \n",
    "#                  'linear')\n",
    "# if cutoff_ws > 0:\n",
    "#     u = u[cutoff_ws:-cutoff_ws, :]\n",
    "#     x = x[cutoff_ws:-cutoff_ws]\n",
    "    \n",
    "# est_sigma, cutoff_ws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c890b0",
   "metadata": {},
   "source": [
    "### Denoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f3d31a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = bm3d.bm3d(u, sigma_psd=est_sigma, \n",
    "              stage_arg=bm3d.BM3DStages.ALL_STAGES, \n",
    "              blockmatches=(False, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05a04eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = np.array([x.reshape(-1, 1), t.reshape(1, -1)], dtype=object)\n",
    "X, T = np.meshgrid(x, t)\n",
    "XT = np.asarray([X, T]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aaf2666",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_library = ps.PolynomialLibrary(degree=n_poly, include_bias=False)\n",
    "\n",
    "weak_lib = ps.WeakPDELibrary(\n",
    "    function_library=function_library,\n",
    "    derivative_order=n_derivatives,\n",
    "    spatiotemporal_grid=XT,\n",
    "    include_bias=True,\n",
    "    K=10000\n",
    ")\n",
    "\n",
    "X_pre = np.array(weak_lib.fit_transform(np.expand_dims(u, -1)))\n",
    "y_pre = weak_lib.convert_u_dot_integral(np.expand_dims(u, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ad9a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_poly = np.array([[p, 0] for p in range(1, n_poly+1)])\n",
    "base_derivative = np.array([[0, d] for d in range(1, n_derivatives+1)])\n",
    "modules = [(0, 0)] if weak_lib.include_bias else []\n",
    "modules += [(p, 0) for p in range(1, n_poly+1)] + \\\n",
    "            [(0, d) for d in range(1, n_derivatives+1)] + \\\n",
    "            [tuple(p+d) for d in base_derivative for p in base_poly]\n",
    "assert len(modules) == len(weak_lib.get_feature_names())\n",
    "base_features = dict(zip(modules, X_pre.T))\n",
    "u_t = y_pre.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb73e146",
   "metadata": {},
   "source": [
    "### Genetic algorithm with NSGA-II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fa61c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PdeDiscoveryProblem(ElementwiseProblem):\n",
    "    def __init__(self, n_poly, n_derivatives, n_modules, \n",
    "                 base_features, u_t, epsilon=0):\n",
    "        super().__init__(n_var=1, n_obj=2, n_ieq_constr=0)\n",
    "        self.n_poly = n_poly\n",
    "        self.n_derivatives = n_derivatives\n",
    "        self.n_modules = n_modules\n",
    "        self.base_features = base_features\n",
    "        self.u_t = u_t\n",
    "        self.epsilon = epsilon\n",
    "        self.sample_size = np.prod(self.u_t.shape)\n",
    "\n",
    "    def _evaluate(self, X, out, *args, **kwargs):\n",
    "        genome = X[0]\n",
    "        coeff, mse = self.compute_genome_coefficient(genome)\n",
    "        mse = mse/self.sample_size\n",
    "        complexity_penalty = self.epsilon*len(genome)\n",
    "        out[\"F\"] = [mse, complexity_penalty]\n",
    "        \n",
    "    def numericalize_genome(self, genome):\n",
    "        return np.stack([self.base_features[tuple(module)] \n",
    "                         for module in genome], axis=-1)\n",
    "\n",
    "    def compute_genome_coefficient(self, genome):\n",
    "        features = self.numericalize_genome(genome)\n",
    "        features = features.reshape(-1, features.shape[-1])\n",
    "        coeff, error, _, _ = np.linalg.lstsq(features, self.u_t, rcond=None)\n",
    "        return coeff, error[0]\n",
    "    \n",
    "    def generate_module(self, n_poly, n_derivatives):\n",
    "        return (random.randint(0, n_poly), random.randint(0, n_derivatives))\n",
    "    \n",
    "    def set_epsilon(self, epsilon):\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "class PopulationSampling(Sampling):\n",
    "    def _do(self, problem, n_samples, **kwargs):\n",
    "        X = np.full((n_samples, 1), None, dtype=object)\n",
    "        X_set = set()\n",
    "        i = 0\n",
    "        while i < n_samples:\n",
    "            n_modules = random.randint(1, problem.n_modules)\n",
    "            genome = frozenset(problem.generate_module(problem.n_poly, problem.n_derivatives) for _ in range(n_modules))\n",
    "            if len(genome) > 0 and genome not in X_set:\n",
    "                X_set.add(genome)\n",
    "                X[i, 0] = genome\n",
    "                i += 1\n",
    "        return X\n",
    "    \n",
    "class DuplicateElimination(ElementwiseDuplicateElimination):\n",
    "    def is_equal(self, g1, g2):\n",
    "        return g1.X[0] == g2.X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dea1072",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenomeCrossover(Crossover):\n",
    "    def __init__(self):\n",
    "        # define the crossover: number of parents and number of offsprings\n",
    "        super().__init__(2, 2)\n",
    "\n",
    "    def _do(self, problem, X, **kwargs):\n",
    "        # The input of has the following shape (n_parents, n_matings, n_var)\n",
    "        _, n_matings, n_var = X.shape\n",
    "\n",
    "        # The output owith the shape (n_offsprings, n_matings, n_var)\n",
    "        # Because there the number of parents and offsprings are equal it keeps the shape of X\n",
    "        Y = np.full_like(X, None, dtype=object)\n",
    "        \n",
    "        # for each mating provided\n",
    "        for k in range(n_matings):\n",
    "            # get the first and the second parent          \n",
    "            Y[0, k, 0], Y[1, k, 0] = self.crossover_permutation(X[0, k, 0], X[1, k, 0])\n",
    "            \n",
    "        return Y\n",
    "    \n",
    "    def crossover_permutation(self, genome1, genome2):\n",
    "        collection = list(genome1) + list(genome2)\n",
    "        random.shuffle(collection)\n",
    "        return frozenset(collection[:len(genome1)]), frozenset(collection[len(genome1):])\n",
    "    \n",
    "class GenomeMutation(Mutation):\n",
    "    def __init__(self, add_rate=0.4, del_rate=0.5, order_rate=0.4):\n",
    "        super().__init__()\n",
    "        self.add_rate = add_rate\n",
    "        self.del_rate = del_rate\n",
    "        self.order_rate = order_rate\n",
    "\n",
    "    def _do(self, problem, X, **kwargs):\n",
    "        for i in range(len(X)):\n",
    "            if random.random() < self.add_rate:\n",
    "                X[i, 0] = self.add_mutate(problem, X[i, 0])\n",
    "            if random.random() < self.del_rate:\n",
    "                X[i, 0] = self.del_mutate(problem, X[i, 0])\n",
    "            if random.random() < self.order_rate:\n",
    "                X[i, 0] = self.module_mutate(problem, X[i, 0])\n",
    "        return X\n",
    "    \n",
    "    def add_mutate(self, problem, genome, max_iter=3):\n",
    "        for _ in range(max_iter):\n",
    "            new_module = problem.generate_module(problem.n_poly, problem.n_derivatives)\n",
    "            if new_module not in genome:\n",
    "                return genome.union(frozenset({new_module}))\n",
    "        return genome\n",
    "    \n",
    "    def del_mutate(self, problem, genome, max_iter=3):\n",
    "        genome = list(genome)\n",
    "        lg = len(genome)\n",
    "        if lg > 0:\n",
    "            if lg == 1:\n",
    "                for _ in range(max_iter):\n",
    "                    new_module = problem.generate_module(problem.n_poly, problem.n_derivatives)\n",
    "                    if new_module != genome[0]:\n",
    "                        return frozenset({new_module})\n",
    "            else:\n",
    "                genome.pop(random.randint(0, lg-1))\n",
    "        return frozenset(genome)\n",
    "    \n",
    "    def module_mutate(self, problem, genome):\n",
    "        if len(genome) == 0:\n",
    "            return genome\n",
    "        genome = set(genome)\n",
    "        genome.remove(random.choice(list(genome)))\n",
    "        for _ in range(3):\n",
    "            new_module = problem.generate_module(problem.n_poly, problem.n_derivatives)\n",
    "            if new_module not in genome:\n",
    "                genome.add(new_module)\n",
    "                return frozenset(genome)\n",
    "        return frozenset(genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "263f3258",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_size = 500\n",
    "problem = PdeDiscoveryProblem(n_poly, n_derivatives, n_modules, \n",
    "                              base_features, u_t, 0)\n",
    "pop = PopulationSampling().do(problem, pop_size)\n",
    "pop = [[pop[i].X[0]] for i in range(len(pop))]\n",
    "epi = 10**(sci_format(np.median(problem.evaluate(pop)[:, 0]))[1])\n",
    "problem.set_epsilon(epi)\n",
    "del pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "296e4b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "n_gen  |  n_eval  | n_nds  |      eps      |   indicator  \n",
      "==========================================================\n",
      "     1 |      500 |      6 |             - |             -\n",
      "     2 |     1550 |      6 |  0.0874788372 |             f\n",
      "     3 |     2600 |      4 |  1.0000000000 |         nadir\n",
      "     4 |     3650 |      5 |  0.4000000000 |         nadir\n",
      "     5 |     4700 |      6 |  0.0333333337 |             f\n",
      "     6 |     5750 |      6 |  0.0540317491 |             f\n",
      "     7 |     6800 |      6 |  0.000000E+00 |             f\n",
      "     8 |     7850 |      6 |  0.000000E+00 |             f\n",
      "     9 |     8900 |      8 |  0.3750000000 |         nadir\n",
      "    10 |     9950 |      8 |  0.0156278965 |             f\n",
      "    11 |    11000 |      9 |  0.2000000000 |         nadir\n",
      "    12 |    12050 |      8 |  0.2500000000 |         nadir\n",
      "    13 |    13100 |      8 |  9.662219E-07 |             f\n",
      "    14 |    14150 |      9 |  0.0138897478 |             f\n",
      "    15 |    15200 |     11 |  0.3333333333 |         nadir\n",
      "    16 |    16250 |     10 |  1.686067E-06 |             f\n",
      "    17 |    17300 |     10 |  0.0083366683 |             f\n",
      "    18 |    18350 |     11 |  0.0075786330 |             f\n",
      "    19 |    19400 |      8 |  0.2000000000 |         nadir\n",
      "    20 |    20450 |     11 |  0.0909090909 |         nadir\n",
      "    21 |    21500 |     12 |  0.0833333333 |         nadir\n",
      "    22 |    22550 |     12 |  0.000000E+00 |             f\n",
      "    23 |    23600 |     13 |  0.0769230769 |         nadir\n",
      "    24 |    24650 |     12 |  2.014057E-06 |             f\n",
      "    25 |    25700 |     13 |  0.0833333333 |         nadir\n",
      "    26 |    26750 |     13 |  1.265641E-08 |             f\n",
      "    27 |    27800 |     13 |  2.583034E-06 |             f\n",
      "    28 |    28850 |     14 |  0.1428571429 |         nadir\n",
      "    29 |    29900 |     14 |  0.000000E+00 |             f\n",
      "    30 |    30950 |     15 |  0.0047619837 |             f\n",
      "    31 |    32000 |     15 |  5.999201E-07 |             f\n",
      "    32 |    33050 |     15 |  6.122545E-07 |             f\n",
      "    33 |    34100 |     15 |  2.122100E-06 |             f\n",
      "    34 |    35150 |     15 |  3.669215E-06 |             f\n",
      "    35 |    36200 |     16 |  0.0666666667 |         nadir\n",
      "    36 |    37250 |     16 |  3.302282E-06 |             f\n",
      "    37 |    38300 |     16 |  3.638278E-06 |             f\n",
      "    38 |    39350 |     16 |  3.650927E-06 |             f\n",
      "    39 |    40400 |     15 |  7.090600E-06 |             f\n",
      "    40 |    41450 |     14 |  0.0714285714 |         nadir\n",
      "    41 |    42500 |     14 |  0.0051024585 |             f\n",
      "    42 |    43550 |     14 |  0.000000E+00 |             f\n",
      "    43 |    44600 |     15 |  0.2222222222 |         nadir\n",
      "    44 |    45650 |     15 |  0.000000E+00 |             f\n",
      "    45 |    46700 |     15 |  0.2000000000 |         nadir\n",
      "    46 |    47750 |     14 |  2.029716E-06 |             f\n",
      "    47 |    48800 |     14 |  2.029716E-06 |             f\n",
      "    48 |    49850 |     14 |  4.117090E-06 |             f\n",
      "    49 |    50900 |     15 |  6.951105E-06 |             f\n",
      "    50 |    51950 |     14 |  0.1538461538 |         nadir\n",
      "    51 |    53000 |     14 |  0.000000E+00 |             f\n",
      "    52 |    54050 |     15 |  0.2777777778 |         nadir\n",
      "    53 |    55100 |     15 |  0.000000E+00 |             f\n",
      "    54 |    56150 |     15 |  0.2857142857 |         nadir\n",
      "    55 |    57200 |     15 |  3.658050E-07 |             f\n",
      "    56 |    58250 |     16 |  0.1764705882 |         nadir\n",
      "    57 |    59300 |     17 |  0.1052631579 |         nadir\n",
      "    58 |    60350 |     17 |  0.0555555556 |         nadir\n",
      "    59 |    61400 |     17 |  3.205246E-07 |             f\n",
      "    60 |    62450 |     17 |  3.205246E-07 |             f\n",
      "    61 |    63500 |     17 |  1.476885E-06 |             f\n",
      "    62 |    64550 |     17 |  1.899834E-06 |             f\n",
      "    63 |    65600 |     17 |  2.067740E-06 |             f\n",
      "    64 |    66650 |     17 |  2.067740E-06 |             f\n",
      "    65 |    67700 |     18 |  0.0030883727 |             f\n",
      "    66 |    68750 |     18 |  0.000000E+00 |             f\n",
      "    67 |    69800 |     19 |  0.0029239766 |             f\n",
      "    68 |    70850 |     19 |  0.000000E+00 |             f\n",
      "    69 |    71900 |     19 |  0.000000E+00 |             f\n",
      "    70 |    72950 |     18 |  8.805475E-07 |             f\n",
      "    71 |    74000 |     18 |  8.805475E-07 |             f\n",
      "    72 |    75050 |     16 |  0.1250000000 |         nadir\n",
      "    73 |    76100 |     16 |  0.0039062500 |             f\n",
      "    74 |    77150 |     17 |  0.0588235294 |         nadir\n",
      "    75 |    78200 |     17 |  9.844626E-07 |             f\n",
      "    76 |    79250 |     17 |  9.844626E-07 |             f\n",
      "    77 |    80300 |     17 |  1.685601E-06 |             f\n",
      "    78 |    81350 |     18 |  0.0555555556 |         nadir\n",
      "    79 |    82400 |     18 |  0.000000E+00 |             f\n",
      "    80 |    83450 |     18 |  0.000000E+00 |             f\n",
      "    81 |    84500 |     18 |  0.000000E+00 |             f\n",
      "    82 |    85550 |     18 |  0.000000E+00 |             f\n",
      "    83 |    86600 |     18 |  0.000000E+00 |             f\n",
      "    84 |    87650 |     18 |  0.000000E+00 |             f\n",
      "    85 |    88700 |     18 |  0.000000E+00 |             f\n",
      "    86 |    89750 |     19 |  0.0029247036 |             f\n",
      "    87 |    90800 |     19 |  3.661148E-07 |             f\n",
      "    88 |    91850 |     19 |  3.661148E-07 |             f\n",
      "    89 |    92900 |     19 |  3.661148E-07 |             f\n",
      "    90 |    93950 |     19 |  4.054940E-07 |             f\n",
      "    91 |    95000 |     19 |  7.932052E-07 |             f\n",
      "    92 |    96050 |     19 |  7.932052E-07 |             f\n",
      "    93 |    97100 |     20 |  0.1000000000 |         nadir\n",
      "    94 |    98150 |     20 |  0.000000E+00 |             f\n",
      "    95 |    99200 |     20 |  0.000000E+00 |             f\n",
      "    96 |   100250 |     20 |  9.490374E-07 |             f\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[frozenset({(3, 1)})],\n",
       "       [frozenset({(3, 1), (3, 0)})],\n",
       "       [frozenset({(1, 1), (0, 4), (0, 2)})],\n",
       "       [frozenset({(1, 1), (3, 3), (0, 4), (0, 2)})],\n",
       "       [frozenset({(0, 4), (1, 1), (4, 2), (0, 2), (3, 3)})],\n",
       "       [frozenset({(0, 4), (3, 4), (1, 1), (1, 4), (0, 2), (3, 3)})],\n",
       "       [frozenset({(0, 4), (3, 4), (1, 1), (4, 2), (1, 4), (0, 2), (3, 3)})],\n",
       "       [frozenset({(2, 4), (4, 0), (0, 4), (3, 4), (1, 1), (0, 2), (3, 3), (2, 2)})],\n",
       "       [frozenset({(2, 4), (4, 0), (0, 4), (3, 4), (1, 1), (1, 4), (0, 2), (3, 3), (2, 2)})],\n",
       "       [frozenset({(2, 4), (4, 0), (0, 4), (3, 4), (4, 3), (1, 1), (0, 2), (3, 3), (4, 5), (2, 2)})],\n",
       "       [frozenset({(2, 4), (4, 0), (0, 4), (3, 4), (1, 1), (1, 4), (0, 2), (3, 3), (2, 2), (3, 2), (4, 1)})],\n",
       "       [frozenset({(2, 4), (4, 0), (0, 4), (3, 4), (1, 1), (1, 4), (2, 3), (0, 2), (3, 3), (4, 5), (2, 2), (3, 2)})],\n",
       "       [frozenset({(2, 4), (4, 0), (0, 4), (3, 4), (4, 3), (1, 1), (2, 0), (1, 4), (0, 2), (3, 3), (4, 5), (2, 2), (3, 2)})],\n",
       "       [frozenset({(2, 4), (4, 0), (0, 4), (3, 4), (4, 3), (0, 0), (1, 1), (2, 0), (1, 4), (0, 2), (3, 3), (4, 5), (2, 2), (3, 2)})],\n",
       "       [frozenset({(2, 4), (1, 2), (4, 0), (0, 4), (3, 4), (4, 3), (1, 1), (2, 0), (1, 4), (0, 2), (4, 5), (3, 3), (2, 2), (3, 2), (4, 1)})]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_optimal_models = 15\n",
    "\n",
    "termination = DefaultMultiObjectiveTermination(\n",
    "    xtol=1e-8,\n",
    "    cvtol=1e-6,\n",
    "    ftol=1e-8,\n",
    "    period=50,\n",
    "    n_max_gen=100,\n",
    "    n_max_evals=100000\n",
    ")\n",
    "\n",
    "algorithm = DNSGA2( \n",
    "                   pop_size=pop_size,\n",
    "                   sampling=PopulationSampling(),\n",
    "                   crossover=GenomeCrossover(),\n",
    "                   mutation=GenomeMutation(),\n",
    "                   eliminate_duplicates=DuplicateElimination())\n",
    "\n",
    "res = minimize(problem,\n",
    "               algorithm,\n",
    "               termination=termination,\n",
    "               verbose=True)\n",
    "\n",
    "pareto_optimal_models = res.X[np.argsort(res.F[:, 0]+res.F[:, 1])][:n_optimal_models]\n",
    "support_sizes = [len(pareto_optimal_models[i][0]) for i in range(len(pareto_optimal_models))]\n",
    "max_ss = max(support_sizes); min_ss = min(support_sizes)\n",
    "pareto_optimal_models[:n_optimal_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fe7f4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 2), (0, 4), (1, 1), (3, 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significance_threshold = 0.95\n",
    "\n",
    "effective_candidates = frozenset()\n",
    "for i in range(len(pareto_optimal_models)):\n",
    "    effective_candidates = effective_candidates.union(pareto_optimal_models[i][0])\n",
    "    \n",
    "effective_candidates = {_: 0.0 for _ in effective_candidates}\n",
    "for i in range(len(pareto_optimal_models)):\n",
    "    potential_pde = list(pareto_optimal_models[i][0])\n",
    "    important_scores = shap_linear_importance(problem.numericalize_genome(potential_pde), \n",
    "                                              y_pre, scale=True)\n",
    "    for j in range(len(potential_pde)):\n",
    "        effective_candidates[potential_pde[j]] += important_scores[j]\n",
    "        \n",
    "total_score = sum(effective_candidates.values())\n",
    "for _ in effective_candidates:\n",
    "    effective_candidates[_] = effective_candidates[_]/total_score\n",
    "    \n",
    "effective_candidates = sorted(effective_candidates.items(), key=lambda _: _[1], reverse=True)\n",
    "cumulative_sum = 0\n",
    "top_candidates = []\n",
    "for i in range(len(effective_candidates)):\n",
    "    cumulative_sum += effective_candidates[i][1]\n",
    "    top_candidates.append(effective_candidates[i][0])\n",
    "    if cumulative_sum > significance_threshold:\n",
    "        break\n",
    "\n",
    "if len(top_candidates) > max_ss:\n",
    "    top_candidates = np.array(top_candidates)[np.nonzero(linear_model.ARDRegression(max_iter=500, fit_intercept=False).fit(problem.numericalize_genome(top_candidates), y_pre.ravel()).coef_)[0]]\n",
    "X_pre_top = problem.numericalize_genome(top_candidates)\n",
    "\n",
    "top_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8757b32",
   "metadata": {},
   "source": [
    "### Best-subset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dc727d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.80it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 263.05it/s]\n"
     ]
    }
   ],
   "source": [
    "_, best_subsets = okridge_solvel0_full(X_pre_top, y_pre, \n",
    "                                       k=X_pre_top.shape[-1], norm='l2')\n",
    "best_subsets = backward_refinement(best_subsets, (X_pre_top, y_pre), \n",
    "                                   ic_type='bic', verbose=False).get_best_subsets()\n",
    "best_subsets = [tuple(best_subsets[-1][_] for _ in bs) \n",
    "                for bs in brute_force_all_subsets(X_pre_top[:, best_subsets[-1]], y_pre)[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259fb918",
   "metadata": {},
   "source": [
    "### Model selection using UBIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96a6c77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2, 3, 4, "
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 2.37109319, 2.61477342, 3.97380924])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Calculate post_means for ARDRegression as well (Implement the ard_uncertainties function)\n",
    "ard_uns = []\n",
    "threshold_lambda = 5e5 # must pass assert \n",
    "for bs in best_subsets:\n",
    "    ard = linear_model.ARDRegression(fit_intercept=False, \n",
    "                                     compute_score=True,\n",
    "                                     threshold_lambda=threshold_lambda)\n",
    "    ard.fit(X_pre_top[:, bs], y_pre.ravel())\n",
    "    print(len(bs), end=', ')\n",
    "    assert len(bs) == len(np.nonzero(ard.coef_)[0])\n",
    "    pde_uncert = np.sqrt(np.diag(ard.sigma_)).sum()\n",
    "    ard_uns.append(pde_uncert)\n",
    "ard_uns = np.array(ard_uns)\n",
    "ard_uns = ard_uns/min(ard_uns)\n",
    "ard_uns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "548e4fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28281.661524965366, 25358.913836257285, -6074.6977076274015, -6065.752022086244]\n",
      "[7.87727482 7.38593367 1.         1.67777909]\n",
      "threshold: 1.0\n",
      "max_lam: 2.8192489911851797\n",
      "2 <---> 2 inf\n",
      "2 <---> 2 inf\n",
      "2 <---> 2 inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.0,\n",
       " array([28354.21390727, 25426.9407993 , -6065.48736726, -6050.29910558]),\n",
       " 2,\n",
       " 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau = 3\n",
    "verbose = True\n",
    "# scale = 1 <- generalized UBIC\n",
    "scale = np.log(len(y_pre))\n",
    "per = 75 # 80\n",
    "\n",
    "post_means, b_bics, b_uns = baye_uncertainties(best_subsets, (X_pre_top, y_pre), \n",
    "                                               u_type='cv1', take_sqrt=True, \n",
    "                                               ridge_lambda=0, \n",
    "                                               threshold=0)\n",
    "# b_uns = ard_uns # USE ard_uns INSTEAD\n",
    "predictions = X_pre_top@post_means\n",
    "print(b_bics)\n",
    "print(b_uns)\n",
    "b_bics = np.array(b_bics)\n",
    "max_complexity = len(b_bics)\n",
    "complexities = np.arange(max_complexity)+1\n",
    "d_complexities = complexities[decreasing_values_indices(b_bics)]\n",
    "d_bics = b_bics[decreasing_values_indices(b_bics)]\n",
    "slopes = np.diff(b_bics)/(np.diff(complexities)*b_bics[:-1])\n",
    "try:\n",
    "    thres = np.percentile(np.abs(np.diff(d_bics)/(np.diff(d_complexities)*d_bics[:-1])), per)\n",
    "    thres = math.ceil(sci_format(thres)[0])*10**sci_format(thres)[1]\n",
    "except IndexError:\n",
    "    thres = 1/40\n",
    "min_thres = 1/40\n",
    "thres = max(thres, min_thres)\n",
    "print(\"threshold:\", thres)\n",
    "\n",
    "lower_bounds = []\n",
    "for k, efi in enumerate(best_subsets):\n",
    "    # assert len(efi) == np.count_nonzero(post_means[:, k:k+1])\n",
    "    com = len(efi)\n",
    "    lower_bound = 2*np.abs(log_like_value(predictions[:, k:k+1], y_pre))-np.log(len(y_pre))*com\n",
    "    lower_bounds.append(lower_bound)\n",
    "\n",
    "last_lam = np.log10(max(lower_bounds/(b_uns*scale)))\n",
    "print(\"max_lam:\", last_lam)\n",
    "delta = last_lam/tau\n",
    "now_lam = last_lam-delta\n",
    "last_ubic = UBIC(b_bics, b_uns, len(y_pre), hyp=10**last_lam, scale=scale)\n",
    "last_bc = np.argmin(last_ubic)\n",
    "bc_seq = [last_bc]\n",
    "while now_lam >= 0:\n",
    "    now_ubic = UBIC(b_bics, b_uns, len(y_pre), hyp=10**now_lam, scale=scale)\n",
    "    now_bc = np.argmin(now_ubic)\n",
    "    \n",
    "    diff_com = now_bc-last_bc\n",
    "    diff_bic = b_bics[now_bc]-b_bics[last_bc]\n",
    "    imp = np.nan\n",
    "    if diff_com != 0:\n",
    "        imp = abs(diff_bic/(b_bics[last_bc]*diff_com))\n",
    "    \n",
    "    if verbose:\n",
    "        print(min(last_bc, now_bc), '<--->', max(last_bc, now_bc), \n",
    "              np.nan_to_num(imp, nan=np.inf))\n",
    "    \n",
    "    if (diff_com > 0 and (diff_bic > 0 or imp < thres)) or \\\n",
    "        (diff_com < 0 and diff_bic > 0 and imp > thres):\n",
    "        break\n",
    "    \n",
    "    last_lam = now_lam\n",
    "    now_lam = round(last_lam-delta, 8)\n",
    "    last_ubic = now_ubic\n",
    "    last_bc = now_bc\n",
    "    if last_bc not in bc_seq:\n",
    "        bc_seq.append(last_bc)\n",
    "\n",
    "# best_bc = knee_finder(last_ubic)\n",
    "best_bc = knee(range(0, len(last_ubic)), last_ubic, 'linear')\n",
    "if best_bc == 0 and last_bc != 0 and abs((b_bics[last_bc]-b_bics[0])/(b_bics[0]*last_bc)) > thres:\n",
    "    best_bc = knee(range(1, len(last_ubic)), last_ubic[1:], 'linear')\n",
    "\n",
    "if best_bc is None:\n",
    "    best_bc = last_bc\n",
    "    alt_bc = bc_seq[-2] if len(bc_seq) > 1 else last_bc-10\n",
    "    cond = abs((b_bics[last_bc]-b_bics[last_bc-1])/b_bics[last_bc-1]) or \\\n",
    "            abs((b_bics[last_bc]-b_bics[alt_bc])/(b_bics[alt_bc]*(last_bc-alt_bc)))\n",
    "    if cond < thres: \n",
    "        best_bc = np.argmin(last_ubic[:alt_bc+1])\n",
    "    \n",
    "last_lam = round(last_lam, 8)\n",
    "last_lam, last_ubic, last_bc, best_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ea07764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x262.5 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "complexity_axis = [len(bs) for bs in best_subsets]\n",
    "with plt.style.context(['science']):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax2 = ax.twinx()\n",
    "    ax.set_zorder(ax2.get_zorder()+1)\n",
    "    ax.patch.set_visible(False)\n",
    "    \n",
    "    l1, = ax.plot(complexity_axis, last_ubic, 'o-', c='black', markerfacecolor='none', label=f\"$\\lambda = {abs(last_lam)}$\")\n",
    "    ax.set_xticks(complexity_axis)\n",
    "    ax.set_ylabel(\"$\\\\textrm{UBIC}$\", fontsize=12)\n",
    "    ax.set_xlabel(\"Support size\", fontsize=12)\n",
    "    ax.vlines(best_bc+1, min(last_ubic), max(last_ubic), color='red')\n",
    "    \n",
    "    l2, = ax2.plot(complexity_axis, b_uns, 'o--', c='blue', markerfacecolor='none', label=\"Uncertainty $\\\\textrm{U}^{k}$\")\n",
    "    s1 = ax2.scatter(complexity_axis[np.argmin(b_uns)], b_uns[np.argmin(b_uns)], c='blue')\n",
    "    ax2.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "    ax.legend([l1, l2, s1], [f\"UBIC with $\\lambda = {round(abs(last_lam), 2)}$\", \"Uncertainty $\\\\textrm{U}^{k}$\", \"Min $\\\\textrm{U}^{k}$\"], \n",
    "              labelcolor='linecolor', loc='upper center', fontsize=12)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa3a233a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2395488129677703"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some ideas\n",
    "# Better knee detection algorithm\n",
    "\n",
    "import kneeliverse.kneedle as kneedle\n",
    "import kneeliverse.lmethod as lmethod\n",
    "import kneeliverse.menger as menger\n",
    "import kneeliverse.zmethod as zmethod\n",
    "\n",
    "print(kneedle.knee(np.vstack([range(0, len(last_ubic)), \n",
    "                              last_ubic]).T, t=0.1))\n",
    "\n",
    "print(lmethod.knee(np.vstack([range(0, len(last_ubic)), \n",
    "                              last_ubic]).T))\n",
    "\n",
    "print(menger.knee(np.vstack([range(0, len(last_ubic)), \n",
    "                             last_ubic]).T))\n",
    "\n",
    "print(knee_finder(last_ubic))\n",
    "\n",
    "abs((b_bics[2]-b_bics[1])/(b_bics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ffc512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e1ff74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pysr_latest]",
   "language": "python",
   "name": "conda-env-pysr_latest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
