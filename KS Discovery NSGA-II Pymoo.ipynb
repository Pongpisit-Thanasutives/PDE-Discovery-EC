{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8401bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/sindy/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn's version: 1.6.1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from functools import partial\n",
    "from decimal import Decimal\n",
    "import numpy as np\n",
    "# from sklearnex import patch_sklearn; patch_sklearn()\n",
    "import scipy.io as sio\n",
    "import pysindy as ps\n",
    "from tqdm import trange\n",
    "\n",
    "# NSGA2, DNSGA2, SMSEMOA, AGEMOEA2\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.algorithms.moo.dnsga2 import DNSGA2\n",
    "from pymoo.algorithms.moo.sms import SMSEMOA\n",
    "from pymoo.algorithms.moo.age2 import AGEMOEA2\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from pymoo.core.sampling import Sampling\n",
    "from pymoo.core.crossover import Crossover\n",
    "from pymoo.core.mutation import Mutation\n",
    "from pymoo.core.duplicate import ElementwiseDuplicateElimination\n",
    "from pymoo.termination.default import DefaultMultiObjectiveTermination\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.visualization.scatter import Scatter\n",
    "\n",
    "from utils import *\n",
    "from skimage.restoration import estimate_sigma\n",
    "import bm3d\n",
    "from okridge.solvel0 import *\n",
    "from best_subset import backward_refinement, brute_force_all_subsets\n",
    "from UBIC import *\n",
    "from kneed import KneeLocator\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5916f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_poly = 4\n",
    "n_derivatives = 5\n",
    "n_modules = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eaa96d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['KdV_sine_rep_big.mat', 'kuramoto_sivishinky.mat', 'KdV_rudy.mat', 'burgers.mat']\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../PDE-Discovery-EC/Datasets/\"\n",
    "print(os.listdir(data_path))\n",
    "data = sio.loadmat(os.path.join(data_path, \"kuramoto_sivishinky.mat\"))\n",
    "u_clean = (data['uu']).real; u = u_clean.copy()\n",
    "x = data['x'].ravel()\n",
    "t = data['tt'].ravel()\n",
    "dt = t[1]-t[0]; dx = x[2]-x[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1e0adc",
   "metadata": {},
   "source": [
    "### Add noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "888ee41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise level: 50.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "noise_lv = float(50)\n",
    "print(\"Noise level:\", noise_lv)\n",
    "noise = 0.01*np.abs(noise_lv)*(u.std())*np.random.randn(u.shape[0],u.shape[1])\n",
    "u = u + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f675560",
   "metadata": {},
   "source": [
    "### Gaussian process\n",
    "    - removing entries in x that show high std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3b809d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|█████████████████████████████████████████| 25/25 [00:11<00:00,  2.16it/s, 7 steps of size 4.83e-02. acc. prob=0.95]\n",
      "sample: 100%|███████████████████████████████████| 25/25 [00:10<00:00,  2.29it/s, 7 steps of size 4.83e-02. acc. prob=0.94]\n",
      "sample: 100%|███████████████████████████████████| 25/25 [00:11<00:00,  2.19it/s, 7 steps of size 4.83e-02. acc. prob=0.94]\n",
      "sample: 100%|███████████████████████████████████| 25/25 [00:10<00:00,  2.31it/s, 7 steps of size 4.83e-02. acc. prob=0.94]\n",
      "sample: 100%|███████████████████████████████████| 25/25 [00:20<00:00,  1.23it/s, 7 steps of size 4.83e-02. acc. prob=0.97]\n",
      "sample: 100%|███████████████████████████████████| 25/25 [00:12<00:00,  2.03it/s, 7 steps of size 4.83e-02. acc. prob=0.94]\n",
      "sample: 100%|███████████████████████████████████| 25/25 [00:12<00:00,  2.04it/s, 7 steps of size 4.83e-02. acc. prob=0.91]\n",
      "sample: 100%|███████████████████████████████████| 25/25 [00:11<00:00,  2.13it/s, 7 steps of size 4.83e-02. acc. prob=0.94]\n",
      "sample: 100%|██████████████████████████████████| 25/25 [00:35<00:00,  1.43s/it, 23 steps of size 4.83e-02. acc. prob=0.96]\n",
      "sample: 100%|███████████████████████████████████| 25/25 [01:51<00:00,  4.47s/it, 7 steps of size 4.83e-02. acc. prob=0.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5562785943810014 0.9466975331306458\n"
     ]
    }
   ],
   "source": [
    "import gpax\n",
    "\n",
    "n_sampled_t = 10\n",
    "xx = colvec(x)\n",
    "u_std = np.ones((u.shape[0], n_sampled_t))\n",
    "for i in range(n_sampled_t):\n",
    "    rng_key_train, rng_key_predict = gpax.utils.get_keys()\n",
    "\n",
    "    gp_model = gpax.ExactGP(1, kernel='RBF')\n",
    "    gp_model.fit(rng_key_train, xx, u[:, np.random.choice(len(t))], \n",
    "                 num_warmup=5, num_samples=20, jitter=1e-6, \n",
    "                 chain_method='parallel', print_summary=False)\n",
    "\n",
    "    posterior_mean, f_samples = gp_model.predict(rng_key_predict, xx)\n",
    "    u_std[:, i] = np.std(f_samples[:, 0, :], axis=0)\n",
    "\n",
    "print(u_std.mean(), u_std.max())\n",
    "est_sigma = u_std.mean() # max also works well\n",
    "\n",
    "outlier = lambda arr: np.arange(len(arr))[arr-np.mean(arr) <= 3*np.std(arr)]\n",
    "filtered_indices = outlier(u_std.mean(axis=-1))\n",
    "u = u[filtered_indices, :]\n",
    "x = x[filtered_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9754901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_sampled_t = 10\n",
    "\n",
    "# kernel = RBF(length_scale=1, length_scale_bounds=(1e-2, 1e3)) + \\\n",
    "#         WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e10))\n",
    "\n",
    "# xx = colvec(x)\n",
    "# u_std = np.ones((u.shape[0], n_sampled_t))\n",
    "# for i in trange(n_sampled_t):    \n",
    "#     gpr = GaussianProcessRegressor(kernel=kernel, alpha=0.0, \n",
    "#                                    n_restarts_optimizer=10 # 20\n",
    "#                                   )\n",
    "\n",
    "#     gpr.fit(xx, u[:, np.random.choice(len(t))])\n",
    "#     _, ustd = gpr.predict(xx, return_std=True)\n",
    "#     u_std[:, i] = ustd\n",
    "    \n",
    "# est_sigma = u_std.mean() # max also works well\n",
    "# cutoff_ws = knee(range(21), \n",
    "#                  [u_std.std()]+[u_std[ws:-ws, :].std() for ws in range(1, 21)], \n",
    "#                  'linear')\n",
    "# if cutoff_ws > 0:\n",
    "#     u = u[cutoff_ws:-cutoff_ws, :]\n",
    "#     x = x[cutoff_ws:-cutoff_ws]\n",
    "    \n",
    "# est_sigma, cutoff_ws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c890b0",
   "metadata": {},
   "source": [
    "### Denoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f3d31a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = bm3d.bm3d(u, sigma_psd=est_sigma, \n",
    "              stage_arg=bm3d.BM3DStages.ALL_STAGES, \n",
    "              blockmatches=(False, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05a04eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = np.array([x.reshape(-1, 1), t.reshape(1, -1)], dtype=object)\n",
    "X, T = np.meshgrid(x, t)\n",
    "XT = np.asarray([X, T]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aaf2666",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_library = ps.PolynomialLibrary(degree=n_poly, include_bias=False)\n",
    "\n",
    "weak_lib = ps.WeakPDELibrary(\n",
    "    function_library=function_library,\n",
    "    derivative_order=n_derivatives,\n",
    "    spatiotemporal_grid=XT,\n",
    "    include_bias=True,\n",
    "    K=10000\n",
    ")\n",
    "\n",
    "X_pre = np.array(weak_lib.fit_transform(np.expand_dims(u, -1)))\n",
    "y_pre = weak_lib.convert_u_dot_integral(np.expand_dims(u, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ad9a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_poly = np.array([[p, 0] for p in range(1, n_poly+1)])\n",
    "base_derivative = np.array([[0, d] for d in range(1, n_derivatives+1)])\n",
    "modules = [(0, 0)] if weak_lib.include_bias else []\n",
    "modules += [(p, 0) for p in range(1, n_poly+1)] + \\\n",
    "            [(0, d) for d in range(1, n_derivatives+1)] + \\\n",
    "            [tuple(p+d) for d in base_derivative for p in base_poly]\n",
    "assert len(modules) == len(weak_lib.get_feature_names())\n",
    "base_features = dict(zip(modules, X_pre.T))\n",
    "u_t = y_pre.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb73e146",
   "metadata": {},
   "source": [
    "### Genetic algorithm with NSGA-II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fa61c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PdeDiscoveryProblem(ElementwiseProblem):\n",
    "    def __init__(self, n_poly, n_derivatives, n_modules, \n",
    "                 base_features, u_t, epsilon=0):\n",
    "        super().__init__(n_var=1, n_obj=2, n_ieq_constr=0)\n",
    "        self.n_poly = n_poly\n",
    "        self.n_derivatives = n_derivatives\n",
    "        self.n_modules = n_modules\n",
    "        self.base_features = base_features\n",
    "        self.u_t = u_t\n",
    "        self.epsilon = epsilon\n",
    "        self.sample_size = np.prod(self.u_t.shape)\n",
    "\n",
    "    def _evaluate(self, X, out, *args, **kwargs):\n",
    "        genome = X[0]\n",
    "        coeff, mse = self.compute_genome_coefficient(genome)\n",
    "        mse = mse/self.sample_size\n",
    "        complexity_penalty = self.epsilon*len(genome)\n",
    "        out[\"F\"] = [mse, complexity_penalty]\n",
    "        \n",
    "    def numericalize_genome(self, genome):\n",
    "        return np.stack([self.base_features[tuple(module)] \n",
    "                         for module in genome], axis=-1)\n",
    "\n",
    "    def compute_genome_coefficient(self, genome):\n",
    "        features = self.numericalize_genome(genome)\n",
    "        features = features.reshape(-1, features.shape[-1])\n",
    "        coeff, error, _, _ = np.linalg.lstsq(features, self.u_t, rcond=None)\n",
    "        return coeff, error[0]\n",
    "    \n",
    "    def generate_module(self, n_poly, n_derivatives):\n",
    "        return (random.randint(0, n_poly), random.randint(0, n_derivatives))\n",
    "    \n",
    "    def set_epsilon(self, epsilon):\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "class PopulationSampling(Sampling):\n",
    "    def _do(self, problem, n_samples, **kwargs):\n",
    "        X = np.full((n_samples, 1), None, dtype=object)\n",
    "        X_set = set()\n",
    "        i = 0\n",
    "        while i < n_samples:\n",
    "            n_modules = random.randint(1, problem.n_modules)\n",
    "            genome = frozenset(problem.generate_module(problem.n_poly, problem.n_derivatives) for _ in range(n_modules))\n",
    "            if len(genome) > 0 and genome not in X_set:\n",
    "                X_set.add(genome)\n",
    "                X[i, 0] = genome\n",
    "                i += 1\n",
    "        return X\n",
    "    \n",
    "class DuplicateElimination(ElementwiseDuplicateElimination):\n",
    "    def is_equal(self, g1, g2):\n",
    "        return g1.X[0] == g2.X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dea1072",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenomeCrossover(Crossover):\n",
    "    def __init__(self):\n",
    "        # define the crossover: number of parents and number of offsprings\n",
    "        super().__init__(2, 2)\n",
    "\n",
    "    def _do(self, problem, X, **kwargs):\n",
    "        # The input of has the following shape (n_parents, n_matings, n_var)\n",
    "        _, n_matings, n_var = X.shape\n",
    "\n",
    "        # The output owith the shape (n_offsprings, n_matings, n_var)\n",
    "        # Because there the number of parents and offsprings are equal it keeps the shape of X\n",
    "        Y = np.full_like(X, None, dtype=object)\n",
    "        \n",
    "        # for each mating provided\n",
    "        for k in range(n_matings):\n",
    "            # get the first and the second parent          \n",
    "            Y[0, k, 0], Y[1, k, 0] = self.crossover_permutation(X[0, k, 0], X[1, k, 0])\n",
    "            \n",
    "        return Y\n",
    "    \n",
    "    def crossover_permutation(self, genome1, genome2):\n",
    "        collection = list(genome1) + list(genome2)\n",
    "        random.shuffle(collection)\n",
    "        return frozenset(collection[:len(genome1)]), frozenset(collection[len(genome1):])\n",
    "    \n",
    "class GenomeMutation(Mutation):\n",
    "    def __init__(self, add_rate=0.4, del_rate=0.5, order_rate=0.4):\n",
    "        super().__init__()\n",
    "        self.add_rate = add_rate\n",
    "        self.del_rate = del_rate\n",
    "        self.order_rate = order_rate\n",
    "\n",
    "    def _do(self, problem, X, **kwargs):\n",
    "        for i in range(len(X)):\n",
    "            if random.random() < self.add_rate:\n",
    "                X[i, 0] = self.add_mutate(problem, X[i, 0])\n",
    "            if random.random() < self.del_rate:\n",
    "                X[i, 0] = self.del_mutate(problem, X[i, 0])\n",
    "            if random.random() < self.order_rate:\n",
    "                X[i, 0] = self.module_mutate(problem, X[i, 0])\n",
    "        return X\n",
    "    \n",
    "    def add_mutate(self, problem, genome, max_iter=3):\n",
    "        for _ in range(max_iter):\n",
    "            new_module = problem.generate_module(problem.n_poly, problem.n_derivatives)\n",
    "            if new_module not in genome:\n",
    "                return genome.union(frozenset({new_module}))\n",
    "        return genome\n",
    "    \n",
    "    def del_mutate(self, problem, genome, max_iter=3):\n",
    "        genome = list(genome)\n",
    "        lg = len(genome)\n",
    "        if lg > 0:\n",
    "            if lg == 1:\n",
    "                for _ in range(max_iter):\n",
    "                    new_module = problem.generate_module(problem.n_poly, problem.n_derivatives)\n",
    "                    if new_module != genome[0]:\n",
    "                        return frozenset({new_module})\n",
    "            else:\n",
    "                genome.pop(random.randint(0, lg-1))\n",
    "        return frozenset(genome)\n",
    "    \n",
    "    def module_mutate(self, problem, genome):\n",
    "        if len(genome) == 0:\n",
    "            return genome\n",
    "        genome = set(genome)\n",
    "        genome.remove(random.choice(list(genome)))\n",
    "        for _ in range(3):\n",
    "            new_module = problem.generate_module(problem.n_poly, problem.n_derivatives)\n",
    "            if new_module not in genome:\n",
    "                genome.add(new_module)\n",
    "                return frozenset(genome)\n",
    "        return frozenset(genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "263f3258",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_size = 500\n",
    "problem = PdeDiscoveryProblem(n_poly, n_derivatives, n_modules, \n",
    "                              base_features, u_t, 0)\n",
    "pop = PopulationSampling().do(problem, pop_size)\n",
    "pop = [[pop[i].X[0]] for i in range(len(pop))]\n",
    "epi = 10**(sci_format(np.median(problem.evaluate(pop)[:, 0]))[1])\n",
    "problem.set_epsilon(epi)\n",
    "del pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "296e4b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "n_gen  |  n_eval  | n_nds  |      eps      |   indicator  \n",
      "==========================================================\n",
      "     1 |      500 |      4 |             - |             -\n",
      "     2 |     1550 |      6 |  0.5714285714 |         nadir\n",
      "     3 |     2600 |      6 |  0.0022294324 |             f\n",
      "     4 |     3650 |      6 |  0.1666666667 |         nadir\n",
      "     5 |     4700 |      7 |  0.0303036579 |             f\n",
      "     6 |     5750 |      7 |  0.2500000000 |         nadir\n",
      "     7 |     6800 |      7 |  0.0178911332 |             f\n",
      "     8 |     7850 |      7 |  2.735681E-06 |             f\n",
      "     9 |     8900 |      9 |  0.2000000000 |         nadir\n",
      "    10 |     9950 |     10 |  0.0100043184 |             f\n",
      "    11 |    11000 |     11 |  0.0090948723 |             f\n",
      "    12 |    12050 |     12 |  0.0909090909 |         nadir\n",
      "    13 |    13100 |     12 |  7.861226E-06 |             f\n",
      "    14 |    14150 |     12 |  0.0000105357 |             f\n",
      "    15 |    15200 |     12 |  0.0000193952 |             f\n",
      "    16 |    16250 |     12 |  0.0000224805 |             f\n",
      "    17 |    17300 |     12 |  0.0000298741 |             f\n",
      "    18 |    18350 |     12 |  0.0000320539 |             f\n",
      "    19 |    19400 |     11 |  0.1000000000 |         nadir\n",
      "    20 |    20450 |     13 |  0.2307692308 |         nadir\n",
      "    21 |    21500 |     13 |  0.000000E+00 |             f\n",
      "    22 |    22550 |     12 |  7.127923E-06 |             f\n",
      "    23 |    23600 |     11 |  0.0000109224 |             f\n",
      "    24 |    24650 |     11 |  0.0000151977 |             f\n",
      "    25 |    25700 |     11 |  0.0000151977 |             f\n",
      "    26 |    26750 |     12 |  0.0000164677 |             f\n",
      "    27 |    27800 |     12 |  0.0000168212 |             f\n",
      "    28 |    28850 |     13 |  0.1333333333 |         nadir\n",
      "    29 |    29900 |     13 |  0.000000E+00 |             f\n",
      "    30 |    30950 |     14 |  0.0047619298 |             f\n",
      "    31 |    32000 |     13 |  0.0051345700 |             f\n",
      "    32 |    33050 |     13 |  0.2500000000 |         nadir\n",
      "    33 |    34100 |     13 |  6.698876E-06 |             f\n",
      "    34 |    35150 |     14 |  0.1428571429 |         nadir\n",
      "    35 |    36200 |     14 |  0.000000E+00 |             f\n",
      "    36 |    37250 |     14 |  1.711144E-06 |             f\n",
      "    37 |    38300 |     13 |  5.862758E-06 |             f\n",
      "    38 |    39350 |     14 |  0.0666666667 |         nadir\n",
      "    39 |    40400 |     15 |  0.0044455570 |             f\n",
      "    40 |    41450 |     15 |  0.000000E+00 |             f\n",
      "    41 |    42500 |     16 |  0.0041669510 |             f\n",
      "    42 |    43550 |     16 |  0.000000E+00 |             f\n",
      "    43 |    44600 |     17 |  0.0625000000 |         nadir\n",
      "    44 |    45650 |     17 |  0.0588235294 |         nadir\n",
      "    45 |    46700 |     16 |  4.075312E-06 |             f\n",
      "    46 |    47750 |     16 |  4.796204E-06 |             f\n",
      "    47 |    48800 |     16 |  4.796204E-06 |             f\n",
      "    48 |    49850 |     17 |  0.0034647217 |             f\n",
      "    49 |    50900 |     18 |  0.0032689782 |             f\n",
      "    50 |    51950 |     17 |  0.0555555556 |         nadir\n",
      "    51 |    53000 |     17 |  5.302795E-07 |             f\n",
      "    52 |    54050 |     17 |  5.302795E-07 |             f\n",
      "    53 |    55100 |     18 |  0.0030869206 |             f\n",
      "    54 |    56150 |     18 |  9.288953E-08 |             f\n",
      "    55 |    57200 |     18 |  5.018249E-07 |             f\n",
      "    56 |    58250 |     19 |  0.0526315789 |         nadir\n",
      "    57 |    59300 |     19 |  0.000000E+00 |             f\n",
      "    58 |    60350 |     19 |  2.635249E-07 |             f\n",
      "    59 |    61400 |     19 |  3.711060E-06 |             f\n",
      "    60 |    62450 |     19 |  7.219081E-06 |             f\n",
      "    61 |    63500 |     19 |  7.234501E-06 |             f\n",
      "    62 |    64550 |     19 |  8.022329E-06 |             f\n",
      "    63 |    65600 |     18 |  9.143810E-06 |             f\n",
      "    64 |    66650 |     18 |  9.143810E-06 |             f\n",
      "    65 |    67700 |     19 |  8.913827E-06 |             f\n",
      "    66 |    68750 |     19 |  9.385566E-06 |             f\n",
      "    67 |    69800 |     19 |  9.385566E-06 |             f\n",
      "    68 |    70850 |     19 |  9.565462E-06 |             f\n",
      "    69 |    71900 |     19 |  9.565462E-06 |             f\n",
      "    70 |    72950 |     19 |  9.999153E-06 |             f\n",
      "    71 |    74000 |     19 |  9.999153E-06 |             f\n",
      "    72 |    75050 |     19 |  9.999153E-06 |             f\n",
      "    73 |    76100 |     20 |  0.0026418919 |             f\n",
      "    74 |    77150 |     20 |  0.000000E+00 |             f\n",
      "    75 |    78200 |     20 |  0.000000E+00 |             f\n",
      "    76 |    79250 |     20 |  0.000000E+00 |             f\n",
      "    77 |    80300 |     20 |  5.306933E-07 |             f\n",
      "    78 |    81350 |     20 |  5.306933E-07 |             f\n",
      "    79 |    82400 |     19 |  1.116906E-06 |             f\n",
      "    80 |    83450 |     20 |  1.817024E-06 |             f\n",
      "    81 |    84500 |     21 |  0.0952380952 |         nadir\n",
      "    82 |    85550 |     21 |  3.295802E-07 |             f\n",
      "    83 |    86600 |     21 |  3.295802E-07 |             f\n",
      "    84 |    87650 |     21 |  3.295802E-07 |             f\n",
      "    85 |    88700 |     22 |  0.0021648168 |             f\n",
      "    86 |    89750 |     22 |  0.0021648168 |             f\n",
      "    87 |    90800 |     22 |  0.0021648168 |             f\n",
      "    88 |    91850 |     22 |  0.0021656458 |             f\n",
      "    89 |    92900 |     22 |  0.0021656458 |             f\n",
      "    90 |    93950 |     22 |  0.0021660630 |             f\n",
      "    91 |    95000 |     22 |  0.0021671972 |             f\n",
      "    92 |    96050 |     22 |  0.0021678986 |             f\n",
      "    93 |    97100 |     22 |  0.0021685176 |             f\n",
      "    94 |    98150 |     22 |  0.0021685176 |             f\n",
      "    95 |    99200 |     23 |  0.0454545455 |         nadir\n",
      "    96 |   100250 |     22 |  8.284061E-07 |             f\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[frozenset({(3, 1)})],\n",
       "       [frozenset({(3, 1), (3, 0)})],\n",
       "       [frozenset({(1, 1), (0, 4), (0, 2)})],\n",
       "       [frozenset({(1, 1), (0, 4), (3, 5), (0, 2)})],\n",
       "       [frozenset({(4, 4), (0, 2), (0, 4), (1, 1), (3, 5)})],\n",
       "       [frozenset({(4, 4), (0, 4), (1, 1), (0, 2), (4, 1), (3, 5)})],\n",
       "       [frozenset({(4, 4), (0, 4), (1, 1), (0, 2), (3, 3), (4, 1), (3, 5)})],\n",
       "       [frozenset({(4, 4), (0, 4), (3, 4), (1, 1), (2, 3), (0, 2), (3, 2), (3, 5)})],\n",
       "       [frozenset({(4, 4), (1, 2), (0, 4), (3, 4), (4, 3), (1, 1), (0, 2), (3, 2), (3, 5)})],\n",
       "       [frozenset({(4, 4), (0, 4), (3, 4), (4, 3), (1, 1), (0, 2), (3, 3), (4, 5), (3, 2), (3, 5)})],\n",
       "       [frozenset({(4, 4), (1, 2), (0, 4), (3, 4), (4, 3), (1, 1), (0, 2), (3, 3), (3, 2), (2, 5), (3, 5)})],\n",
       "       [frozenset({(4, 4), (1, 2), (0, 4), (3, 4), (4, 3), (1, 1), (0, 2), (3, 3), (4, 5), (1, 0), (3, 2), (3, 5)})],\n",
       "       [frozenset({(4, 4), (1, 2), (0, 4), (3, 4), (4, 3), (1, 1), (2, 0), (3, 0), (0, 2), (3, 3), (4, 5), (3, 2), (3, 5)})],\n",
       "       [frozenset({(2, 4), (1, 2), (0, 4), (2, 1), (3, 4), (4, 3), (4, 0), (1, 1), (4, 5), (3, 3), (0, 2), (1, 0), (3, 2), (3, 5)})],\n",
       "       [frozenset({(2, 4), (0, 4), (2, 1), (3, 4), (4, 3), (1, 1), (4, 2), (2, 3), (0, 2), (3, 3), (2, 2), (3, 2), (2, 5), (4, 1), (3, 5)})]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_optimal_models = 15\n",
    "\n",
    "termination = DefaultMultiObjectiveTermination(\n",
    "    xtol=1e-8,\n",
    "    cvtol=1e-6,\n",
    "    ftol=1e-8,\n",
    "    period=50,\n",
    "    n_max_gen=100,\n",
    "    n_max_evals=100000\n",
    ")\n",
    "\n",
    "algorithm = DNSGA2( \n",
    "                   pop_size=pop_size,\n",
    "                   sampling=PopulationSampling(),\n",
    "                   crossover=GenomeCrossover(),\n",
    "                   mutation=GenomeMutation(),\n",
    "                   eliminate_duplicates=DuplicateElimination())\n",
    "\n",
    "res = minimize(problem,\n",
    "               algorithm,\n",
    "               termination=termination,\n",
    "               verbose=True)\n",
    "\n",
    "pareto_optimal_models = res.X[np.argsort(res.F[:, 0]+res.F[:, 1])][:n_optimal_models]\n",
    "support_sizes = [len(pareto_optimal_models[i][0]) for i in range(len(pareto_optimal_models))]\n",
    "max_ss = max(support_sizes); min_ss = min(support_sizes)\n",
    "pareto_optimal_models[:n_optimal_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fe7f4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2), (0, 4), (1, 1), (3, 1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significance_threshold = 0.95\n",
    "\n",
    "effective_candidates = frozenset()\n",
    "for i in range(len(pareto_optimal_models)):\n",
    "    effective_candidates = effective_candidates.union(pareto_optimal_models[i][0])\n",
    "    \n",
    "effective_candidates = {_: 0.0 for _ in effective_candidates}\n",
    "for i in range(len(pareto_optimal_models)):\n",
    "    potential_pde = list(pareto_optimal_models[i][0])\n",
    "    important_scores = shap_linear_importance(problem.numericalize_genome(potential_pde), \n",
    "                                              y_pre, scale=True)\n",
    "    for j in range(len(potential_pde)):\n",
    "        effective_candidates[potential_pde[j]] += important_scores[j]\n",
    "        \n",
    "total_score = sum(effective_candidates.values())\n",
    "for _ in effective_candidates:\n",
    "    effective_candidates[_] = effective_candidates[_]/total_score\n",
    "    \n",
    "effective_candidates = sorted(effective_candidates.items(), key=lambda _: _[1], reverse=True)\n",
    "cumulative_sum = 0\n",
    "top_candidates = []\n",
    "for i in range(len(effective_candidates)):\n",
    "    cumulative_sum += effective_candidates[i][1]\n",
    "    top_candidates.append(effective_candidates[i][0])\n",
    "    if cumulative_sum > significance_threshold:\n",
    "        break\n",
    "\n",
    "if len(top_candidates) > max_ss:\n",
    "    top_candidates = np.array(top_candidates)[np.nonzero(linear_model.ARDRegression(max_iter=500, fit_intercept=False).fit(problem.numericalize_genome(top_candidates), y_pre.ravel()).coef_)[0]]\n",
    "X_pre_top = problem.numericalize_genome(top_candidates)\n",
    "\n",
    "top_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8757b32",
   "metadata": {},
   "source": [
    "### Best-subset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5dc727d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  3.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 223.49it/s]\n"
     ]
    }
   ],
   "source": [
    "_, best_subsets = okridge_solvel0_full(X_pre_top, y_pre, \n",
    "                                       k=X_pre_top.shape[-1], norm='l2')\n",
    "best_subsets = backward_refinement(best_subsets, (X_pre_top, y_pre), \n",
    "                                   ic_type='bic', verbose=False).get_best_subsets()\n",
    "best_subsets = [tuple(best_subsets[-1][_] for _ in bs) \n",
    "                for bs in brute_force_all_subsets(X_pre_top[:, best_subsets[-1]], y_pre)[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259fb918",
   "metadata": {},
   "source": [
    "### Model selection using UBIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96a6c77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2, 3, 4, "
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 2.37155498, 2.70163207, 4.0587751 ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Calculate post_means for ARDRegression as well (Implement the ard_uncertainties function)\n",
    "ard_uns = []\n",
    "threshold_lambda = 5e5 # must pass assert \n",
    "for bs in best_subsets:\n",
    "    ard = linear_model.ARDRegression(fit_intercept=False, \n",
    "                                     compute_score=True,\n",
    "                                     threshold_lambda=threshold_lambda)\n",
    "    ard.fit(X_pre_top[:, bs], y_pre.ravel())\n",
    "    print(len(bs), end=', ')\n",
    "    assert len(bs) == len(np.nonzero(ard.coef_)[0])\n",
    "    pde_uncert = np.sqrt(np.diag(ard.sigma_)).sum()\n",
    "    ard_uns.append(pde_uncert)\n",
    "ard_uns = np.array(ard_uns)\n",
    "ard_uns = ard_uns/min(ard_uns)\n",
    "ard_uns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "548e4fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28248.760200397304, 25324.15152352444, -5426.573335106925, -5417.364640549846]\n",
      "[7.56178052 7.11874067 1.         1.67811688]\n",
      "threshold: 1.0\n",
      "max_lam: 2.7702499964455387\n",
      "2 <---> 2 inf\n",
      "2 <---> 2 inf\n",
      "2 <---> 2 inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " array([28318.40677281, 25389.71754807, -5417.36299473, -5401.90861293]),\n",
       " 2,\n",
       " 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau = 3\n",
    "verbose = True\n",
    "# scale = 1 <- generalized UBIC\n",
    "scale = np.log(len(y_pre))\n",
    "per = 75 # 80\n",
    "\n",
    "post_means, b_bics, b_uns = baye_uncertainties(best_subsets, (X_pre_top, y_pre), \n",
    "                                               u_type='cv1', take_sqrt=True, \n",
    "                                               ridge_lambda=0, \n",
    "                                               threshold=0)\n",
    "# b_uns = ard_uns # USE ard_uns INSTEAD\n",
    "predictions = X_pre_top@post_means\n",
    "print(b_bics)\n",
    "print(b_uns)\n",
    "b_bics = np.array(b_bics)\n",
    "max_complexity = len(b_bics)\n",
    "complexities = np.arange(max_complexity)+1\n",
    "d_complexities = complexities[decreasing_values_indices(b_bics)]\n",
    "d_bics = b_bics[decreasing_values_indices(b_bics)]\n",
    "slopes = np.diff(b_bics)/(np.diff(complexities)*b_bics[:-1])\n",
    "try:\n",
    "    thres = np.percentile(np.abs(np.diff(d_bics)/(np.diff(d_complexities)*d_bics[:-1])), per)\n",
    "    thres = math.ceil(sci_format(thres)[0])*10**sci_format(thres)[1]\n",
    "except IndexError:\n",
    "    thres = 1/40\n",
    "min_thres = 1/40\n",
    "thres = max(thres, min_thres)\n",
    "print(\"threshold:\", thres)\n",
    "\n",
    "lower_bounds = []\n",
    "for k, efi in enumerate(best_subsets):\n",
    "    # assert len(efi) == np.count_nonzero(post_means[:, k:k+1])\n",
    "    com = len(efi)\n",
    "    lower_bound = 2*np.abs(log_like_value(predictions[:, k:k+1], y_pre))-np.log(len(y_pre))*com\n",
    "    lower_bounds.append(lower_bound)\n",
    "\n",
    "last_lam = np.log10(max(lower_bounds/(b_uns*scale)))\n",
    "print(\"max_lam:\", last_lam)\n",
    "delta = last_lam/tau\n",
    "now_lam = last_lam-delta\n",
    "last_ubic = UBIC(b_bics, b_uns, len(y_pre), hyp=10**last_lam, scale=scale)\n",
    "last_bc = np.argmin(last_ubic)\n",
    "bc_seq = [last_bc]\n",
    "while now_lam >= 0:\n",
    "    now_ubic = UBIC(b_bics, b_uns, len(y_pre), hyp=10**now_lam, scale=scale)\n",
    "    now_bc = np.argmin(now_ubic)\n",
    "    \n",
    "    diff_com = now_bc-last_bc\n",
    "    diff_bic = b_bics[now_bc]-b_bics[last_bc]\n",
    "    imp = np.nan\n",
    "    if diff_com != 0:\n",
    "        imp = abs(diff_bic/(b_bics[last_bc]*diff_com))\n",
    "    \n",
    "    if verbose:\n",
    "        print(min(last_bc, now_bc), '<--->', max(last_bc, now_bc), \n",
    "              np.nan_to_num(imp, nan=np.inf))\n",
    "    \n",
    "    if (diff_com > 0 and (diff_bic > 0 or imp < thres)) or \\\n",
    "        (diff_com < 0 and diff_bic > 0 and imp > thres):\n",
    "        break\n",
    "    \n",
    "    last_lam = now_lam\n",
    "    now_lam = round(last_lam-delta, 8)\n",
    "    last_ubic = now_ubic\n",
    "    last_bc = now_bc\n",
    "    if last_bc not in bc_seq:\n",
    "        bc_seq.append(last_bc)\n",
    "\n",
    "# best_bc = knee_finder(last_ubic)\n",
    "best_bc = knee(range(0, len(last_ubic)), last_ubic, 'linear')\n",
    "if best_bc == 0 and last_bc != 0 and abs((b_bics[last_bc]-b_bics[0])/(b_bics[0]*last_bc)) > thres:\n",
    "    best_bc = knee(range(1, len(last_ubic)), last_ubic[1:], 'linear')\n",
    "\n",
    "if best_bc is None:\n",
    "    best_bc = last_bc\n",
    "    alt_bc = bc_seq[-2] if len(bc_seq) > 1 else last_bc-10\n",
    "    cond = abs((b_bics[last_bc]-b_bics[last_bc-1])/b_bics[last_bc-1]) or \\\n",
    "            abs((b_bics[last_bc]-b_bics[alt_bc])/(b_bics[alt_bc]*(last_bc-alt_bc)))\n",
    "    if cond < thres: \n",
    "        best_bc = np.argmin(last_ubic[:alt_bc+1])\n",
    "    \n",
    "last_lam = abs(round(last_lam, 8))\n",
    "last_lam, last_ubic, last_bc, best_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ea07764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x262.5 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "complexity_axis = [len(bs) for bs in best_subsets]\n",
    "with plt.style.context(['science']):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax2 = ax.twinx()\n",
    "    ax.set_zorder(ax2.get_zorder()+1)\n",
    "    ax.patch.set_visible(False)\n",
    "    \n",
    "    l1, = ax.plot(complexity_axis, last_ubic, 'o-', c='black', markerfacecolor='none', label=f\"$\\lambda = {abs(last_lam)}$\")\n",
    "    ax.set_xticks(complexity_axis)\n",
    "    ax.set_ylabel(\"$\\\\textrm{UBIC}$\", fontsize=12)\n",
    "    ax.set_xlabel(\"Support size\", fontsize=12)\n",
    "    ax.vlines(best_bc+1, min(last_ubic), max(last_ubic), color='red')\n",
    "    \n",
    "    l2, = ax2.plot(complexity_axis, b_uns, 'o--', c='blue', markerfacecolor='none', label=\"Uncertainty $\\\\textrm{U}^{k}$\")\n",
    "    s1 = ax2.scatter(complexity_axis[np.argmin(b_uns)], b_uns[np.argmin(b_uns)], c='blue')\n",
    "    ax2.tick_params(axis='y', labelcolor='blue')\n",
    "    \n",
    "    ax.legend([l1, l2, s1], [f\"UBIC with $\\lambda = {round(abs(last_lam), 2)}$\", \"Uncertainty $\\\\textrm{U}^{k}$\", \"Min $\\\\textrm{U}^{k}$\"], \n",
    "              labelcolor='linecolor', loc='upper center', fontsize=12)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa3a233a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2142845074223316"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some ideas\n",
    "# Better knee detection algorithm\n",
    "\n",
    "import kneeliverse.kneedle as kneedle\n",
    "import kneeliverse.lmethod as lmethod\n",
    "import kneeliverse.menger as menger\n",
    "import kneeliverse.zmethod as zmethod\n",
    "\n",
    "print(kneedle.knee(np.vstack([range(0, len(last_ubic)), \n",
    "                              last_ubic]).T, t=0.1))\n",
    "\n",
    "print(lmethod.knee(np.vstack([range(0, len(last_ubic)), \n",
    "                              last_ubic]).T))\n",
    "\n",
    "print(menger.knee(np.vstack([range(0, len(last_ubic)), \n",
    "                             last_ubic]).T))\n",
    "\n",
    "print(knee_finder(last_ubic))\n",
    "\n",
    "abs((b_bics[2]-b_bics[1])/(b_bics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4abd5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e1ff74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sindy]",
   "language": "python",
   "name": "conda-env-sindy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
