{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8401bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/sindy/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn's version: 1.6.1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from functools import partial\n",
    "from decimal import Decimal\n",
    "import numpy as np\n",
    "# from sklearnex import patch_sklearn; patch_sklearn()\n",
    "import scipy.io as sio\n",
    "import pysindy as ps\n",
    "from tqdm import trange\n",
    "\n",
    "# NSGA2, DNSGA2, SMSEMOA, AGEMOEA2\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.algorithms.moo.dnsga2 import DNSGA2\n",
    "from pymoo.algorithms.moo.sms import SMSEMOA\n",
    "from pymoo.algorithms.moo.age2 import AGEMOEA2\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from pymoo.core.sampling import Sampling\n",
    "from pymoo.core.crossover import Crossover\n",
    "from pymoo.core.mutation import Mutation\n",
    "from pymoo.core.duplicate import ElementwiseDuplicateElimination\n",
    "from pymoo.termination.default import DefaultMultiObjectiveTermination\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.visualization.scatter import Scatter\n",
    "\n",
    "from utils import *\n",
    "from skimage.restoration import estimate_sigma\n",
    "import bm3d\n",
    "from okridge.solvel0 import *\n",
    "from solvel0 import solvel0\n",
    "from best_subset import backward_refinement, brute_force_all_subsets\n",
    "from UBIC import *\n",
    "from kneed import KneeLocator\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5916f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_poly = 6\n",
    "n_derivatives = 6\n",
    "n_modules = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eaa96d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['KdV_sine_rep_big.mat', 'kuramoto_sivishinky.mat', 'KdV_rudy.mat', 'burgers.mat']\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../PDE-Discovery-EC/Datasets/\"\n",
    "print(os.listdir(data_path))\n",
    "data = sio.loadmat(os.path.join(data_path, \"kuramoto_sivishinky.mat\"))\n",
    "u_clean = (data['uu']).real; u = u_clean.copy()\n",
    "x = data['x'].ravel()\n",
    "t = data['tt'].ravel()\n",
    "dt = t[1]-t[0]; dx = x[2]-x[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1e0adc",
   "metadata": {},
   "source": [
    "### Add noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "888ee41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise level: 50.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "noise_lv = float(50)\n",
    "print(\"Noise level:\", noise_lv)\n",
    "noise = 0.01*np.abs(noise_lv)*(u.std())*np.random.randn(u.shape[0],u.shape[1])\n",
    "u = u + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f675560",
   "metadata": {},
   "source": [
    "### Gaussian process\n",
    "    - removing entries in x that show high std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3b809d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████████████████| 25/25 [00:12<00:00,  1.96it/s, 7 steps of size 4.83e-02. acc. prob=0.95]\n",
      "sample: 100%|██████████████████████| 25/25 [00:13<00:00,  1.83it/s, 7 steps of size 4.83e-02. acc. prob=0.94]\n",
      "sample: 100%|██████████████████████| 25/25 [00:12<00:00,  1.96it/s, 7 steps of size 4.83e-02. acc. prob=0.94]\n",
      "sample: 100%|██████████████████████| 25/25 [00:12<00:00,  2.06it/s, 7 steps of size 4.83e-02. acc. prob=0.94]\n",
      "sample: 100%|██████████████████████| 25/25 [00:20<00:00,  1.25it/s, 7 steps of size 4.83e-02. acc. prob=0.97]\n",
      "sample: 100%|██████████████████████| 25/25 [00:13<00:00,  1.85it/s, 7 steps of size 4.83e-02. acc. prob=0.94]\n",
      "sample: 100%|██████████████████████| 25/25 [00:13<00:00,  1.82it/s, 7 steps of size 4.83e-02. acc. prob=0.91]\n",
      "sample: 100%|██████████████████████| 25/25 [00:12<00:00,  2.04it/s, 7 steps of size 4.83e-02. acc. prob=0.94]\n",
      "sample: 100%|█████████████████████| 25/25 [00:26<00:00,  1.06s/it, 23 steps of size 4.83e-02. acc. prob=0.96]\n",
      "sample: 100%|██████████████████████| 25/25 [00:13<00:00,  1.82it/s, 7 steps of size 4.83e-02. acc. prob=0.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5562785943810014 0.9466975331306458\n"
     ]
    }
   ],
   "source": [
    "import gpax\n",
    "\n",
    "n_sampled_t = 10\n",
    "xx = colvec(x)\n",
    "u_std = np.ones((u.shape[0], n_sampled_t))\n",
    "for i in range(n_sampled_t):\n",
    "    rng_key_train, rng_key_predict = gpax.utils.get_keys()\n",
    "\n",
    "    gp_model = gpax.ExactGP(1, kernel='RBF')\n",
    "    gp_model.fit(rng_key_train, xx, u[:, np.random.choice(len(t))], \n",
    "                 num_warmup=5, num_samples=20, jitter=1e-6, \n",
    "                 chain_method='parallel', print_summary=False)\n",
    "\n",
    "    posterior_mean, f_samples = gp_model.predict(rng_key_predict, xx)\n",
    "    u_std[:, i] = np.std(f_samples[:, 0, :], axis=0)\n",
    "\n",
    "print(u_std.mean(), u_std.max())\n",
    "est_sigma = u_std.mean() # max also works well\n",
    "\n",
    "outlier = lambda arr: np.arange(len(arr))[arr-np.mean(arr) <= 3*np.std(arr)]\n",
    "filtered_indices = outlier(u_std.mean(axis=-1))\n",
    "u = u[filtered_indices, :]\n",
    "x = x[filtered_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9754901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_sampled_t = 10\n",
    "\n",
    "# kernel = RBF(length_scale=1, length_scale_bounds=(1e-2, 1e3)) + \\\n",
    "#         WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e10))\n",
    "\n",
    "# xx = colvec(x)\n",
    "# u_std = np.ones((u.shape[0], n_sampled_t))\n",
    "# for i in trange(n_sampled_t):    \n",
    "#     gpr = GaussianProcessRegressor(kernel=kernel, alpha=0.0, \n",
    "#                                    n_restarts_optimizer=10 # 20\n",
    "#                                   )\n",
    "\n",
    "#     gpr.fit(xx, u[:, np.random.choice(len(t))])\n",
    "#     _, ustd = gpr.predict(xx, return_std=True)\n",
    "#     u_std[:, i] = ustd\n",
    "    \n",
    "# est_sigma = u_std.mean() # max also works well\n",
    "# cutoff_ws = knee(range(21), \n",
    "#                  [u_std.std()]+[u_std[ws:-ws, :].std() for ws in range(1, 21)], \n",
    "#                  'linear')\n",
    "# if cutoff_ws > 0:\n",
    "#     u = u[cutoff_ws:-cutoff_ws, :]\n",
    "#     x = x[cutoff_ws:-cutoff_ws]\n",
    "    \n",
    "# est_sigma, cutoff_ws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c890b0",
   "metadata": {},
   "source": [
    "### Denoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f3d31a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = bm3d.bm3d(u, sigma_psd=est_sigma, \n",
    "              stage_arg=bm3d.BM3DStages.ALL_STAGES, \n",
    "              blockmatches=(False, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05a04eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = np.array([x.reshape(-1, 1), t.reshape(1, -1)], dtype=object)\n",
    "X, T = np.meshgrid(x, t)\n",
    "XT = np.asarray([X, T]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aaf2666",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_library = ps.PolynomialLibrary(degree=n_poly, include_bias=False)\n",
    "\n",
    "weak_lib = ps.WeakPDELibrary(\n",
    "    function_library=function_library,\n",
    "    derivative_order=n_derivatives,\n",
    "    spatiotemporal_grid=XT,\n",
    "    include_bias=True,\n",
    "    K=10000\n",
    ")\n",
    "\n",
    "X_pre = np.array(weak_lib.fit_transform(np.expand_dims(u, -1)))\n",
    "y_pre = weak_lib.convert_u_dot_integral(np.expand_dims(u, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ad9a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_poly = np.array([[p, 0] for p in range(1, n_poly+1)])\n",
    "base_derivative = np.array([[0, d] for d in range(1, n_derivatives+1)])\n",
    "modules = [(0, 0)] if weak_lib.include_bias else []\n",
    "modules += [(p, 0) for p in range(1, n_poly+1)] + \\\n",
    "            [(0, d) for d in range(1, n_derivatives+1)] + \\\n",
    "            [tuple(p+d) for d in base_derivative for p in base_poly]\n",
    "assert len(modules) == len(weak_lib.get_feature_names())\n",
    "base_features = dict(zip(modules, X_pre.T))\n",
    "u_t = y_pre.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f17d5b3-f19f-4e3c-97eb-fd58a0deb772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# miosr_subsets = solvel0(X_pre, y_pre, miosr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6435acb8-7a35-4af3-904c-a073cdb4bba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tau = 3\n",
    "# verbose = True\n",
    "# # scale = 1 <- generalized UBIC\n",
    "# scale = np.log(len(y_pre))\n",
    "# per = 75 # 80\n",
    "\n",
    "# post_means, b_bics, b_uns = baye_uncertainties(miosr_subsets, (X_pre, y_pre), \n",
    "#                                                u_type='cv1', take_sqrt=True, \n",
    "#                                                ridge_lambda=0, \n",
    "#                                                threshold=0)\n",
    "# # b_uns = ard_uns # USE ard_uns INSTEAD\n",
    "# predictions = X_pre@post_means\n",
    "# print(b_bics)\n",
    "# print(b_uns)\n",
    "# b_bics = np.array(b_bics)\n",
    "# max_complexity = len(b_bics)\n",
    "# complexities = np.arange(max_complexity)+1\n",
    "# d_complexities = complexities[decreasing_values_indices(b_bics)]\n",
    "# d_bics = b_bics[decreasing_values_indices(b_bics)]\n",
    "# slopes = np.diff(b_bics)/(np.diff(complexities)*b_bics[:-1])\n",
    "# try:\n",
    "#     thres = np.percentile(np.abs(np.diff(d_bics)/(np.diff(d_complexities)*d_bics[:-1])), per)\n",
    "#     thres = math.ceil(sci_format(thres)[0])*10**sci_format(thres)[1]\n",
    "# except IndexError:\n",
    "#     thres = 1/40\n",
    "# min_thres = 1/40\n",
    "# thres = max(thres, min_thres)\n",
    "# print(\"threshold:\", thres)\n",
    "\n",
    "# lower_bounds = []\n",
    "# for k, efi in enumerate(miosr_subsets):\n",
    "#     # assert len(efi) == np.count_nonzero(post_means[:, k:k+1])\n",
    "#     com = len(efi)\n",
    "#     lower_bound = 2*np.abs(log_like_value(predictions[:, k:k+1], y_pre))-np.log(len(y_pre))*com\n",
    "#     lower_bounds.append(lower_bound)\n",
    "\n",
    "# last_lam = np.log10(max(lower_bounds/(b_uns*scale)))\n",
    "# print(\"max_lam:\", last_lam)\n",
    "# delta = last_lam/tau\n",
    "# now_lam = last_lam-delta\n",
    "# last_ubic = UBIC(b_bics, b_uns, len(y_pre), hyp=10**last_lam, scale=scale)\n",
    "# last_bc = np.argmin(last_ubic)\n",
    "# bc_seq = [last_bc]\n",
    "# while now_lam >= 0:\n",
    "#     now_ubic = UBIC(b_bics, b_uns, len(y_pre), hyp=10**now_lam, scale=scale)\n",
    "#     now_bc = np.argmin(now_ubic)\n",
    "    \n",
    "#     diff_com = now_bc-last_bc\n",
    "#     diff_bic = b_bics[now_bc]-b_bics[last_bc]\n",
    "#     imp = np.nan\n",
    "#     if diff_com != 0:\n",
    "#         imp = abs(diff_bic/(b_bics[last_bc]*diff_com))\n",
    "    \n",
    "#     if verbose:\n",
    "#         print(min(last_bc, now_bc), '<--->', max(last_bc, now_bc), \n",
    "#               np.nan_to_num(imp, nan=np.inf))\n",
    "    \n",
    "#     if (diff_com > 0 and (diff_bic > 0 or imp < thres)) or \\\n",
    "#         (diff_com < 0 and diff_bic > 0 and imp > thres):\n",
    "#         break\n",
    "    \n",
    "#     last_lam = now_lam\n",
    "#     now_lam = round(last_lam-delta, 8)\n",
    "#     last_ubic = now_ubic\n",
    "#     last_bc = now_bc\n",
    "#     if last_bc not in bc_seq:\n",
    "#         bc_seq.append(last_bc)\n",
    "\n",
    "# # best_bc = knee_finder(last_ubic)\n",
    "# best_bc = knee(range(0, len(last_ubic)), last_ubic, 'linear')\n",
    "# if best_bc == 0 and last_bc != 0 and abs((b_bics[last_bc]-b_bics[0])/(b_bics[0]*last_bc)) > thres:\n",
    "#     best_bc = knee(range(1, len(last_ubic)), last_ubic[1:], 'linear')\n",
    "\n",
    "# if best_bc is None:\n",
    "#     best_bc = last_bc\n",
    "#     alt_bc = bc_seq[-2] if len(bc_seq) > 1 else last_bc-10\n",
    "#     cond = abs((b_bics[last_bc]-b_bics[last_bc-1])/b_bics[last_bc-1]) or \\\n",
    "#             abs((b_bics[last_bc]-b_bics[alt_bc])/(b_bics[alt_bc]*(last_bc-alt_bc)))\n",
    "#     if cond < thres: \n",
    "#         best_bc = np.argmin(last_ubic[:alt_bc+1])\n",
    "    \n",
    "# last_lam = round(last_lam, 8)\n",
    "# last_lam, last_ubic, last_bc, best_bc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb73e146",
   "metadata": {},
   "source": [
    "### Genetic algorithm with NSGA-II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fa61c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PdeDiscoveryProblem(ElementwiseProblem):\n",
    "    def __init__(self, n_poly, n_derivatives, n_modules, \n",
    "                 base_features, u_t, epsilon=0):\n",
    "        super().__init__(n_var=1, n_obj=2, n_ieq_constr=0)\n",
    "        self.n_poly = n_poly\n",
    "        self.n_derivatives = n_derivatives\n",
    "        self.n_modules = n_modules\n",
    "        self.base_features = base_features\n",
    "        self.u_t = u_t\n",
    "        self.epsilon = epsilon\n",
    "        self.sample_size = np.prod(self.u_t.shape)\n",
    "\n",
    "    def _evaluate(self, X, out, *args, **kwargs):\n",
    "        genome = X[0]\n",
    "        coeff, mse = self.compute_genome_coefficient(genome)\n",
    "        mse = mse/self.sample_size\n",
    "        complexity_penalty = self.epsilon*len(genome)\n",
    "        out[\"F\"] = [mse, complexity_penalty]\n",
    "        \n",
    "    def numericalize_genome(self, genome):\n",
    "        return np.stack([self.base_features[tuple(module)] \n",
    "                         for module in genome], axis=-1)\n",
    "\n",
    "    def compute_genome_coefficient(self, genome):\n",
    "        features = self.numericalize_genome(genome)\n",
    "        features = features.reshape(-1, features.shape[-1])\n",
    "        coeff, error, _, _ = np.linalg.lstsq(features, self.u_t, rcond=None)\n",
    "        return coeff, error[0]\n",
    "    \n",
    "    def generate_module(self, n_poly, n_derivatives):\n",
    "        return (random.randint(0, n_poly), random.randint(0, n_derivatives))\n",
    "    \n",
    "    def set_epsilon(self, epsilon):\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "class PopulationSampling(Sampling):\n",
    "    def _do(self, problem, n_samples, **kwargs):\n",
    "        X = np.full((n_samples, 1), None, dtype=object)\n",
    "        X_set = set()\n",
    "        i = 0\n",
    "        while i < n_samples:\n",
    "            n_modules = random.randint(1, problem.n_modules)\n",
    "            genome = frozenset(problem.generate_module(problem.n_poly, problem.n_derivatives) for _ in range(n_modules))\n",
    "            if len(genome) > 0 and genome not in X_set:\n",
    "                X_set.add(genome)\n",
    "                X[i, 0] = genome\n",
    "                i += 1\n",
    "        return X\n",
    "    \n",
    "class DuplicateElimination(ElementwiseDuplicateElimination):\n",
    "    def is_equal(self, g1, g2):\n",
    "        return g1.X[0] == g2.X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dea1072",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenomeCrossover(Crossover):\n",
    "    def __init__(self):\n",
    "        # define the crossover: number of parents and number of offsprings\n",
    "        super().__init__(2, 2)\n",
    "\n",
    "    def _do(self, problem, X, **kwargs):\n",
    "        # The input of has the following shape (n_parents, n_matings, n_var)\n",
    "        _, n_matings, n_var = X.shape\n",
    "\n",
    "        # The output owith the shape (n_offsprings, n_matings, n_var)\n",
    "        # Because there the number of parents and offsprings are equal it keeps the shape of X\n",
    "        Y = np.full_like(X, None, dtype=object)\n",
    "        \n",
    "        # for each mating provided\n",
    "        for k in range(n_matings):\n",
    "            # get the first and the second parent          \n",
    "            Y[0, k, 0], Y[1, k, 0] = self.crossover_permutation(X[0, k, 0], X[1, k, 0])\n",
    "            \n",
    "        return Y\n",
    "    \n",
    "    def crossover_permutation(self, genome1, genome2):\n",
    "        collection = list(genome1) + list(genome2)\n",
    "        random.shuffle(collection)\n",
    "        return frozenset(collection[:len(genome1)]), frozenset(collection[len(genome1):])\n",
    "    \n",
    "class GenomeMutation(Mutation):\n",
    "    def __init__(self, add_rate=0.4, del_rate=0.5, order_rate=0.4):\n",
    "        super().__init__()\n",
    "        self.add_rate = add_rate\n",
    "        self.del_rate = del_rate\n",
    "        self.order_rate = order_rate\n",
    "\n",
    "    def _do(self, problem, X, **kwargs):\n",
    "        for i in range(len(X)):\n",
    "            if random.random() < self.add_rate:\n",
    "                X[i, 0] = self.add_mutate(problem, X[i, 0])\n",
    "            if random.random() < self.del_rate:\n",
    "                X[i, 0] = self.del_mutate(problem, X[i, 0])\n",
    "            if random.random() < self.order_rate:\n",
    "                X[i, 0] = self.module_mutate(problem, X[i, 0])\n",
    "        return X\n",
    "    \n",
    "    def add_mutate(self, problem, genome, max_iter=3):\n",
    "        for _ in range(max_iter):\n",
    "            new_module = problem.generate_module(problem.n_poly, problem.n_derivatives)\n",
    "            if new_module not in genome:\n",
    "                return genome.union(frozenset({new_module}))\n",
    "        return genome\n",
    "    \n",
    "    def del_mutate(self, problem, genome, max_iter=3):\n",
    "        genome = list(genome)\n",
    "        lg = len(genome)\n",
    "        if lg > 0:\n",
    "            if lg == 1:\n",
    "                for _ in range(max_iter):\n",
    "                    new_module = problem.generate_module(problem.n_poly, problem.n_derivatives)\n",
    "                    if new_module != genome[0]:\n",
    "                        return frozenset({new_module})\n",
    "            else:\n",
    "                genome.pop(random.randint(0, lg-1))\n",
    "        return frozenset(genome)\n",
    "    \n",
    "    def module_mutate(self, problem, genome):\n",
    "        if len(genome) == 0:\n",
    "            return genome\n",
    "        genome = set(genome)\n",
    "        genome.remove(random.choice(list(genome)))\n",
    "        for _ in range(3):\n",
    "            new_module = problem.generate_module(problem.n_poly, problem.n_derivatives)\n",
    "            if new_module not in genome:\n",
    "                genome.add(new_module)\n",
    "                return frozenset(genome)\n",
    "        return frozenset(genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "263f3258",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_size = 500\n",
    "problem = PdeDiscoveryProblem(n_poly, n_derivatives, n_modules, \n",
    "                              base_features, u_t, 0)\n",
    "pop = PopulationSampling().do(problem, pop_size)\n",
    "pop = [[pop[i].X[0]] for i in range(len(pop))]\n",
    "epi = 10**(sci_format(np.median(problem.evaluate(pop)[:, 0]))[1])\n",
    "problem.set_epsilon(epi)\n",
    "del pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "296e4b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "n_gen  |  n_eval  | n_nds  |      eps      |   indicator  \n",
      "==========================================================\n",
      "     1 |      500 |      6 |             - |             -\n",
      "     2 |     1550 |      5 |  0.1648885685 |         ideal\n",
      "     3 |     2600 |      7 |  0.1666666667 |         nadir\n",
      "     4 |     3650 |      7 |  0.0957263939 |             f\n",
      "     5 |     4700 |      7 |  0.0315940373 |             f\n",
      "     6 |     5750 |      7 |  0.0228045773 |             f\n",
      "     7 |     6800 |      8 |  0.1428571429 |         nadir\n",
      "     8 |     7850 |      8 |  0.0211320915 |             f\n",
      "     9 |     8900 |     10 |  0.2222222222 |         nadir\n",
      "    10 |     9950 |     10 |  0.0111297148 |             f\n",
      "    11 |    11000 |      8 |  0.0000245098 |             f\n",
      "    12 |    12050 |      7 |  0.5000000000 |         nadir\n",
      "    13 |    13100 |      7 |  0.0000386990 |             f\n",
      "    14 |    14150 |      7 |  0.0000403643 |             f\n",
      "    15 |    15200 |      7 |  0.0000403643 |             f\n",
      "    16 |    16250 |      7 |  0.0000403643 |             f\n",
      "    17 |    17300 |      8 |  0.4545454545 |         nadir\n",
      "    18 |    18350 |      8 |  0.0000357451 |             f\n",
      "    19 |    19400 |     10 |  0.0273107184 |             f\n",
      "    20 |    20450 |     11 |  0.0082644629 |             f\n",
      "    21 |    21500 |     11 |  0.0000246781 |             f\n",
      "    22 |    22550 |     11 |  0.0000246781 |             f\n",
      "    23 |    23600 |     11 |  0.0082891411 |             f\n",
      "    24 |    24650 |     11 |  9.294581E-06 |             f\n",
      "    25 |    25700 |     11 |  9.294581E-06 |             f\n",
      "    26 |    26750 |     11 |  9.294581E-06 |             f\n",
      "    27 |    27800 |     12 |  0.0075842800 |             f\n",
      "    28 |    28850 |     13 |  0.0833333333 |         nadir\n",
      "    29 |    29900 |     13 |  0.000000E+00 |             f\n",
      "    30 |    30950 |     13 |  0.000000E+00 |             f\n",
      "    31 |    32000 |     13 |  0.000000E+00 |             f\n",
      "    32 |    33050 |     14 |  0.2500000000 |         nadir\n",
      "    33 |    34100 |     14 |  0.000000E+00 |             f\n",
      "    34 |    35150 |     14 |  0.1428571429 |         nadir\n",
      "    35 |    36200 |     15 |  0.1250000000 |         nadir\n",
      "    36 |    37250 |     14 |  0.0044764903 |             f\n",
      "    37 |    38300 |     14 |  3.006080E-06 |             f\n",
      "    38 |    39350 |     14 |  3.006080E-06 |             f\n",
      "    39 |    40400 |     14 |  3.006080E-06 |             f\n",
      "    40 |    41450 |     14 |  5.088350E-06 |             f\n",
      "    41 |    42500 |     13 |  0.0588235294 |         nadir\n",
      "    42 |    43550 |     14 |  0.0042038172 |             f\n",
      "    43 |    44600 |     13 |  0.0625000000 |         nadir\n",
      "    44 |    45650 |     13 |  8.024085E-07 |             f\n",
      "    45 |    46700 |     14 |  0.0044660672 |             f\n",
      "    46 |    47750 |     13 |  5.570440E-06 |             f\n",
      "    47 |    48800 |     15 |  0.0041776170 |             f\n",
      "    48 |    49850 |     15 |  0.000000E+00 |             f\n",
      "    49 |    50900 |     15 |  0.000000E+00 |             f\n",
      "    50 |    51950 |     15 |  0.000000E+00 |             f\n",
      "    51 |    53000 |     17 |  0.1111111111 |         nadir\n",
      "    52 |    54050 |     17 |  0.000000E+00 |             f\n",
      "    53 |    55100 |     16 |  0.0588235294 |         nadir\n",
      "    54 |    56150 |     16 |  0.000000E+00 |             f\n",
      "    55 |    57200 |     14 |  0.0625000000 |         nadir\n",
      "    56 |    58250 |     14 |  6.650531E-07 |             f\n",
      "    57 |    59300 |     15 |  0.0588235294 |         nadir\n",
      "    58 |    60350 |     16 |  0.1052631579 |         nadir\n",
      "    59 |    61400 |     17 |  0.0030959755 |             f\n",
      "    60 |    62450 |     16 |  0.1176470588 |         nadir\n",
      "    61 |    63500 |     17 |  0.0034621725 |             f\n",
      "    62 |    64550 |     17 |  0.000000E+00 |             f\n",
      "    63 |    65600 |     18 |  0.0032686764 |             f\n",
      "    64 |    66650 |     19 |  0.1052631579 |         nadir\n",
      "    65 |    67700 |     19 |  2.440029E-06 |             f\n",
      "    66 |    68750 |     19 |  2.440029E-06 |             f\n",
      "    67 |    69800 |     19 |  4.047438E-06 |             f\n",
      "    68 |    70850 |     20 |  0.0500000000 |         nadir\n",
      "    69 |    71900 |     20 |  9.812475E-08 |             f\n",
      "    70 |    72950 |     20 |  2.580640E-06 |             f\n",
      "    71 |    74000 |     20 |  6.100576E-06 |             f\n",
      "    72 |    75050 |     21 |  0.0909090909 |         nadir\n",
      "    73 |    76100 |     22 |  0.0020662290 |             f\n",
      "    74 |    77150 |     21 |  0.0021662876 |             f\n",
      "    75 |    78200 |     21 |  0.0021662876 |             f\n",
      "    76 |    79250 |     20 |  0.0022759336 |             f\n",
      "    77 |    80300 |     19 |  0.0023999410 |             f\n",
      "    78 |    81350 |     19 |  0.0024019941 |             f\n",
      "    79 |    82400 |     20 |  0.0022869753 |             f\n",
      "    80 |    83450 |     20 |  0.0022902786 |             f\n",
      "    81 |    84500 |     20 |  0.1000000000 |         nadir\n",
      "    82 |    85550 |     20 |  9.591006E-07 |             f\n",
      "    83 |    86600 |     20 |  9.591006E-07 |             f\n",
      "    84 |    87650 |     20 |  9.591006E-07 |             f\n",
      "    85 |    88700 |     20 |  1.582210E-06 |             f\n",
      "    86 |    89750 |     21 |  0.1304347826 |         nadir\n",
      "    87 |    90800 |     21 |  0.000000E+00 |             f\n",
      "    88 |    91850 |     22 |  0.0019762850 |             f\n",
      "    89 |    92900 |     22 |  0.0019762850 |             f\n",
      "    90 |    93950 |     22 |  0.0019773765 |             f\n",
      "    91 |    95000 |     23 |  0.0037841522 |             f\n",
      "    92 |    96050 |     24 |  0.0018116647 |             f\n",
      "    93 |    97100 |     24 |  0.0018116647 |             f\n",
      "    94 |    98150 |     24 |  0.0018118633 |             f\n",
      "    95 |    99200 |     24 |  0.0018134183 |             f\n",
      "    96 |   100250 |     24 |  0.0018134183 |             f\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[frozenset({(5, 1)})],\n",
       "       [frozenset({(3, 1), (3, 0)})],\n",
       "       [frozenset({(1, 1), (0, 4), (0, 2)})],\n",
       "       [frozenset({(1, 1), (5, 3), (0, 2), (0, 4)})],\n",
       "       [frozenset({(0, 4), (1, 1), (6, 4), (0, 2), (3, 5)})],\n",
       "       [frozenset({(0, 4), (6, 1), (1, 1), (6, 4), (0, 2), (3, 5)})],\n",
       "       [frozenset({(0, 4), (6, 1), (1, 1), (4, 6), (0, 2), (6, 6), (3, 5)})],\n",
       "       [frozenset({(2, 4), (0, 2), (0, 4), (6, 6), (6, 1), (1, 1), (4, 6), (3, 5)})],\n",
       "       [frozenset({(0, 4), (3, 4), (6, 1), (1, 1), (6, 4), (1, 4), (0, 2), (5, 6), (3, 5)})],\n",
       "       [frozenset({(0, 4), (6, 5), (4, 3), (1, 1), (4, 6), (5, 3), (0, 2), (6, 0), (6, 6), (3, 5)})],\n",
       "       [frozenset({(0, 4), (3, 4), (4, 3), (1, 1), (6, 4), (4, 2), (0, 2), (3, 6), (5, 3), (3, 5), (5, 2)})],\n",
       "       [frozenset({(6, 2), (0, 4), (3, 4), (4, 3), (1, 1), (6, 4), (4, 2), (0, 2), (3, 6), (5, 3), (3, 5), (5, 2)})],\n",
       "       [frozenset({(0, 4), (3, 4), (6, 5), (4, 3), (1, 1), (5, 4), (6, 4), (1, 4), (0, 2), (5, 6), (5, 3), (3, 5), (5, 2)})],\n",
       "       [frozenset({(2, 4), (0, 4), (3, 4), (6, 5), (4, 3), (2, 1), (1, 1), (5, 4), (1, 4), (2, 3), (0, 2), (6, 0), (5, 3), (3, 5)})],\n",
       "       [frozenset({(4, 4), (0, 4), (3, 4), (6, 5), (4, 3), (1, 1), (5, 4), (5, 3), (1, 4), (0, 6), (0, 2), (5, 6), (1, 0), (3, 5), (5, 2)})]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_optimal_models = 15\n",
    "\n",
    "termination = DefaultMultiObjectiveTermination(\n",
    "    xtol=1e-8,\n",
    "    cvtol=1e-6,\n",
    "    ftol=1e-8,\n",
    "    period=50,\n",
    "    n_max_gen=100,\n",
    "    n_max_evals=100000\n",
    ")\n",
    "\n",
    "algorithm = DNSGA2( \n",
    "                   pop_size=pop_size,\n",
    "                   sampling=PopulationSampling(),\n",
    "                   crossover=GenomeCrossover(),\n",
    "                   mutation=GenomeMutation(),\n",
    "                   eliminate_duplicates=DuplicateElimination())\n",
    "\n",
    "res = minimize(problem,\n",
    "               algorithm,\n",
    "               termination=termination,\n",
    "               verbose=True)\n",
    "\n",
    "pareto_optimal_models = res.X[np.argsort(res.F[:, 0]+res.F[:, 1])][:n_optimal_models]\n",
    "support_sizes = [len(pareto_optimal_models[i][0]) for i in range(len(pareto_optimal_models))]\n",
    "max_ss = max(support_sizes); min_ss = min(support_sizes)\n",
    "pareto_optimal_models[:n_optimal_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fe7f4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2), (0, 4), (1, 1), (5, 1), (3, 1)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significance_threshold = 0.95\n",
    "\n",
    "effective_candidates = frozenset()\n",
    "for i in range(len(pareto_optimal_models)):\n",
    "    effective_candidates = effective_candidates.union(pareto_optimal_models[i][0])\n",
    "    \n",
    "effective_candidates = {_: 0.0 for _ in effective_candidates}\n",
    "for i in range(len(pareto_optimal_models)):\n",
    "    potential_pde = list(pareto_optimal_models[i][0])\n",
    "    important_scores = shap_linear_importance(problem.numericalize_genome(potential_pde), \n",
    "                                              y_pre, scale=True)\n",
    "    for j in range(len(potential_pde)):\n",
    "        effective_candidates[potential_pde[j]] += important_scores[j]\n",
    "        \n",
    "total_score = sum(effective_candidates.values())\n",
    "for _ in effective_candidates:\n",
    "    effective_candidates[_] = effective_candidates[_]/total_score\n",
    "    \n",
    "effective_candidates = sorted(effective_candidates.items(), key=lambda _: _[1], reverse=True)\n",
    "cumulative_sum = 0\n",
    "top_candidates = []\n",
    "for i in range(len(effective_candidates)):\n",
    "    cumulative_sum += effective_candidates[i][1]\n",
    "    top_candidates.append(effective_candidates[i][0])\n",
    "    if cumulative_sum > significance_threshold:\n",
    "        break\n",
    "\n",
    "if len(top_candidates) > max_ss:\n",
    "    top_candidates = np.array(top_candidates)[np.nonzero(linear_model.ARDRegression(max_iter=500, fit_intercept=False).fit(problem.numericalize_genome(top_candidates), y_pre.ravel()).coef_)[0]]\n",
    "X_pre_top = problem.numericalize_genome(top_candidates)\n",
    "\n",
    "top_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8757b32",
   "metadata": {},
   "source": [
    "### Best-subset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dc727d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                  | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-10-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 107.80it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 106.85it/s]\n"
     ]
    }
   ],
   "source": [
    "best_subsets = solvel0(X_pre_top, y_pre, miosr=True, refine=True)\n",
    "\n",
    "# _, best_subsets = okridge_solvel0_full(X_pre_top, y_pre, \n",
    "#                                        k=X_pre_top.shape[-1], norm='l2')\n",
    "# best_subsets = backward_refinement(best_subsets, (X_pre_top, y_pre), \n",
    "#                                    ic_type='bic', verbose=False).get_best_subsets()\n",
    "\n",
    "best_subsets = [tuple(best_subsets[-1][_] for _ in bs) \n",
    "                for bs in brute_force_all_subsets(X_pre_top[:, best_subsets[-1]], y_pre)[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259fb918",
   "metadata": {},
   "source": [
    "### Model selection using UBIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96a6c77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2, 3, 4, 5, "
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  8.68421473, 10.28004975, 15.40305242, 21.70750003])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Calculate post_means for ARDRegression as well (Implement the ard_uncertainties function)\n",
    "ard_uns = []\n",
    "threshold_lambda = 5e5 # must pass assert \n",
    "for bs in best_subsets:\n",
    "    ard = linear_model.ARDRegression(fit_intercept=False, \n",
    "                                     compute_score=True,\n",
    "                                     threshold_lambda=threshold_lambda)\n",
    "    ard.fit(X_pre_top[:, bs], y_pre.ravel())\n",
    "    print(len(bs), end=', ')\n",
    "    assert len(bs) == len(np.nonzero(ard.coef_)[0])\n",
    "    pde_uncert = np.sqrt(np.diag(ard.sigma_)).sum()\n",
    "    ard_uns.append(pde_uncert)\n",
    "ard_uns = np.array(ard_uns)\n",
    "ard_uns = ard_uns/min(ard_uns)\n",
    "ard_uns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "548e4fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27003.66282118632, 25227.61104035954, -5519.321554855993, -5510.136209705846, -5501.612152810972]\n",
      "[7.41941101 8.34416558 1.         1.67901156 3.73946085]\n",
      "threshold: 1.0\n",
      "max_lam: 2.7776100167070767\n",
      "2 <---> 2 inf\n",
      "2 <---> 2 inf\n",
      "2 <---> 2 inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " array([27071.99812191, 25304.46364549, -5510.11121448, -5494.67194179,\n",
       "        -5467.17044553]),\n",
       " 2,\n",
       " 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau = 3\n",
    "verbose = True\n",
    "# scale = 1 <- generalized UBIC\n",
    "scale = np.log(len(y_pre))\n",
    "per = 75 # 80\n",
    "\n",
    "post_means, b_bics, b_uns = baye_uncertainties(best_subsets, (X_pre_top, y_pre), \n",
    "                                               u_type='cv1', take_sqrt=True, \n",
    "                                               ridge_lambda=0, \n",
    "                                               threshold=0)\n",
    "# b_uns = ard_uns # USE ard_uns INSTEAD\n",
    "predictions = X_pre_top@post_means\n",
    "print(b_bics)\n",
    "print(b_uns)\n",
    "b_bics = np.array(b_bics)\n",
    "max_complexity = len(b_bics)\n",
    "complexities = np.arange(max_complexity)+1\n",
    "d_complexities = complexities[decreasing_values_indices(b_bics)]\n",
    "d_bics = b_bics[decreasing_values_indices(b_bics)]\n",
    "slopes = np.diff(b_bics)/(np.diff(complexities)*b_bics[:-1])\n",
    "try:\n",
    "    thres = np.percentile(np.abs(np.diff(d_bics)/(np.diff(d_complexities)*d_bics[:-1])), per)\n",
    "    thres = math.ceil(sci_format(thres)[0])*10**sci_format(thres)[1]\n",
    "except IndexError:\n",
    "    thres = 1/40\n",
    "min_thres = 1/40\n",
    "thres = max(thres, min_thres)\n",
    "print(\"threshold:\", thres)\n",
    "\n",
    "lower_bounds = []\n",
    "for k, efi in enumerate(best_subsets):\n",
    "    # assert len(efi) == np.count_nonzero(post_means[:, k:k+1])\n",
    "    com = len(efi)\n",
    "    lower_bound = 2*np.abs(log_like_value(predictions[:, k:k+1], y_pre))-np.log(len(y_pre))*com\n",
    "    lower_bounds.append(lower_bound)\n",
    "\n",
    "last_lam = np.log10(max(lower_bounds/(b_uns*scale)))\n",
    "print(\"max_lam:\", last_lam)\n",
    "delta = last_lam/tau\n",
    "now_lam = last_lam-delta\n",
    "last_ubic = UBIC(b_bics, b_uns, len(y_pre), hyp=10**last_lam, scale=scale)\n",
    "last_bc = np.argmin(last_ubic)\n",
    "bc_seq = [last_bc]\n",
    "while now_lam >= 0:\n",
    "    now_ubic = UBIC(b_bics, b_uns, len(y_pre), hyp=10**now_lam, scale=scale)\n",
    "    now_bc = np.argmin(now_ubic)\n",
    "    \n",
    "    diff_com = now_bc-last_bc\n",
    "    diff_bic = b_bics[now_bc]-b_bics[last_bc]\n",
    "    imp = np.nan\n",
    "    if diff_com != 0:\n",
    "        imp = abs(diff_bic/(b_bics[last_bc]*diff_com))\n",
    "    \n",
    "    if verbose:\n",
    "        print(min(last_bc, now_bc), '<--->', max(last_bc, now_bc), \n",
    "              np.nan_to_num(imp, nan=np.inf))\n",
    "    \n",
    "    if (diff_com > 0 and (diff_bic > 0 or imp < thres)) or \\\n",
    "        (diff_com < 0 and diff_bic > 0 and imp > thres):\n",
    "        break\n",
    "    \n",
    "    last_lam = now_lam\n",
    "    now_lam = round(last_lam-delta, 8)\n",
    "    last_ubic = now_ubic\n",
    "    last_bc = now_bc\n",
    "    if last_bc not in bc_seq:\n",
    "        bc_seq.append(last_bc)\n",
    "\n",
    "# best_bc = knee_finder(last_ubic)\n",
    "best_bc = knee(range(0, len(last_ubic)), last_ubic, 'linear')\n",
    "if best_bc == 0 and last_bc != 0 and abs((b_bics[last_bc]-b_bics[0])/(b_bics[0]*last_bc)) > thres:\n",
    "    best_bc = knee(range(1, len(last_ubic)), last_ubic[1:], 'linear')\n",
    "\n",
    "if best_bc is None:\n",
    "    best_bc = last_bc\n",
    "    alt_bc = bc_seq[-2] if len(bc_seq) > 1 else last_bc-10\n",
    "    cond = abs((b_bics[last_bc]-b_bics[last_bc-1])/b_bics[last_bc-1]) or \\\n",
    "            abs((b_bics[last_bc]-b_bics[alt_bc])/(b_bics[alt_bc]*(last_bc-alt_bc)))\n",
    "    if cond < thres: \n",
    "        best_bc = np.argmin(last_ubic[:alt_bc+1])\n",
    "    \n",
    "last_lam = abs(round(last_lam, 8))\n",
    "last_lam, last_ubic, last_bc, best_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ea07764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x262.5 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "complexity_axis = [len(bs) for bs in best_subsets]\n",
    "with plt.style.context(['science']):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax2 = ax.twinx()\n",
    "    ax.set_zorder(ax2.get_zorder()+1)\n",
    "    ax.patch.set_visible(False)\n",
    "    \n",
    "    l1, = ax.plot(complexity_axis, last_ubic, 'o-', c='black', markerfacecolor='none', label=f\"$\\lambda = {abs(last_lam)}$\")\n",
    "    ax.set_xticks(complexity_axis)\n",
    "    ax.set_ylabel(\"$\\\\textrm{UBIC}$\", fontsize=12)\n",
    "    ax.set_xlabel(\"Support size\", fontsize=12)\n",
    "    ax.vlines(best_bc+1, min(last_ubic), max(last_ubic), color='red')\n",
    "    \n",
    "    l2, = ax2.plot(complexity_axis, b_uns, 'o--', c='blue', markerfacecolor='none', label=\"Uncertainty $\\\\textrm{U}^{k}$\")\n",
    "    s1 = ax2.scatter(complexity_axis[np.argmin(b_uns)], b_uns[np.argmin(b_uns)], c='blue')\n",
    "    ax2.tick_params(axis='y', labelcolor='blue')\n",
    "    \n",
    "    ax.legend([l1, l2, s1], [f\"UBIC with $\\lambda = {round(abs(last_lam), 2)}$\", \"Uncertainty $\\\\textrm{U}^{k}$\", \"Min $\\\\textrm{U}^{k}$\"], \n",
    "              labelcolor='linecolor', loc='upper center', fontsize=12)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa3a233a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "3\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2187809835035943"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some ideas\n",
    "# Better knee detection algorithm\n",
    "\n",
    "import kneeliverse.kneedle as kneedle\n",
    "import kneeliverse.lmethod as lmethod\n",
    "import kneeliverse.menger as menger\n",
    "import kneeliverse.zmethod as zmethod\n",
    "\n",
    "print(kneedle.knee(np.vstack([range(0, len(last_ubic)), \n",
    "                              last_ubic]).T, t=0.1))\n",
    "\n",
    "print(lmethod.knee(np.vstack([range(0, len(last_ubic)), \n",
    "                              last_ubic]).T))\n",
    "\n",
    "print(menger.knee(np.vstack([range(0, len(last_ubic)), \n",
    "                             last_ubic]).T))\n",
    "\n",
    "print(knee_finder(last_ubic))\n",
    "\n",
    "abs((b_bics[2]-b_bics[1])/(b_bics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4abd5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e1ff74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sindy]",
   "language": "python",
   "name": "conda-env-sindy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
