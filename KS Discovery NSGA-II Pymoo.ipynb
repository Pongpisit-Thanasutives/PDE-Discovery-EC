{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8401bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from functools import partial\n",
    "from decimal import Decimal\n",
    "import numpy as np\n",
    "from sklearnex import patch_sklearn; patch_sklearn()\n",
    "import scipy.io as sio\n",
    "import pysindy as ps\n",
    "from tqdm import trange\n",
    "\n",
    "# NSGA2, DNSGA2, SMSEMOA, AGEMOEA2\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.algorithms.moo.dnsga2 import DNSGA2\n",
    "from pymoo.algorithms.moo.sms import SMSEMOA\n",
    "from pymoo.algorithms.moo.age2 import AGEMOEA2\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from pymoo.core.sampling import Sampling\n",
    "from pymoo.core.crossover import Crossover\n",
    "from pymoo.core.mutation import Mutation\n",
    "from pymoo.core.duplicate import ElementwiseDuplicateElimination\n",
    "from pymoo.termination.default import DefaultMultiObjectiveTermination\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.visualization.scatter import Scatter\n",
    "\n",
    "from utils import *\n",
    "from skimage.restoration import estimate_sigma\n",
    "import bm3d\n",
    "from okridge.solvel0 import *\n",
    "from best_subset import backward_refinement, brute_force_all_subsets\n",
    "from UBIC import *\n",
    "from kneed import KneeLocator\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5916f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_poly = 4\n",
    "n_derivatives = 5\n",
    "n_modules = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eaa96d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['KdV_sine_rep_big.mat', 'kuramoto_sivishinky.mat', 'KdV_rudy.mat', 'burgers.mat']\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../PDE-Discovery-EC/Datasets/\"\n",
    "print(os.listdir(data_path))\n",
    "data = sio.loadmat(os.path.join(data_path, \"kuramoto_sivishinky.mat\"))\n",
    "u_clean = (data['uu']).real; u = u_clean.copy()\n",
    "x = data['x'].ravel()\n",
    "t = data['tt'].ravel()\n",
    "dt = t[1]-t[0]; dx = x[2]-x[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1e0adc",
   "metadata": {},
   "source": [
    "### Add noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "888ee41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise level: 50.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "noise_lv = float(50)\n",
    "print(\"Noise level:\", noise_lv)\n",
    "noise = 0.01*np.abs(noise_lv)*(u.std())*np.random.randn(u.shape[0],u.shape[1])\n",
    "u = u + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f675560",
   "metadata": {},
   "source": [
    "### Gaussian process\n",
    "    - removing entries in x that show high std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3b809d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████████████| 25/25 [00:09<00:00,  2.61it/s, 7 steps of size 4.83e-02. acc. prob=0.95]\n",
      "sample: 100%|██████████████████| 25/25 [00:08<00:00,  2.85it/s, 7 steps of size 4.83e-02. acc. prob=0.94]\n",
      "sample: 100%|██████████████████| 25/25 [00:08<00:00,  2.87it/s, 7 steps of size 4.83e-02. acc. prob=0.94]\n",
      "sample: 100%|██████████████████| 25/25 [00:08<00:00,  2.94it/s, 7 steps of size 4.83e-02. acc. prob=0.94]\n",
      "sample: 100%|██████████████████| 25/25 [00:13<00:00,  1.89it/s, 7 steps of size 4.83e-02. acc. prob=0.97]\n",
      "sample: 100%|██████████████████| 25/25 [00:09<00:00,  2.60it/s, 7 steps of size 4.83e-02. acc. prob=0.94]\n",
      "sample: 100%|██████████████████| 25/25 [00:07<00:00,  3.20it/s, 7 steps of size 4.83e-02. acc. prob=0.90]\n",
      "sample: 100%|██████████████████| 25/25 [00:09<00:00,  2.64it/s, 7 steps of size 4.83e-02. acc. prob=0.93]\n",
      "sample: 100%|█████████████████| 25/25 [00:19<00:00,  1.28it/s, 23 steps of size 4.83e-02. acc. prob=0.96]\n",
      "sample: 100%|██████████████████| 25/25 [00:09<00:00,  2.59it/s, 7 steps of size 4.83e-02. acc. prob=0.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5564492114412133 0.9466760754585266\n"
     ]
    }
   ],
   "source": [
    "import gpax\n",
    "\n",
    "n_sampled_t = 10\n",
    "xx = colvec(x)\n",
    "u_std = np.ones((u.shape[0], n_sampled_t))\n",
    "for i in range(n_sampled_t):\n",
    "    rng_key_train, rng_key_predict = gpax.utils.get_keys()\n",
    "\n",
    "    gp_model = gpax.ExactGP(1, kernel='RBF')\n",
    "    gp_model.fit(rng_key_train, xx, u[:, np.random.choice(len(t))], \n",
    "                 num_warmup=5, num_samples=20, jitter=1e-6, \n",
    "                 chain_method='parallel', print_summary=False)\n",
    "\n",
    "    posterior_mean, f_samples = gp_model.predict(rng_key_predict, xx)\n",
    "    u_std[:, i] = np.std(f_samples[:, 0, :], axis=0)\n",
    "\n",
    "print(u_std.mean(), u_std.max())\n",
    "est_sigma = u_std.mean() # max also works well\n",
    "\n",
    "outlier = lambda arr: np.arange(len(arr))[arr-np.mean(arr) <= 3*np.std(arr)]\n",
    "filtered_indices = outlier(u_std.mean(axis=-1))\n",
    "u = u[filtered_indices, :]\n",
    "x = x[filtered_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9754901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_sampled_t = 10\n",
    "\n",
    "# kernel = RBF(length_scale=1, length_scale_bounds=(1e-2, 1e3)) + \\\n",
    "#         WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e10))\n",
    "\n",
    "# xx = colvec(x)\n",
    "# u_std = np.ones((u.shape[0], n_sampled_t))\n",
    "# for i in trange(n_sampled_t):    \n",
    "#     gpr = GaussianProcessRegressor(kernel=kernel, alpha=0.0, \n",
    "#                                    n_restarts_optimizer=10 # 20\n",
    "#                                   )\n",
    "\n",
    "#     gpr.fit(xx, u[:, np.random.choice(len(t))])\n",
    "#     _, ustd = gpr.predict(xx, return_std=True)\n",
    "#     u_std[:, i] = ustd\n",
    "    \n",
    "# est_sigma = u_std.mean() # max also works well\n",
    "# cutoff_ws = knee(range(21), \n",
    "#                  [u_std.std()]+[u_std[ws:-ws, :].std() for ws in range(1, 21)], \n",
    "#                  'linear')\n",
    "# if cutoff_ws > 0:\n",
    "#     u = u[cutoff_ws:-cutoff_ws, :]\n",
    "#     x = x[cutoff_ws:-cutoff_ws]\n",
    "    \n",
    "# est_sigma, cutoff_ws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c890b0",
   "metadata": {},
   "source": [
    "### Denoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f3d31a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = bm3d.bm3d(u, sigma_psd=est_sigma, \n",
    "              stage_arg=bm3d.BM3DStages.ALL_STAGES, \n",
    "              blockmatches=(False, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05a04eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = np.array([x.reshape(-1, 1), t.reshape(1, -1)], dtype=object)\n",
    "X, T = np.meshgrid(x, t)\n",
    "XT = np.asarray([X, T]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aaf2666",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_library = ps.PolynomialLibrary(degree=n_poly, include_bias=False)\n",
    "\n",
    "weak_lib = ps.WeakPDELibrary(\n",
    "    function_library=function_library,\n",
    "    derivative_order=n_derivatives,\n",
    "    spatiotemporal_grid=XT,\n",
    "    include_bias=True,\n",
    "    K=10000\n",
    ")\n",
    "\n",
    "X_pre = np.array(weak_lib.fit_transform(np.expand_dims(u, -1)))\n",
    "y_pre = weak_lib.convert_u_dot_integral(np.expand_dims(u, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ad9a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_poly = np.array([[p, 0] for p in range(1, n_poly+1)])\n",
    "base_derivative = np.array([[0, d] for d in range(1, n_derivatives+1)])\n",
    "modules = [(0, 0)] if weak_lib.include_bias else []\n",
    "modules += [(p, 0) for p in range(1, n_poly+1)] + \\\n",
    "            [(0, d) for d in range(1, n_derivatives+1)] + \\\n",
    "            [tuple(p+d) for d in base_derivative for p in base_poly]\n",
    "assert len(modules) == len(weak_lib.get_feature_names())\n",
    "base_features = dict(zip(modules, X_pre.T))\n",
    "u_t = y_pre.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb73e146",
   "metadata": {},
   "source": [
    "### Genetic algorithm with NSGA-II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fa61c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PdeDiscoveryProblem(ElementwiseProblem):\n",
    "    def __init__(self, n_poly, n_derivatives, n_modules, \n",
    "                 base_features, u_t, epsilon=0):\n",
    "        super().__init__(n_var=1, n_obj=2, n_ieq_constr=0)\n",
    "        self.n_poly = n_poly\n",
    "        self.n_derivatives = n_derivatives\n",
    "        self.n_modules = n_modules\n",
    "        self.base_features = base_features\n",
    "        self.u_t = u_t\n",
    "        self.epsilon = epsilon\n",
    "        self.sample_size = np.prod(self.u_t.shape)\n",
    "\n",
    "    def _evaluate(self, X, out, *args, **kwargs):\n",
    "        genome = X[0]\n",
    "        coeff, mse = self.compute_genome_coefficient(genome)\n",
    "        mse = mse/self.sample_size\n",
    "        complexity_penalty = self.epsilon*len(genome)\n",
    "        out[\"F\"] = [mse, complexity_penalty]\n",
    "        \n",
    "    def numericalize_genome(self, genome):\n",
    "        return np.stack([self.base_features[tuple(module)] \n",
    "                         for module in genome], axis=-1)\n",
    "\n",
    "    def compute_genome_coefficient(self, genome):\n",
    "        features = self.numericalize_genome(genome)\n",
    "        features = features.reshape(-1, features.shape[-1])\n",
    "        coeff, error, _, _ = np.linalg.lstsq(features, self.u_t, rcond=None)\n",
    "        return coeff, error[0]\n",
    "    \n",
    "    def generate_module(self, n_poly, n_derivatives):\n",
    "        return (random.randint(0, n_poly), random.randint(0, n_derivatives))\n",
    "    \n",
    "    def set_epsilon(self, epsilon):\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "class PopulationSampling(Sampling):\n",
    "    def _do(self, problem, n_samples, **kwargs):\n",
    "        X = np.full((n_samples, 1), None, dtype=object)\n",
    "        X_set = set()\n",
    "        i = 0\n",
    "        while i < n_samples:\n",
    "            n_modules = random.randint(1, problem.n_modules)\n",
    "            genome = frozenset(problem.generate_module(problem.n_poly, problem.n_derivatives) for _ in range(n_modules))\n",
    "            if len(genome) > 0 and genome not in X_set:\n",
    "                X_set.add(genome)\n",
    "                X[i, 0] = genome\n",
    "                i += 1\n",
    "        return X\n",
    "    \n",
    "class DuplicateElimination(ElementwiseDuplicateElimination):\n",
    "    def is_equal(self, g1, g2):\n",
    "        return g1.X[0] == g2.X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dea1072",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenomeCrossover(Crossover):\n",
    "    def __init__(self):\n",
    "        # define the crossover: number of parents and number of offsprings\n",
    "        super().__init__(2, 2)\n",
    "\n",
    "    def _do(self, problem, X, **kwargs):\n",
    "        # The input of has the following shape (n_parents, n_matings, n_var)\n",
    "        _, n_matings, n_var = X.shape\n",
    "\n",
    "        # The output owith the shape (n_offsprings, n_matings, n_var)\n",
    "        # Because there the number of parents and offsprings are equal it keeps the shape of X\n",
    "        Y = np.full_like(X, None, dtype=object)\n",
    "        \n",
    "        # for each mating provided\n",
    "        for k in range(n_matings):\n",
    "            # get the first and the second parent          \n",
    "            Y[0, k, 0], Y[1, k, 0] = self.crossover_permutation(X[0, k, 0], X[1, k, 0])\n",
    "            \n",
    "        return Y\n",
    "    \n",
    "    def crossover_permutation(self, genome1, genome2):\n",
    "        collection = list(genome1) + list(genome2)\n",
    "        random.shuffle(collection)\n",
    "        return frozenset(collection[:len(genome1)]), frozenset(collection[len(genome1):])\n",
    "    \n",
    "class GenomeMutation(Mutation):\n",
    "    def __init__(self, add_rate=0.4, del_rate=0.5, order_rate=0.4):\n",
    "        super().__init__()\n",
    "        self.add_rate = add_rate\n",
    "        self.del_rate = del_rate\n",
    "        self.order_rate = order_rate\n",
    "\n",
    "    def _do(self, problem, X, **kwargs):\n",
    "        for i in range(len(X)):\n",
    "            if random.random() < self.add_rate:\n",
    "                X[i, 0] = self.add_mutate(problem, X[i, 0])\n",
    "            if random.random() < self.del_rate:\n",
    "                X[i, 0] = self.del_mutate(problem, X[i, 0])\n",
    "            if random.random() < self.order_rate:\n",
    "                X[i, 0] = self.module_mutate(problem, X[i, 0])\n",
    "        return X\n",
    "    \n",
    "    def add_mutate(self, problem, genome, max_iter=3):\n",
    "        for _ in range(max_iter):\n",
    "            new_module = problem.generate_module(problem.n_poly, problem.n_derivatives)\n",
    "            if new_module not in genome:\n",
    "                return genome.union(frozenset({new_module}))\n",
    "        return genome\n",
    "    \n",
    "    def del_mutate(self, problem, genome, max_iter=3):\n",
    "        genome = list(genome)\n",
    "        lg = len(genome)\n",
    "        if lg > 0:\n",
    "            if lg == 1:\n",
    "                for _ in range(max_iter):\n",
    "                    new_module = problem.generate_module(problem.n_poly, problem.n_derivatives)\n",
    "                    if new_module != genome[0]:\n",
    "                        return frozenset({new_module})\n",
    "            else:\n",
    "                genome.pop(random.randint(0, lg-1))\n",
    "        return frozenset(genome)\n",
    "    \n",
    "    def module_mutate(self, problem, genome):\n",
    "        if len(genome) == 0:\n",
    "            return genome\n",
    "        genome = set(genome)\n",
    "        genome.remove(random.choice(list(genome)))\n",
    "        for _ in range(3):\n",
    "            new_module = problem.generate_module(problem.n_poly, problem.n_derivatives)\n",
    "            if new_module not in genome:\n",
    "                genome.add(new_module)\n",
    "                return frozenset(genome)\n",
    "        return frozenset(genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "263f3258",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_size = 500\n",
    "problem = PdeDiscoveryProblem(n_poly, n_derivatives, n_modules, \n",
    "                              base_features, u_t, 0)\n",
    "pop = PopulationSampling().do(problem, pop_size)\n",
    "pop = [[pop[i].X[0]] for i in range(len(pop))]\n",
    "epi = 10**(sci_format(np.median(problem.evaluate(pop)[:, 0]))[1])\n",
    "problem.set_epsilon(epi)\n",
    "del pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "296e4b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "n_gen  |  n_eval  | n_nds  |      eps      |   indicator  \n",
      "==========================================================\n",
      "     1 |      500 |      5 |             - |             -\n",
      "     2 |     1550 |      6 |  0.0277777864 |             f\n",
      "     3 |     2600 |      6 |  0.1428571429 |         nadir\n",
      "     4 |     3650 |      7 |  0.0204664047 |             f\n",
      "     5 |     4700 |      7 |  0.0027041345 |             f\n",
      "     6 |     5750 |      7 |  0.0047373142 |             f\n",
      "     7 |     6800 |      8 |  0.0178571479 |             f\n",
      "     8 |     7850 |      8 |  0.0178942973 |             f\n",
      "     9 |     8900 |      9 |  0.2222222222 |         nadir\n",
      "    10 |     9950 |      9 |  3.828621E-06 |             f\n",
      "    11 |    11000 |      9 |  6.137031E-06 |             f\n",
      "    12 |    12050 |      9 |  6.137031E-06 |             f\n",
      "    13 |    13100 |      9 |  0.0000201265 |             f\n",
      "    14 |    14150 |      9 |  0.1250000000 |         nadir\n",
      "    15 |    15200 |     10 |  0.1111111111 |         nadir\n",
      "    16 |    16250 |      9 |  0.0000241878 |             f\n",
      "    17 |    17300 |      8 |  0.1250000000 |         nadir\n",
      "    18 |    18350 |      9 |  0.2000000000 |         nadir\n",
      "    19 |    19400 |      9 |  9.453032E-06 |             f\n",
      "    20 |    20450 |     10 |  0.0100098023 |             f\n",
      "    21 |    21500 |     10 |  0.000000E+00 |             f\n",
      "    22 |    22550 |     11 |  0.1666666667 |         nadir\n",
      "    23 |    23600 |     11 |  6.356495E-06 |             f\n",
      "    24 |    24650 |     11 |  8.420511E-06 |             f\n",
      "    25 |    25700 |     11 |  0.0909090909 |         nadir\n",
      "    26 |    26750 |     11 |  5.037418E-06 |             f\n",
      "    27 |    27800 |     12 |  0.0075873860 |             f\n",
      "    28 |    28850 |     12 |  0.000000E+00 |             f\n",
      "    29 |    29900 |     13 |  0.1538461538 |         nadir\n",
      "    30 |    30950 |     13 |  0.000000E+00 |             f\n",
      "    31 |    32000 |     15 |  0.1333333333 |         nadir\n",
      "    32 |    33050 |     15 |  1.312209E-06 |             f\n",
      "    33 |    34100 |     16 |  0.0625000000 |         nadir\n",
      "    34 |    35150 |     16 |  0.000000E+00 |             f\n",
      "    35 |    36200 |     16 |  1.281156E-07 |             f\n",
      "    36 |    37250 |     16 |  0.0039063781 |             f\n",
      "    37 |    38300 |     16 |  2.469746E-06 |             f\n",
      "    38 |    39350 |     15 |  0.1428571429 |         nadir\n",
      "    39 |    40400 |     15 |  3.740990E-06 |             f\n",
      "    40 |    41450 |     15 |  3.740990E-06 |             f\n",
      "    41 |    42500 |     15 |  4.693814E-06 |             f\n",
      "    42 |    43550 |     15 |  4.693814E-06 |             f\n",
      "    43 |    44600 |     14 |  9.999001E-06 |             f\n",
      "    44 |    45650 |     15 |  0.1250000000 |         nadir\n",
      "    45 |    46700 |     15 |  0.000000E+00 |             f\n",
      "    46 |    47750 |     15 |  0.0041666667 |             f\n",
      "    47 |    48800 |     15 |  1.926036E-06 |             f\n",
      "    48 |    49850 |     16 |  0.0588235294 |         nadir\n",
      "    49 |    50900 |     16 |  1.547109E-06 |             f\n",
      "    50 |    51950 |     16 |  1.547109E-06 |             f\n",
      "    51 |    53000 |     16 |  1.547109E-06 |             f\n",
      "    52 |    54050 |     16 |  1.547109E-06 |             f\n",
      "    53 |    55100 |     16 |  1.705373E-06 |             f\n",
      "    54 |    56150 |     16 |  1.705373E-06 |             f\n",
      "    55 |    57200 |     16 |  1.705373E-06 |             f\n",
      "    56 |    58250 |     16 |  2.280507E-06 |             f\n",
      "    57 |    59300 |     16 |  3.812066E-06 |             f\n",
      "    58 |    60350 |     16 |  3.812066E-06 |             f\n",
      "    59 |    61400 |     16 |  5.073626E-06 |             f\n",
      "    60 |    62450 |     16 |  5.147709E-06 |             f\n",
      "    61 |    63500 |     17 |  0.0034650526 |             f\n",
      "    62 |    64550 |     17 |  0.000000E+00 |             f\n",
      "    63 |    65600 |     17 |  0.000000E+00 |             f\n",
      "    64 |    66650 |     17 |  4.862876E-07 |             f\n",
      "    65 |    67700 |     18 |  0.1052631579 |         nadir\n",
      "    66 |    68750 |     18 |  2.043753E-07 |             f\n",
      "    67 |    69800 |     17 |  3.425523E-06 |             f\n",
      "    68 |    70850 |     17 |  3.590756E-06 |             f\n",
      "    69 |    71900 |     17 |  4.217550E-06 |             f\n",
      "    70 |    72950 |     17 |  4.217550E-06 |             f\n",
      "    71 |    74000 |     17 |  4.217550E-06 |             f\n",
      "    72 |    75050 |     16 |  0.1176470588 |         nadir\n",
      "    73 |    76100 |     16 |  0.000000E+00 |             f\n",
      "    74 |    77150 |     16 |  0.000000E+00 |             f\n",
      "    75 |    78200 |     17 |  0.0034602076 |             f\n",
      "    76 |    79250 |     18 |  0.1052631579 |         nadir\n",
      "    77 |    80300 |     18 |  0.0555555556 |         nadir\n",
      "    78 |    81350 |     18 |  0.000000E+00 |             f\n",
      "    79 |    82400 |     18 |  0.000000E+00 |             f\n",
      "    80 |    83450 |     18 |  0.000000E+00 |             f\n",
      "    81 |    84500 |     18 |  0.000000E+00 |             f\n",
      "    82 |    85550 |     18 |  4.198591E-07 |             f\n",
      "    83 |    86600 |     18 |  9.578018E-07 |             f\n",
      "    84 |    87650 |     18 |  9.578018E-07 |             f\n",
      "    85 |    88700 |     18 |  2.261677E-06 |             f\n",
      "    86 |    89750 |     18 |  2.714385E-06 |             f\n",
      "    87 |    90800 |     17 |  3.336594E-06 |             f\n",
      "    88 |    91850 |     17 |  3.336594E-06 |             f\n",
      "    89 |    92900 |     17 |  3.336594E-06 |             f\n",
      "    90 |    93950 |     18 |  0.0030895710 |             f\n",
      "    91 |    95000 |     19 |  0.0526315789 |         nadir\n",
      "    92 |    96050 |     19 |  1.060824E-06 |             f\n",
      "    93 |    97100 |     19 |  1.939521E-06 |             f\n",
      "    94 |    98150 |     19 |  2.015998E-06 |             f\n",
      "    95 |    99200 |     20 |  0.0026337790 |             f\n",
      "    96 |   100250 |     20 |  0.000000E+00 |             f\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[frozenset({(3, 1)})],\n",
       "       [frozenset({(3, 1), (3, 0)})],\n",
       "       [frozenset({(1, 1), (0, 4), (0, 2)})],\n",
       "       [frozenset({(1, 1), (0, 4), (3, 5), (0, 2)})],\n",
       "       [frozenset({(4, 4), (0, 4), (1, 1), (0, 2), (3, 5)})],\n",
       "       [frozenset({(4, 4), (0, 4), (1, 1), (0, 2), (4, 1), (3, 5)})],\n",
       "       [frozenset({(4, 4), (4, 0), (0, 4), (1, 1), (2, 3), (0, 2), (3, 5)})],\n",
       "       [frozenset({(4, 4), (0, 4), (3, 4), (1, 1), (2, 3), (0, 2), (3, 2), (3, 5)})],\n",
       "       [frozenset({(4, 4), (4, 0), (0, 4), (4, 3), (1, 1), (2, 0), (0, 2), (4, 5), (3, 5)})],\n",
       "       [frozenset({(4, 4), (4, 0), (0, 4), (4, 3), (1, 1), (2, 0), (0, 2), (4, 5), (3, 3), (3, 5)})],\n",
       "       [frozenset({(4, 4), (1, 2), (0, 4), (3, 4), (4, 3), (1, 1), (4, 2), (4, 5), (0, 2), (3, 2), (3, 5)})],\n",
       "       [frozenset({(4, 4), (1, 2), (0, 4), (3, 4), (4, 3), (1, 1), (1, 4), (0, 2), (3, 3), (4, 5), (3, 2), (3, 5)})],\n",
       "       [frozenset({(4, 4), (0, 1), (1, 2), (0, 4), (3, 4), (4, 3), (1, 1), (3, 0), (0, 2), (4, 5), (3, 3), (3, 2), (3, 5)})],\n",
       "       [frozenset({(4, 4), (1, 2), (0, 4), (3, 4), (4, 0), (4, 3), (1, 1), (4, 2), (3, 0), (0, 2), (4, 5), (3, 3), (3, 2), (3, 5)})],\n",
       "       [frozenset({(4, 4), (2, 4), (1, 2), (0, 4), (4, 0), (3, 4), (4, 3), (1, 1), (4, 2), (3, 0), (4, 5), (0, 2), (3, 3), (3, 2), (3, 5)})]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_optimal_models = 15\n",
    "\n",
    "termination = DefaultMultiObjectiveTermination(\n",
    "    xtol=1e-8,\n",
    "    cvtol=1e-6,\n",
    "    ftol=1e-8,\n",
    "    period=50,\n",
    "    n_max_gen=100,\n",
    "    n_max_evals=100000\n",
    ")\n",
    "\n",
    "algorithm = DNSGA2( \n",
    "                   pop_size=pop_size,\n",
    "                   sampling=PopulationSampling(),\n",
    "                   crossover=GenomeCrossover(),\n",
    "                   mutation=GenomeMutation(),\n",
    "                   eliminate_duplicates=DuplicateElimination())\n",
    "\n",
    "res = minimize(problem,\n",
    "               algorithm,\n",
    "               termination=termination,\n",
    "               verbose=True)\n",
    "\n",
    "pareto_optimal_models = res.X[np.argsort(res.F[:, 0]+res.F[:, 1])][:n_optimal_models]\n",
    "support_sizes = [len(pareto_optimal_models[i][0]) for i in range(len(pareto_optimal_models))]\n",
    "max_ss = max(support_sizes); min_ss = min(support_sizes)\n",
    "pareto_optimal_models[:n_optimal_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fe7f4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/pongpisit/anaconda3/envs/pysr_latest/lib/python3.11/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 2), (0, 4), (1, 1), (3, 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significance_threshold = 0.95\n",
    "\n",
    "effective_candidates = frozenset()\n",
    "for i in range(len(pareto_optimal_models)):\n",
    "    effective_candidates = effective_candidates.union(pareto_optimal_models[i][0])\n",
    "    \n",
    "effective_candidates = {_: 0.0 for _ in effective_candidates}\n",
    "for i in range(len(pareto_optimal_models)):\n",
    "    potential_pde = list(pareto_optimal_models[i][0])\n",
    "    important_scores = shap_linear_importance(problem.numericalize_genome(potential_pde), \n",
    "                                              y_pre, scale=True)\n",
    "    for j in range(len(potential_pde)):\n",
    "        effective_candidates[potential_pde[j]] += important_scores[j]\n",
    "        \n",
    "total_score = sum(effective_candidates.values())\n",
    "for _ in effective_candidates:\n",
    "    effective_candidates[_] = effective_candidates[_]/total_score\n",
    "    \n",
    "effective_candidates = sorted(effective_candidates.items(), key=lambda _: _[1], reverse=True)\n",
    "cumulative_sum = 0\n",
    "top_candidates = []\n",
    "for i in range(len(effective_candidates)):\n",
    "    cumulative_sum += effective_candidates[i][1]\n",
    "    top_candidates.append(effective_candidates[i][0])\n",
    "    if cumulative_sum > significance_threshold:\n",
    "        break\n",
    "\n",
    "if len(top_candidates) > max_ss:\n",
    "    top_candidates = np.array(top_candidates)[np.nonzero(linear_model.ARDRegression(max_iter=500, fit_intercept=False).fit(problem.numericalize_genome(top_candidates), y_pre.ravel()).coef_)[0]]\n",
    "X_pre_top = problem.numericalize_genome(top_candidates)\n",
    "\n",
    "top_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8757b32",
   "metadata": {},
   "source": [
    "### Best-subset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dc727d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.68it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 421.86it/s]\n"
     ]
    }
   ],
   "source": [
    "_, best_subsets = okridge_solvel0_full(X_pre_top, y_pre, \n",
    "                                       k=X_pre_top.shape[-1], norm='l2')\n",
    "best_subsets = backward_refinement(best_subsets, (X_pre_top, y_pre), \n",
    "                                   ic_type='bic', verbose=False).get_best_subsets()\n",
    "best_subsets = [tuple(best_subsets[-1][_] for _ in bs) \n",
    "                for bs in brute_force_all_subsets(X_pre_top[:, best_subsets[-1]], y_pre)[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259fb918",
   "metadata": {},
   "source": [
    "### Model selection using UBIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96a6c77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2, 3, 4, "
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 2.3714422 , 2.70113939, 4.05842934])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Calculate post_means for ARDRegression as well (Implement the ard_uncertainties function)\n",
    "ard_uns = []\n",
    "threshold_lambda = 5e5 # must pass assert \n",
    "for bs in best_subsets:\n",
    "    ard = linear_model.ARDRegression(fit_intercept=False, \n",
    "                                     compute_score=True,\n",
    "                                     threshold_lambda=threshold_lambda)\n",
    "    ard.fit(X_pre_top[:, bs], y_pre.ravel())\n",
    "    print(len(bs), end=', ')\n",
    "    assert len(bs) == len(np.nonzero(ard.coef_)[0])\n",
    "    pde_uncert = np.sqrt(np.diag(ard.sigma_)).sum()\n",
    "    ard_uns.append(pde_uncert)\n",
    "ard_uns = np.array(ard_uns)\n",
    "ard_uns = ard_uns/min(ard_uns)\n",
    "ard_uns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "548e4fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28248.177889690058, 25323.543516836744, -5429.506264208034, -5420.295967869681]\n",
      "[7.5627152  7.11955066 1.         1.6782476 ]\n",
      "threshold: 1.0\n",
      "max_lam: 2.770484658497113\n",
      "2 <---> 2 inf\n",
      "2 <---> 2 inf\n",
      "2 <---> 2 inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " array([28317.83307081, 25389.11700173, -5420.29592384, -5404.83873627]),\n",
       " 2,\n",
       " 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau = 3\n",
    "verbose = True\n",
    "# scale = 1 <- generalized UBIC\n",
    "scale = np.log(len(y_pre))\n",
    "per = 75 # 80\n",
    "\n",
    "post_means, b_bics, b_uns = baye_uncertainties(best_subsets, (X_pre_top, y_pre), \n",
    "                                               u_type='cv1', take_sqrt=True, \n",
    "                                               ridge_lambda=0, \n",
    "                                               threshold=0)\n",
    "# b_uns = ard_uns # USE ard_uns INSTEAD\n",
    "predictions = X_pre_top@post_means\n",
    "print(b_bics)\n",
    "print(b_uns)\n",
    "b_bics = np.array(b_bics)\n",
    "max_complexity = len(b_bics)\n",
    "complexities = np.arange(max_complexity)+1\n",
    "d_complexities = complexities[decreasing_values_indices(b_bics)]\n",
    "d_bics = b_bics[decreasing_values_indices(b_bics)]\n",
    "slopes = np.diff(b_bics)/(np.diff(complexities)*b_bics[:-1])\n",
    "try:\n",
    "    thres = np.percentile(np.abs(np.diff(d_bics)/(np.diff(d_complexities)*d_bics[:-1])), per)\n",
    "    thres = math.ceil(sci_format(thres)[0])*10**sci_format(thres)[1]\n",
    "except IndexError:\n",
    "    thres = 1/40\n",
    "min_thres = 1/40\n",
    "thres = max(thres, min_thres)\n",
    "print(\"threshold:\", thres)\n",
    "\n",
    "lower_bounds = []\n",
    "for k, efi in enumerate(best_subsets):\n",
    "    # assert len(efi) == np.count_nonzero(post_means[:, k:k+1])\n",
    "    com = len(efi)\n",
    "    lower_bound = 2*np.abs(log_like_value(predictions[:, k:k+1], y_pre))-np.log(len(y_pre))*com\n",
    "    lower_bounds.append(lower_bound)\n",
    "\n",
    "last_lam = np.log10(max(lower_bounds/(b_uns*scale)))\n",
    "print(\"max_lam:\", last_lam)\n",
    "delta = last_lam/tau\n",
    "now_lam = last_lam-delta\n",
    "last_ubic = UBIC(b_bics, b_uns, len(y_pre), hyp=10**last_lam, scale=scale)\n",
    "last_bc = np.argmin(last_ubic)\n",
    "bc_seq = [last_bc]\n",
    "while now_lam >= 0:\n",
    "    now_ubic = UBIC(b_bics, b_uns, len(y_pre), hyp=10**now_lam, scale=scale)\n",
    "    now_bc = np.argmin(now_ubic)\n",
    "    \n",
    "    diff_com = now_bc-last_bc\n",
    "    diff_bic = b_bics[now_bc]-b_bics[last_bc]\n",
    "    imp = np.nan\n",
    "    if diff_com != 0:\n",
    "        imp = abs(diff_bic/(b_bics[last_bc]*diff_com))\n",
    "    \n",
    "    if verbose:\n",
    "        print(min(last_bc, now_bc), '<--->', max(last_bc, now_bc), \n",
    "              np.nan_to_num(imp, nan=np.inf))\n",
    "    \n",
    "    if (diff_com > 0 and (diff_bic > 0 or imp < thres)) or \\\n",
    "        (diff_com < 0 and diff_bic > 0 and imp > thres):\n",
    "        break\n",
    "    \n",
    "    last_lam = now_lam\n",
    "    now_lam = round(last_lam-delta, 8)\n",
    "    last_ubic = now_ubic\n",
    "    last_bc = now_bc\n",
    "    if last_bc not in bc_seq:\n",
    "        bc_seq.append(last_bc)\n",
    "\n",
    "# best_bc = knee_finder(last_ubic)\n",
    "best_bc = knee(range(0, len(last_ubic)), last_ubic, 'linear')\n",
    "if best_bc == 0 and last_bc != 0 and abs((b_bics[last_bc]-b_bics[0])/(b_bics[0]*last_bc)) > thres:\n",
    "    best_bc = knee(range(1, len(last_ubic)), last_ubic[1:], 'linear')\n",
    "\n",
    "if best_bc is None:\n",
    "    best_bc = last_bc\n",
    "    alt_bc = bc_seq[-2] if len(bc_seq) > 1 else last_bc-10\n",
    "    cond = abs((b_bics[last_bc]-b_bics[last_bc-1])/b_bics[last_bc-1]) or \\\n",
    "            abs((b_bics[last_bc]-b_bics[alt_bc])/(b_bics[alt_bc]*(last_bc-alt_bc)))\n",
    "    if cond < thres: \n",
    "        best_bc = np.argmin(last_ubic[:alt_bc+1])\n",
    "    \n",
    "last_lam = abs(round(last_lam, 8))\n",
    "last_lam, last_ubic, last_bc, best_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ea07764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x262.5 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "complexity_axis = [len(bs) for bs in best_subsets]\n",
    "with plt.style.context(['science']):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax2 = ax.twinx()\n",
    "    ax.set_zorder(ax2.get_zorder()+1)\n",
    "    ax.patch.set_visible(False)\n",
    "    \n",
    "    l1, = ax.plot(complexity_axis, last_ubic, 'o-', c='black', markerfacecolor='none', label=f\"$\\lambda = {abs(last_lam)}$\")\n",
    "    ax.set_xticks(complexity_axis)\n",
    "    ax.set_ylabel(\"$\\\\textrm{UBIC}$\", fontsize=12)\n",
    "    ax.set_xlabel(\"Support size\", fontsize=12)\n",
    "    ax.vlines(best_bc+1, min(last_ubic), max(last_ubic), color='red')\n",
    "    \n",
    "    l2, = ax2.plot(complexity_axis, b_uns, 'o--', c='blue', markerfacecolor='none', label=\"Uncertainty $\\\\textrm{U}^{k}$\")\n",
    "    s1 = ax2.scatter(complexity_axis[np.argmin(b_uns)], b_uns[np.argmin(b_uns)], c='blue')\n",
    "    ax2.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "    ax.legend([l1, l2, s1], [f\"UBIC with $\\lambda = {round(abs(last_lam), 2)}$\", \"Uncertainty $\\\\textrm{U}^{k}$\", \"Min $\\\\textrm{U}^{k}$\"], \n",
    "              labelcolor='linecolor', loc='upper center', fontsize=12)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa3a233a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.214405470569241"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some ideas\n",
    "# Better knee detection algorithm\n",
    "\n",
    "import kneeliverse.kneedle as kneedle\n",
    "import kneeliverse.lmethod as lmethod\n",
    "import kneeliverse.menger as menger\n",
    "import kneeliverse.zmethod as zmethod\n",
    "\n",
    "print(kneedle.knee(np.vstack([range(0, len(last_ubic)), \n",
    "                              last_ubic]).T, t=0.1))\n",
    "\n",
    "print(lmethod.knee(np.vstack([range(0, len(last_ubic)), \n",
    "                              last_ubic]).T))\n",
    "\n",
    "print(menger.knee(np.vstack([range(0, len(last_ubic)), \n",
    "                             last_ubic]).T))\n",
    "\n",
    "print(knee_finder(last_ubic))\n",
    "\n",
    "abs((b_bics[2]-b_bics[1])/(b_bics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4abd5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e1ff74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sindy]",
   "language": "python",
   "name": "conda-env-sindy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
