{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db079a60-aab5-486f-95ae-8c1ed6d4efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from functools import partial\n",
    "from decimal import Decimal\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import pysindy as ps\n",
    "from tqdm import trange\n",
    "\n",
    "from utils import *\n",
    "from skimage.restoration import estimate_sigma\n",
    "import bm3d\n",
    "from solvel0 import solvel0\n",
    "from best_subset import backward_refinement, brute_force_all_subsets\n",
    "from UBIC import *\n",
    "from kneed import KneeLocator\n",
    "from bayesian_model_evidence import log_evidence\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "749a111d-2c70-47b7-9574-b84e15fbc756",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pre = np.load(\"./Cache/X_weak_RD_2025.npy\").astype(np.float32)\n",
    "y_pre = np.load(\"./Cache/y_weak_RD_2025.npy\").astype(np.float32)\n",
    "# Ground truth\n",
    "ground_indices_u = np.array((0, 5, 6, 7, 8, 11, 17))\n",
    "ground_coeff_u = np.array([1.000,-1.000,1.000,-1.000,1.000,0.100,0.100])\n",
    "ground_indices_v = np.array((1, 5, 6, 7, 8, 12, 18))\n",
    "ground_coeff_v = np.array([1.000,-1.000,-1.000,-1.000,-1.000,0.100,0.100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f17dedee-25ac-4262-8353-bced04177348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alibi is not installed in the environment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:57<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import covariance\n",
    "from abess import LinearRegression as AbessLinearRegression\n",
    "from knockpy import KnockoffFilter, knockoff_stats, knockoffs\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "### extra ###\n",
    "from c2st.check import c2st # https://github.com/psteinb/c2st\n",
    "\n",
    "X_scale = StandardScaler().fit_transform(X_pre)\n",
    "X_pre_top = X_scale.copy()\n",
    "y_pre = (y_pre-y_pre.mean())/y_pre.std()\n",
    "y_pre = y_pre[:, 0:1]\n",
    "\n",
    "# lr = SCO(path_type='gs', sparsity=10, ic_method='LinearSIC')\n",
    "lr = AbessLinearRegression(path_type='gs', s_max=12, fit_intercept=False, cv=5, screening_size=0)\n",
    "fstat = knockoff_stats.Eli5PIStatistic(model=lr, n_iter=10)\n",
    "# fstat = knockoff_stats.ShapStatistic(model=lr)\n",
    "kfilter = KnockoffFilter(ksampler='gaussian', fstat=fstat, knockoff_kwargs={'method':'ci'})\n",
    "# kfilter = KnockoffFilter(ksampler='gaussian', fstat='lasso', knockoff_kwargs={'method':'ci'})\n",
    "\n",
    "fdr = 0.2\n",
    "rejections = []\n",
    "np.random.seed(1234)\n",
    "for _ in trange(50):\n",
    "    rejection = kfilter.forward(X=X_pre_top, y=y_pre.flatten(), fdr=fdr, shrinkage=\"ledoitwolf\", recycle_up_to=0.5)\n",
    "    rejection = set(np.where(rejection == 1)[0])\n",
    "    if len(rejection) > 0:\n",
    "        rejections.append(rejection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a271851-4d9a-44f4-913b-dc4b5e3b474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(ground_indices_u).issubset(biggest_superset(rejections))\n",
    "rejections = np.array(sorted(biggest_superset(rejections)))\n",
    "X_pre_top = X_pre_top[:, rejections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86fa3d95-bd70-4cd8-b4c4-cd325730cdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9723034  0.6119583  0.5902573  0.26487362 0.25998566 0.05612521\n",
      " 0.05611704 0.03836295]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:17<00:00,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary classifier's acc: 0.539767671364943\n",
      "P-value: 8.881784197001252e-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "while True:\n",
    "    non_null_indices, shap_values = shap_model_selection(X_pre_top, y_pre)\n",
    "    rejections = rejections[non_null_indices]\n",
    "    X_pre_top = X_pre_top[:, non_null_indices]\n",
    "    print(abs(shap_values).mean(axis=0))\n",
    "    \n",
    "    j = len(rejections)-1\n",
    "    classifier_confidences = []\n",
    "    for _ in trange(50):\n",
    "        Xk = knockoffs.GaussianSampler(X_pre_top, Sigma=covariance.LedoitWolf().fit(X_pre_top).covariance_, \n",
    "                                       method='ci').sample_knockoffs()\n",
    "        Xn = X_pre_top.copy()\n",
    "        Xn[:, j] = Xk[:, j]\n",
    "        \n",
    "        swap_explainer = shap.explainers.Linear(linear_model.LinearRegression(fit_intercept=False).fit(Xn, y_pre),\n",
    "                                                Xn)\n",
    "        swap_shap_values = swap_explainer(Xn).values\n",
    "        \n",
    "        classifier_confidences.append(c2st(shap_values[:, j:j+1], swap_shap_values[:, j:j+1], clf=linear_model.LogisticRegression()))\n",
    "\n",
    "    classifier_confidences = np.array(classifier_confidences)\n",
    "    pv = stats.wilcoxon(classifier_confidences-0.51, alternative='greater').pvalue\n",
    "    \n",
    "    decision = classifier_confidences.mean() >= 0.51\n",
    "    decision = pv < alpha\n",
    "    print(\"binary classifier's acc:\", classifier_confidences.mean())\n",
    "    print(\"P-value:\", pv)\n",
    "\n",
    "    if decision:\n",
    "        break\n",
    "    else:\n",
    "        rejections = rejections[:j]\n",
    "        X_pre_top = X_pre_top[:,:j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6eb22d65-0da8-43f5-a006-1463808e52a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2026-04-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 64.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 24.94it/s]\n"
     ]
    }
   ],
   "source": [
    "from mbic import mbic, mbic2, ebic\n",
    "best_subsets = solvel0(X_pre_top, y_pre, miosr=True, refine=True)\n",
    "best_subsets = [tuple(best_subsets[-1][_] for _ in bs) \n",
    "                for bs in brute_force_all_subsets(X_pre_top[:, best_subsets[-1]], y_pre)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12c74d05-ad3c-433c-8720-b847259d9a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2, 3, 4, 5, 6, 7, 8, "
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.       ,  1.9191405,  3.6291192,  4.768603 , 10.173801 ,\n",
       "       26.454456 ,  6.2694693, 16.009884 ], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Calculate post_means for ARDRegression as well (Implement the ard_uncertainties function)\n",
    "ard_uns = []\n",
    "threshold_lambda = 5e5 # must pass assert \n",
    "for bs in best_subsets:\n",
    "    ard = linear_model.ARDRegression(fit_intercept=False, \n",
    "                                     compute_score=True,\n",
    "                                     threshold_lambda=threshold_lambda)\n",
    "    ard.fit(X_pre_top[:, bs], y_pre.ravel())\n",
    "    print(len(bs), end=', ')\n",
    "    assert len(bs) == len(np.nonzero(ard.coef_)[0])\n",
    "    pde_uncert = np.sqrt(np.diag(ard.sigma_)).sum()/abs(ard.coef_).sum()\n",
    "    ard_uns.append(pde_uncert)\n",
    "ard_uns = np.array(ard_uns)\n",
    "ard_uns = ard_uns/min(ard_uns)\n",
    "ard_uns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4ae70ce-a5c1-48e8-8d07-5e265bdf19af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-42862.96107663496, -43563.69859410328, -44094.79681855538, -47271.912678188506, -47304.30902705898, -51075.080848937054, -71125.40145125426, -71195.58896801552]\n",
      "[ 1.          1.91965858  3.63122435  4.76864352 10.24666284 26.44636571\n",
      "  6.26685123 15.99791453]\n",
      "threshold: 0.08\n",
      "max_lam: 3.667806489824039\n",
      "0 <---> 6 0.10989457122855913\n",
      "6 <---> 6 inf\n",
      "6 <---> 6 inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.0,\n",
       " array([-42853.75073626, -43546.01788516, -44061.35200637, -47227.99184825,\n",
       "        -47209.93377465, -50831.50081914, -71067.68161837, -71048.24272998]),\n",
       " 6,\n",
       " 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau = 3\n",
    "verbose = True\n",
    "# scale = 1 <- generalized UBIC\n",
    "scale = np.log(len(y_pre))\n",
    "per = 75 # 80\n",
    "\n",
    "post_means, b_bics, b_uns = baye_uncertainties(best_subsets, (X_pre_top, y_pre), \n",
    "                                               u_type='cv1', take_sqrt=True, \n",
    "                                               ridge_lambda=0, \n",
    "                                               threshold=0)\n",
    "# b_uns = ard_uns # USE ard_uns INSTEAD\n",
    "predictions = X_pre_top@post_means\n",
    "print(b_bics)\n",
    "print(b_uns)\n",
    "b_bics = np.array(b_bics)\n",
    "max_complexity = len(b_bics)\n",
    "complexities = np.arange(max_complexity)+1\n",
    "d_complexities = complexities[decreasing_values_indices(b_bics)]\n",
    "d_bics = b_bics[decreasing_values_indices(b_bics)]\n",
    "slopes = np.diff(d_bics)/(np.diff(d_complexities)*d_bics[:-1])\n",
    "try:\n",
    "    thres = np.percentile(np.abs(slopes), per)\n",
    "    thres = math.ceil(sci_format(thres)[0])*10**sci_format(thres)[1]\n",
    "except IndexError:\n",
    "    thres = 1/40\n",
    "min_thres = 1/40\n",
    "thres = max(thres, min_thres)\n",
    "print(\"threshold:\", thres)\n",
    "\n",
    "lower_bounds = []\n",
    "for k, efi in enumerate(best_subsets):\n",
    "    # assert len(efi) == np.count_nonzero(post_means[:, k:k+1])\n",
    "    com = len(efi)\n",
    "    lower_bound = 2*np.abs(log_like_value(predictions[:, k:k+1], y_pre))-np.log(len(y_pre))*com\n",
    "    lower_bounds.append(lower_bound)\n",
    "\n",
    "last_lam = np.log10(max(lower_bounds/(b_uns*scale)))\n",
    "print(\"max_lam:\", last_lam)\n",
    "delta = last_lam/tau\n",
    "now_lam = last_lam-delta\n",
    "last_ubic = UBIC(b_bics, b_uns, len(y_pre), hyp=10**last_lam, scale=scale)\n",
    "last_bc = np.argmin(last_ubic)\n",
    "bc_seq = [last_bc]\n",
    "while now_lam >= 0:\n",
    "    now_ubic = UBIC(b_bics, b_uns, len(y_pre), hyp=10**now_lam, scale=scale)\n",
    "    now_bc = np.argmin(now_ubic)\n",
    "    \n",
    "    diff_com = now_bc-last_bc\n",
    "    diff_bic = b_bics[now_bc]-b_bics[last_bc]\n",
    "    imp = np.nan\n",
    "    if diff_com != 0:\n",
    "        imp = abs(diff_bic/(b_bics[last_bc]*diff_com))\n",
    "    \n",
    "    if verbose:\n",
    "        print(min(last_bc, now_bc), '<--->', max(last_bc, now_bc), \n",
    "              np.nan_to_num(imp, nan=np.inf))\n",
    "    \n",
    "    if (diff_com > 0 and (diff_bic > 0 or imp < thres)) or \\\n",
    "        (diff_com < 0 and diff_bic > 0 and imp > thres):\n",
    "        break\n",
    "    \n",
    "    last_lam = now_lam\n",
    "    now_lam = round(last_lam-delta, 8)\n",
    "    last_ubic = now_ubic\n",
    "    last_bc = now_bc\n",
    "    if last_bc not in bc_seq:\n",
    "        bc_seq.append(last_bc)\n",
    "\n",
    "# best_bc = knee(range(len(last_ubic)), last_ubic, 0.95, 'linear', direction='decreasing')\n",
    "best_bc = knee_finder(last_ubic)\n",
    "if best_bc == 0 and last_bc != 0 and b_bics[last_bc] < b_bics[0] and \\\n",
    "                                    abs((b_bics[last_bc]-b_bics[0])/(b_bics[0]*last_bc)) > thres:\n",
    "    best_bc = knee(range(1, len(last_ubic)), last_ubic[1:], 0.95, 'linear')\n",
    "if best_bc < last_bc and abs((b_bics[last_bc]-b_bics[best_bc])/(b_bics[best_bc]*(last_bc-best_bc))) > thres:\n",
    "    best_bc = last_bc\n",
    "    \n",
    "last_lam = round(last_lam, 8)\n",
    "last_lam, last_ubic, last_bc, best_bc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a2fd23-b369-4326-bd20-d1ed41ada01e",
   "metadata": {},
   "source": [
    "### Selective inference ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c31b353a-59d5-402c-a564-cf6fb3a46b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selective_inference import sfs_si, stepwise_selective_inference, subset_fdr\n",
    "import fpsample\n",
    "from dppy.finite_dpps import FiniteDPP\n",
    "\n",
    "from si4pipeline import ( \n",
    "                        construct_pipelines, \n",
    "                        extract_features, \n",
    "                        initialize_dataset, \n",
    "                        intersection, \n",
    "                        lasso, \n",
    "                        marginal_screening, \n",
    "                        stepwise_feature_selection, \n",
    "                        union, \n",
    "                        PipelineManager\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "434b895b-513a-436c-a747-2a0f0fd3b5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({True: 14}) 0.0\n",
      "Counter({False: 14}) 0.421671494422755\n",
      "Counter({False: 14}) 0.61420880445064\n",
      "Counter({False: 14}) 0.7433967279135411\n",
      "Counter({False: 14}) 1.122993187359406\n",
      "Counter({False: 14}) 0.6373181691376487\n",
      "Counter({True: 14}) 0.03973898690764753\n",
      "Counter({False: 14}) 0.8285702386905577\n"
     ]
    }
   ],
   "source": [
    "n_samples = 100*(best_bc+1)\n",
    "max_fdr = 0.05\n",
    "for bs in best_subsets:\n",
    "    fdrs = []\n",
    "    for _ in range(len(y_pre)//n_samples):\n",
    "        X_test = X_pre_top[:, bs]\n",
    "        y_test = y_pre.ravel()\n",
    "        \n",
    "        np.random.seed(random.randint(0, 100))\n",
    "        # sample_indices = sorted(set([np.random.randint(len(y_pre)) for _ in range(n_samples)]))\n",
    "        sample_indices = fpsample.bucket_fps_kdline_sampling(X_test, n_samples=n_samples, h=5) # Farthest Point Sampling (FPS) is better!!!\n",
    "        X_test = X_test[sample_indices]; y_test = y_test[sample_indices]\n",
    "        # FPS + k-DPP\n",
    "        # DPP = FiniteDPP('likelihood', **{'L': X_test.dot(X_test.T)})\n",
    "        # DPP.flush_samples()\n",
    "        # for _ in range(n_samples//(len(bs))):\n",
    "        #     DPP.sample_exact_k_dpp(size=len(bs))\n",
    "        # sample_indices = np.unique(np.ravel(DPP.list_of_samples))\n",
    "        # X_test = X_test[sample_indices]; y_test = y_test[sample_indices]\n",
    "        \n",
    "        manager = stepwise_selective_inference(support_size=X_test.shape[1])\n",
    "        M, p_list = manager.inference(X_test, y_test, np.std(y_test))\n",
    "        # print(M, p_list, subset_fdr(p_list) < 0.01, np.array(p_list) < 0.05)\n",
    "        fdrs.append(subset_fdr(p_list))\n",
    "        \n",
    "    fdrs = np.array(fdrs)\n",
    "    print(Counter(fdrs < max_fdr), fdrs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54159af8-6174-4086-84b6-b5fd21cfbbc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e33164d-1e60-482e-be8d-ae24132937af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sindy]",
   "language": "python",
   "name": "conda-env-sindy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
