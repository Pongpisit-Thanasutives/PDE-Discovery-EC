{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db079a60-aab5-486f-95ae-8c1ed6d4efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from functools import partial\n",
    "from decimal import Decimal\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import pysindy as ps\n",
    "from tqdm import trange\n",
    "\n",
    "from utils import *\n",
    "from skimage.restoration import estimate_sigma\n",
    "import bm3d\n",
    "from solvel0 import solvel0\n",
    "from best_subset import backward_refinement, brute_force_all_subsets\n",
    "from UBIC import *\n",
    "from kneed import KneeLocator\n",
    "from bayesian_model_evidence import log_evidence\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "749a111d-2c70-47b7-9574-b84e15fbc756",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pre = np.load(\"./Cache/X_pre_RD_2025.npy\")\n",
    "uv_pre = np.load(\"./Cache/y_pre_RD_2025.npy\")\n",
    "feature_names = np.load(\"./Cache/feature_names_RD_2025.npy\")\n",
    "target_name = 'u'\n",
    "\n",
    "# Ground truth\n",
    "ground_indices_u = np.array((0, 5, 6, 7, 8, 11, 17))\n",
    "ground_coeff_u = np.array([1.000,-1.000,1.000,-1.000,1.000,0.100,0.100])\n",
    "ground_indices_v = np.array((1, 5, 6, 7, 8, 12, 18))\n",
    "ground_coeff_v = np.array([1.000,-1.000,-1.000,-1.000,-1.000,0.100,0.100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f17dedee-25ac-4262-8353-bced04177348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alibi is not installed in the environment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:22<00:00,  2.20it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import covariance\n",
    "from abess import LinearRegression as AbessLinearRegression\n",
    "from knockpy import KnockoffFilter, knockoff_stats, knockoffs\n",
    "from knockpy.utilities import estimate_covariance\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "### extra ###\n",
    "from c2st.check import c2st # https://github.com/psteinb/c2st\n",
    "\n",
    "X_scale = StandardScaler().fit_transform(X_pre)\n",
    "X_pre_top = X_scale.copy()\n",
    "y_pre = StandardScaler().fit_transform(uv_pre)\n",
    "if target_name == 'u':\n",
    "    y_pre = y_pre[:, 0:1]\n",
    "elif target_name == 'v':\n",
    "    y_pre = y_pre[:, 1:2]\n",
    "    \n",
    "# lr = SCO(path_type='gs', sparsity=10, ic_method='LinearSIC')\n",
    "lr = AbessLinearRegression(path_type='gs', s_max=12, fit_intercept=False, cv=5, screening_size=0)\n",
    "# fstat = knockoff_stats.Eli5PIStatistic(model=lr, n_iter=10)\n",
    "fstat = knockoff_stats.ShapStatistic(model=lr)\n",
    "kfilter = KnockoffFilter(ksampler='gaussian', fstat=fstat, knockoff_kwargs={'method':'ci'}) # sdp, ci\n",
    "# kfilter = KnockoffFilter(ksampler='gaussian', fstat='lasso', knockoff_kwargs={'method':'ci'})\n",
    "\n",
    "fdr = 0.2\n",
    "rejections = []\n",
    "np.random.seed(1234)\n",
    "for _ in trange(50):\n",
    "    rejection = kfilter.forward(X=X_pre_top, y=y_pre.flatten(), fdr=fdr, shrinkage=\"ledoitwolf\", recycle_up_to=0.5, tol=1e-2)\n",
    "    rejection = set(np.where(rejection == 1)[0])\n",
    "    if len(rejection) > 0:\n",
    "        rejections.append(rejection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a271851-4d9a-44f4-913b-dc4b5e3b474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_name == 'u':\n",
    "    assert set(ground_indices_u).issubset(biggest_superset(rejections))\n",
    "elif target_name == 'v':\n",
    "    assert set(ground_indices_v).issubset(biggest_superset(rejections))\n",
    "rejections = np.array(sorted(biggest_superset(rejections)))\n",
    "X_pre_top = X_pre_top[:, rejections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86fa3d95-bd70-4cd8-b4c4-cd325730cdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97597401 0.61426815 0.59248468 0.26587347 0.26096671 0.05633711\n",
      " 0.05632892 0.03851168]\n",
      "[ 0  5  8  7  6 17 11  1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:20<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary classifier's acc: 0.5805883213739055\n",
      "P-value: 3.652242990355243e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:17<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary classifier's acc: 0.6587739076032716\n",
      "P-value: 1.8956154935896829e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:18<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary classifier's acc: 0.5564545198613733\n",
      "P-value: 3.747819373466181e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:17<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary classifier's acc: 0.5529422437239774\n",
      "P-value: 3.625511732833164e-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 50/50 [00:17<00:00,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary classifier's acc: 0.5512225982431274\n",
      "P-value: 1.4599508461573694e-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "classifier_threshold = 0.5\n",
    "while True:\n",
    "    non_null_indices, shap_values = shap_model_selection(X_pre_top, y_pre)\n",
    "    scale_shap_values = abs(shap_values).mean(axis=0)\n",
    "    rejections = rejections[non_null_indices]\n",
    "    X_pre_top = X_pre_top[:, non_null_indices]\n",
    "    # stop = -1\n",
    "    stop = knee_finder(-np.cumsum(scale_shap_values))\n",
    "    print(scale_shap_values)\n",
    "    print(rejections)\n",
    "\n",
    "    decision = True\n",
    "    Sigma, invSigma = estimate_covariance(X_pre_top, 1e-3, \"graphicallasso\")\n",
    "    for j in range(len(rejections)-1, stop, -1):\n",
    "        classifier_confidences = []\n",
    "        for _ in trange(50):\n",
    "            Xk = knockoffs.GaussianSampler(X_pre_top, Sigma=Sigma, invSigma=invSigma, \n",
    "                                           method='ci').sample_knockoffs()\n",
    "            Xn = X_pre_top.copy()\n",
    "            Xn[:, j] = Xk[:, j]\n",
    "            \n",
    "            swap_explainer = shap.explainers.Linear(linear_model.LinearRegression(fit_intercept=False).fit(Xn, y_pre),\n",
    "                                                    Xn)\n",
    "            swap_shap_values = swap_explainer(Xn).values\n",
    "            \n",
    "            classifier_confidences.append(c2st(shap_values[:, j:j+1], swap_shap_values[:, j:j+1], clf=linear_model.LogisticRegression()))\n",
    "    \n",
    "        classifier_confidences = np.array(classifier_confidences)\n",
    "        pv = stats.wilcoxon(classifier_confidences-classifier_threshold, alternative='greater').pvalue\n",
    "        \n",
    "        print(\"binary classifier's acc:\", classifier_confidences.mean())\n",
    "        print(\"P-value:\", pv)\n",
    "    \n",
    "        if not pv < alpha:\n",
    "            decision = False\n",
    "            break\n",
    "\n",
    "    if not decision:\n",
    "        non_null_indices = list(solvel0(X_pre_top, y_pre, max_complexity=len(rejections)-1, miosr=True, refine=True)[-1])\n",
    "        rejections = rejections[non_null_indices]\n",
    "        X_pre_top = X_pre_top[:, non_null_indices]\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d710454f-ae7c-4d5a-9d40-ba084d2d657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pre_top = X_pre[:, rejections]\n",
    "X_pre_top = X_pre_top/np.linalg.norm(X_pre_top, 2, axis=0)\n",
    "if target_name == 'u':\n",
    "    y_pre = uv_pre[:, 0:1]\n",
    "elif target_name == 'v':\n",
    "    y_pre = uv_pre[:, 1:2]\n",
    "# y_pre = y_pre/np.linalg.norm(y_pre, 2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eb22d65-0da8-43f5-a006-1463808e52a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                    | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2026-04-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 67.30it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 26.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(7,),\n",
       " (6, 7),\n",
       " (0, 6, 7),\n",
       " (0, 5, 6, 7),\n",
       " (0, 1, 5, 6, 7),\n",
       " (0, 1, 3, 5, 6, 7),\n",
       " (0, 1, 2, 3, 4, 5, 6),\n",
       " (0, 1, 2, 3, 4, 5, 6, 7)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mbic import mbic, mbic2, ebic\n",
    "best_subsets = solvel0(X_pre_top, y_pre, miosr=True, refine=True)\n",
    "best_subsets = [tuple(best_subsets[-1][_] for _ in bs) \n",
    "                for bs in brute_force_all_subsets(X_pre_top[:, best_subsets[-1]], y_pre)[1]]\n",
    "best_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12c74d05-ad3c-433c-8720-b847259d9a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2, 3, 4, 5, 6, 7, 8, "
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  1.91911869,  3.62915079,  4.7681372 , 10.16958225,\n",
       "       26.45335367,  6.26882816, 15.92240492])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Calculate post_means for ARDRegression as well (Implement the ard_uncertainties function)\n",
    "ard_uns = []\n",
    "threshold_lambda = 5e5 # must pass assert \n",
    "for bs in best_subsets:\n",
    "    ard = linear_model.ARDRegression(fit_intercept=False, \n",
    "                                     compute_score=True,\n",
    "                                     threshold_lambda=threshold_lambda)\n",
    "    ard.fit(X_pre_top[:, bs], y_pre.ravel())\n",
    "    print(len(bs), end=', ')\n",
    "    assert len(bs) == len(np.nonzero(ard.coef_)[0])\n",
    "    pde_uncert = np.sqrt(np.diag(ard.sigma_)).sum()/abs(ard.coef_).sum()\n",
    "    ard_uns.append(pde_uncert)\n",
    "ard_uns = np.array(ard_uns)\n",
    "ard_uns = ard_uns/min(ard_uns)\n",
    "ard_uns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4ae70ce-a5c1-48e8-8d07-5e265bdf19af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-82004.02832730942, -82704.7724308089, -83235.48572408342, -86414.31597398147, -86446.65289622564, -90217.85407296669, -110268.06514588586, -110338.5035045842]\n",
      "[ 1.          1.91965902  3.63126215  4.76806691 10.244316   26.22119289\n",
      "  6.25926936 15.94113009]\n",
      "threshold: 0.05\n",
      "max_lam: 3.9495595069581295\n",
      "0 <---> 6 0.05744440729538282\n",
      "6 <---> 6 inf\n",
      "6 <---> 6 inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " array([ -81994.81798694,  -82687.09171784,  -83202.04056373,\n",
       "         -86370.40045486,  -86352.29925895,  -89976.34796148,\n",
       "        -110210.41514458, -110191.68027053]),\n",
       " 6,\n",
       " 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau = 3\n",
    "verbose = True\n",
    "# scale = 1 <- generalized UBIC\n",
    "scale = np.log(len(y_pre))\n",
    "per = 75 # 80\n",
    "\n",
    "post_means, b_bics, b_uns = baye_uncertainties(best_subsets, (X_pre_top, y_pre), \n",
    "                                               u_type='cv1', take_sqrt=True, \n",
    "                                               ridge_lambda=0, \n",
    "                                               threshold=0)\n",
    "# b_uns = ard_uns # USE ard_uns INSTEAD\n",
    "predictions = X_pre_top@post_means\n",
    "print(b_bics)\n",
    "print(b_uns)\n",
    "b_bics = np.array(b_bics)\n",
    "max_complexity = len(b_bics)\n",
    "complexities = np.arange(max_complexity)+1\n",
    "d_complexities = complexities[decreasing_values_indices(b_bics)]\n",
    "d_bics = b_bics[decreasing_values_indices(b_bics)]\n",
    "slopes = np.diff(d_bics)/(np.diff(d_complexities)*d_bics[:-1])\n",
    "try:\n",
    "    thres = np.percentile(np.abs(slopes), per)\n",
    "    thres = math.ceil(sci_format(thres)[0])*10**sci_format(thres)[1]\n",
    "except IndexError:\n",
    "    thres = 1/40\n",
    "min_thres = 1/40\n",
    "max_thres = 1/10\n",
    "thres = min(max(thres, min_thres), max_thres)\n",
    "print(\"threshold:\", thres)\n",
    "\n",
    "lower_bounds = []\n",
    "for k, efi in enumerate(best_subsets):\n",
    "    # assert len(efi) == np.count_nonzero(post_means[:, k:k+1])\n",
    "    com = len(efi)\n",
    "    lower_bound = 2*np.abs(log_like_value(predictions[:, k:k+1], y_pre))-np.log(len(y_pre))*com\n",
    "    lower_bounds.append(lower_bound)\n",
    "\n",
    "last_lam = np.log10(max(lower_bounds/(b_uns*scale)))\n",
    "print(\"max_lam:\", last_lam)\n",
    "delta = last_lam/tau\n",
    "now_lam = last_lam-delta\n",
    "last_ubic = UBIC(b_bics, b_uns, len(y_pre), hyp=10**last_lam, scale=scale)\n",
    "last_bc = np.argmin(last_ubic)\n",
    "bc_seq = [last_bc]\n",
    "while now_lam >= 0:\n",
    "    now_ubic = UBIC(b_bics, b_uns, len(y_pre), hyp=10**now_lam, scale=scale)\n",
    "    now_bc = np.argmin(now_ubic)\n",
    "    \n",
    "    diff_com = now_bc-last_bc\n",
    "    diff_bic = b_bics[now_bc]-b_bics[last_bc]\n",
    "    imp = np.nan\n",
    "    if diff_com != 0:\n",
    "        imp = abs(diff_bic/(b_bics[last_bc]*diff_com))\n",
    "    \n",
    "    if verbose:\n",
    "        print(min(last_bc, now_bc), '<--->', max(last_bc, now_bc), \n",
    "              np.nan_to_num(imp, nan=np.inf))\n",
    "    \n",
    "    if (diff_com > 0 and (diff_bic > 0 or imp < thres)) or \\\n",
    "        (diff_com < 0 and diff_bic > 0 and imp > thres):\n",
    "        break\n",
    "    \n",
    "    last_lam = now_lam\n",
    "    now_lam = round(last_lam-delta, 8)\n",
    "    last_ubic = now_ubic\n",
    "    last_bc = now_bc\n",
    "    if last_bc not in bc_seq:\n",
    "        bc_seq.append(last_bc)\n",
    "\n",
    "# best_bc = knee(range(len(last_ubic)), last_ubic, 0.95, 'linear', direction='decreasing')\n",
    "best_bc = knee_finder(last_ubic)\n",
    "if best_bc == 0 and last_bc != 0 and b_bics[last_bc] < b_bics[0] and \\\n",
    "                                    abs((b_bics[last_bc]-b_bics[0])/(b_bics[0]*last_bc)) > thres:\n",
    "    best_bc = knee(range(1, len(last_ubic)), last_ubic[1:], 0.95, 'linear')\n",
    "if best_bc < last_bc and abs((b_bics[last_bc]-b_bics[best_bc])/(b_bics[best_bc]*(last_bc-best_bc))) > thres:\n",
    "    best_bc = last_bc\n",
    "    \n",
    "last_lam = round(last_lam, 8)\n",
    "last_lam, last_ubic, last_bc, best_bc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a2fd23-b369-4326-bd20-d1ed41ada01e",
   "metadata": {},
   "source": [
    "### Selective inference ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c31b353a-59d5-402c-a564-cf6fb3a46b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selective_inference import sfs_si, stepwise_selective_inference, subset_fdr\n",
    "import fpsample\n",
    "from dppy.finite_dpps import FiniteDPP\n",
    "\n",
    "from si4pipeline import ( \n",
    "                        construct_pipelines, \n",
    "                        extract_features, \n",
    "                        initialize_dataset, \n",
    "                        intersection, \n",
    "                        lasso, \n",
    "                        marginal_screening, \n",
    "                        stepwise_feature_selection, \n",
    "                        union, \n",
    "                        PipelineManager\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "434b895b-513a-436c-a747-2a0f0fd3b5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.03125\n",
      "0.33402896958864114 1.0\n",
      "0.5798957361654506 1.0\n",
      "0.44629171253902966 1.0\n",
      "1.3376399771711998 1.0\n",
      "0.4703252104860508 1.0\n",
      "0.013462920511081986 0.03125\n",
      "0.7060907777482935 1.0\n"
     ]
    }
   ],
   "source": [
    "n_samples = 250*(last_bc+1)\n",
    "# max_fdr = 0.2; false_discovery_control_method = 'by'\n",
    "max_fdr = 0.2; false_discovery_control_method = 'bh'\n",
    "# max_fdr = 0.2; false_discovery_control_method =  None\n",
    "for bs in best_subsets:\n",
    "    fdrs = []\n",
    "    for _ in range(len(y_pre)//n_samples):\n",
    "        X_test = X_pre_top[:, bs]\n",
    "        y_test = y_pre.ravel()\n",
    "        \n",
    "        np.random.seed(random.randint(0, 100))\n",
    "        # sample_indices = sorted(set([np.random.randint(len(y_pre)) for _ in range(n_samples)]))\n",
    "        sample_indices = fpsample.bucket_fps_kdline_sampling(X_test, n_samples=n_samples, h=5) # Farthest Point Sampling (FPS) is better!!!\n",
    "        X_test = X_test[sample_indices]; y_test = y_test[sample_indices]\n",
    "        # FPS + k-DPP\n",
    "        # DPP = FiniteDPP('likelihood', **{'L': X_test.dot(X_test.T)})\n",
    "        # DPP.flush_samples()\n",
    "        # for _ in range(n_samples//(len(bs))):\n",
    "        #     DPP.sample_exact_k_dpp(size=len(bs))\n",
    "        # sample_indices = np.unique(np.ravel(DPP.list_of_samples))\n",
    "        # X_test = X_test[sample_indices]; y_test = y_test[sample_indices]\n",
    "        \n",
    "        manager = stepwise_selective_inference(support_size=X_test.shape[1])\n",
    "        M, p_list = manager.inference(X_test, y_test, np.std(y_test))\n",
    "        if false_discovery_control_method is not None:\n",
    "            p_list = stats.false_discovery_control(p_list, method=false_discovery_control_method)\n",
    "        # print(M, p_list, np.array(p_list) < 0.05)\n",
    "        fdrs.append(subset_fdr(p_list))\n",
    "        \n",
    "    fdrs = np.array(fdrs)\n",
    "    print(fdrs.mean(), stats.wilcoxon(fdrs-max_fdr, alternative='less').pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31ac76c-220d-481d-bf86-b57143c8ae63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9011f6-a6ce-4062-b55c-3b354dd834dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sindy]",
   "language": "python",
   "name": "conda-env-sindy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
