{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f17f8bc-3661-444d-b9ed-9368b86cc29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from functools import partial\n",
    "from decimal import Decimal\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import pysindy as ps\n",
    "from tqdm import trange\n",
    "\n",
    "from utils import *\n",
    "from skimage.restoration import estimate_sigma\n",
    "import bm3d\n",
    "from solvel0 import solvel0\n",
    "from best_subset import backward_refinement, brute_force_all_subsets\n",
    "from UBIC import *\n",
    "from kneed import KneeLocator\n",
    "from bayesian_model_evidence import log_evidence\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29569d0f-2009-4a02-9262-4d939e6f6edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pre = np.load(\"./Cache/X_pre_GS_2025.npy\")\n",
    "uv_pre = np.load(\"./Cache/y_pre_GS_2025.npy\")\n",
    "feature_names = np.load(\"./Cache/feature_names_GS_2025.npy\")\n",
    "target_name = 'v'\n",
    "\n",
    "# Ground truth\n",
    "ground_indices_u = (0, 1, 8, 12, 18, 26)\n",
    "ground_coeff_u = np.array([0.014, -0.014, -1.000, 0.020, 0.020, 0.020])\n",
    "ground_indices_v = (2, 8, 13, 19, 27)\n",
    "ground_coeff_v = np.array([-0.067, 1.0, 0.01, 0.01, 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "343e8377-dcc7-44a7-83bd-b903bc1746e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alibi is not installed in the environment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:53<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import covariance\n",
    "from abess import LinearRegression as AbessLinearRegression\n",
    "from knockpy import KnockoffFilter, knockoff_stats, knockoffs\n",
    "from knockpy.utilities import estimate_covariance\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "### extra ###\n",
    "from c2st.check import c2st # https://github.com/psteinb/c2st\n",
    "\n",
    "X_scale = StandardScaler().fit_transform(X_pre)\n",
    "X_pre_top = X_scale.copy()\n",
    "y_pre = StandardScaler().fit_transform(uv_pre)\n",
    "if target_name == 'u':\n",
    "    y_pre = y_pre[:, 0:1]\n",
    "elif target_name == 'v':\n",
    "    y_pre = y_pre[:, 1:2]\n",
    "    \n",
    "# lr = SCO(path_type='gs', sparsity=10, ic_method='LinearSIC')\n",
    "lr = AbessLinearRegression(path_type='gs', s_max=12, fit_intercept=False, cv=5, screening_size=0)\n",
    "fstat = knockoff_stats.Eli5PIStatistic(model=lr, n_iter=10)\n",
    "# fstat = knockoff_stats.ShapStatistic(model=lr)\n",
    "kfilter = KnockoffFilter(ksampler='gaussian', fstat=fstat, knockoff_kwargs={'method':'ci'})\n",
    "# kfilter = KnockoffFilter(ksampler='gaussian', fstat='lasso', knockoff_kwargs={'method':'ci'})\n",
    "\n",
    "fdr = 0.2\n",
    "rejections = []\n",
    "for _ in trange(50):\n",
    "    rejection = kfilter.forward(X=X_pre_top, y=y_pre.flatten(), fdr=fdr, shrinkage=\"ledoitwolf\", recycle_up_to=0.5, tol=1e-3)\n",
    "    rejection = set(np.where(rejection == 1)[0])\n",
    "    if len(rejection) > 0:\n",
    "        rejections.append(rejection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "121a5119-323e-47ae-ac8e-0cba2c2152f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_name == 'u':\n",
    "    assert set(ground_indices_u).issubset(biggest_superset(rejections))\n",
    "elif target_name == 'v':\n",
    "    assert set(ground_indices_v).issubset(biggest_superset(rejections))\n",
    "rejections = np.array(sorted(biggest_superset(rejections)))\n",
    "X_pre_top = X_pre_top[:, rejections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33e1d80e-d14e-4a7b-849b-3127e21391b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34700653 0.28807088 0.24421814 0.19964928 0.03202913]\n",
      "[27 19  2  8 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:11<00:00,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary classifier's acc: 0.7651213799095947\n",
      "P-value: 3.740193003210621e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "while True:\n",
    "    non_null_indices, shap_values = shap_model_selection(StandardScaler().fit_transform(X_pre_top), \n",
    "                                                         y_pre)\n",
    "    scale_shap_values = abs(shap_values).mean(axis=0)\n",
    "    rejections = rejections[non_null_indices]\n",
    "    X_pre_top = X_pre_top[:, non_null_indices]\n",
    "    # stop = -1\n",
    "    stop = knee_finder(-np.cumsum(scale_shap_values))\n",
    "    print(scale_shap_values)\n",
    "    print(rejections)\n",
    "\n",
    "    decision = True\n",
    "    Sigma, invSigma = estimate_covariance(X_pre_top, 1e-3, \"graphicallasso\")\n",
    "    for j in range(len(rejections)-1, stop, -1):\n",
    "        classifier_confidences = []\n",
    "        for _ in trange(50):\n",
    "            Xk = knockoffs.GaussianSampler(X_pre_top, Sigma=Sigma, invSigma=invSigma, \n",
    "                                           method='ci').sample_knockoffs()\n",
    "            Xn = X_pre_top.copy()\n",
    "            Xn[:, j] = Xk[:, j]\n",
    "            \n",
    "            swap_explainer = shap.explainers.Linear(linear_model.LinearRegression(fit_intercept=False).fit(Xn, y_pre),\n",
    "                                                    Xn)\n",
    "            swap_shap_values = swap_explainer(Xn).values\n",
    "            \n",
    "            classifier_confidences.append(c2st(shap_values[:, j:j+1], swap_shap_values[:, j:j+1], clf=linear_model.LogisticRegression()))\n",
    "    \n",
    "        classifier_confidences = np.array(classifier_confidences)\n",
    "        pv = stats.wilcoxon(classifier_confidences-0.51, alternative='greater').pvalue\n",
    "        \n",
    "        print(\"binary classifier's acc:\", classifier_confidences.mean())\n",
    "        print(\"P-value:\", pv)\n",
    "    \n",
    "        if not pv < alpha:\n",
    "            decision = False\n",
    "            break\n",
    "\n",
    "    if not decision:\n",
    "        non_null_indices = list(solvel0(X_pre_top, y_pre, max_complexity=len(rejections)-1, miosr=True, refine=True)[-1])\n",
    "        rejections = rejections[non_null_indices]\n",
    "        X_pre_top = X_pre_top[:, non_null_indices]\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9409f978-92f8-4e33-8236-9412b64ffed0",
   "metadata": {},
   "source": [
    "### Best-subset selection ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba9f0eba-256b-4a69-9a4b-991e0bb57e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pre_top = X_pre[:, rejections]\n",
    "X_pre_top = X_pre_top/np.linalg.norm(X_pre_top, 2, axis=0)\n",
    "if target_name == 'u':\n",
    "    y_pre = uv_pre[:, 0:1]\n",
    "elif target_name == 'v':\n",
    "    y_pre = uv_pre[:, 1:2]\n",
    "y_pre = y_pre/np.linalg.norm(y_pre, 2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1b227c4-a9e8-480f-97d0-7aa659be0f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 65.75it/s]\n"
     ]
    }
   ],
   "source": [
    "_, best_subsets = brute_force_all_subsets(X_pre_top, y_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d8c13f-accd-4c23-b98f-247c97cc564d",
   "metadata": {},
   "source": [
    "### UBIC ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eb0bbb3-d693-40c8-8aba-3c82b3916609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-77186.17667782714, -80109.66341137749, -96918.2663018797, -126135.88646986596, -198024.0396900899]\n",
      "[125.40214763 286.92107553  81.6463625   31.70225808   1.        ]\n",
      "threshold: 0.025\n",
      "max_lam: 4.332442235845276\n",
      "4 <---> 4 inf\n",
      "4 <---> 4 inf\n",
      "4 <---> 4 inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.0,\n",
       " array([ -76031.1802148 ,  -77467.02264586,  -96166.27551316,\n",
       "        -125843.89788243, -198014.82934972]),\n",
       " 4,\n",
       " 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau = 3\n",
    "verbose = True\n",
    "# scale = 1 <- generalized UBIC\n",
    "scale = np.log(len(y_pre))\n",
    "per = 75 # 80\n",
    "\n",
    "post_means, b_bics, b_uns = baye_uncertainties(best_subsets, (X_pre_top, y_pre), \n",
    "                                               u_type='cv1', take_sqrt=True, \n",
    "                                               ridge_lambda=0, \n",
    "                                               threshold=0)\n",
    "# b_uns = ard_uns # USE ard_uns INSTEAD\n",
    "predictions = X_pre_top@post_means\n",
    "print(b_bics)\n",
    "print(b_uns)\n",
    "b_bics = np.array(b_bics)\n",
    "max_complexity = len(b_bics)\n",
    "complexities = np.arange(max_complexity)+1\n",
    "d_complexities = complexities[decreasing_values_indices(b_bics)]\n",
    "d_bics = b_bics[decreasing_values_indices(b_bics)]\n",
    "slopes = np.diff(d_bics)/(np.diff(d_complexities)*d_bics[:-1])\n",
    "try:\n",
    "    thres = np.percentile(np.abs(slopes), per)\n",
    "    thres = math.ceil(sci_format(thres)[0])*10**sci_format(thres)[1]\n",
    "except IndexError:\n",
    "    thres = 1/40\n",
    "min_thres = 1/40; max_thres = 0.5\n",
    "thres = min(max(thres, min_thres), min_thres)\n",
    "print(\"threshold:\", thres)\n",
    "\n",
    "lower_bounds = []\n",
    "for k, efi in enumerate(best_subsets):\n",
    "    # assert len(efi) == np.count_nonzero(post_means[:, k:k+1])\n",
    "    com = len(efi)\n",
    "    lower_bound = 2*np.abs(log_like_value(predictions[:, k:k+1], y_pre))-np.log(len(y_pre))*com\n",
    "    lower_bounds.append(lower_bound)\n",
    "\n",
    "last_lam = np.log10(max(lower_bounds/(b_uns*scale)))\n",
    "print(\"max_lam:\", last_lam)\n",
    "delta = last_lam/tau\n",
    "now_lam = last_lam-delta\n",
    "last_ubic = UBIC(b_bics, b_uns, len(y_pre), hyp=10**last_lam, scale=scale)\n",
    "last_bc = np.argmin(last_ubic)\n",
    "bc_seq = [last_bc]\n",
    "while now_lam >= 0:\n",
    "    now_ubic = UBIC(b_bics, b_uns, len(y_pre), hyp=10**now_lam, scale=scale)\n",
    "    now_bc = np.argmin(now_ubic)\n",
    "    \n",
    "    diff_com = now_bc-last_bc\n",
    "    diff_bic = b_bics[now_bc]-b_bics[last_bc]\n",
    "    imp = np.nan\n",
    "    if diff_com != 0:\n",
    "        imp = abs(diff_bic/(b_bics[last_bc]*diff_com))\n",
    "    \n",
    "    if verbose:\n",
    "        print(min(last_bc, now_bc), '<--->', max(last_bc, now_bc), \n",
    "              np.nan_to_num(imp, nan=np.inf))\n",
    "    \n",
    "    if (diff_com > 0 and (diff_bic > 0 or imp < thres)) or \\\n",
    "        (diff_com < 0 and diff_bic > 0 and imp > thres):\n",
    "        break\n",
    "    \n",
    "    last_lam = now_lam\n",
    "    now_lam = round(last_lam-delta, 8)\n",
    "    last_ubic = now_ubic\n",
    "    last_bc = now_bc\n",
    "    if last_bc not in bc_seq:\n",
    "        bc_seq.append(last_bc)\n",
    "\n",
    "# best_bc = knee(range(len(last_ubic)), last_ubic, 0.95, 'linear', direction='decreasing')\n",
    "best_bc = knee_finder(last_ubic)\n",
    "if best_bc == 0 and last_bc != 0 and b_bics[last_bc] < b_bics[0] and \\\n",
    "                                    abs((b_bics[last_bc]-b_bics[0])/(b_bics[0]*last_bc)) > thres:\n",
    "    best_bc = knee(range(1, len(last_ubic)), last_ubic[1:], 0.95, 'linear')\n",
    "if best_bc < last_bc and abs((b_bics[last_bc]-b_bics[best_bc])/(b_bics[best_bc]*(last_bc-best_bc))) > thres:\n",
    "    best_bc = last_bc\n",
    "    \n",
    "last_lam = round(last_lam, 8)\n",
    "last_lam, last_ubic, last_bc, best_bc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfb0a0f-1899-419e-8ae1-886fc0956725",
   "metadata": {},
   "source": [
    "### Selective inference ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78f7982f-a0cd-42ba-b046-2e871fa0491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selective_inference import sfs_si, stepwise_selective_inference, subset_fdr\n",
    "import fpsample\n",
    "from dppy.finite_dpps import FiniteDPP\n",
    "\n",
    "from si4pipeline import ( \n",
    "                        construct_pipelines, \n",
    "                        extract_features, \n",
    "                        initialize_dataset, \n",
    "                        intersection, \n",
    "                        lasso, \n",
    "                        marginal_screening, \n",
    "                        stepwise_feature_selection, \n",
    "                        union, \n",
    "                        PipelineManager\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75060204-e43c-49bc-9209-d1c44c357e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.00390625\n",
      "0.0 0.00390625\n",
      "0.0 0.00390625\n",
      "7.962146857613305e-10 0.00390625\n",
      "0.02665034854633123 0.00390625\n"
     ]
    }
   ],
   "source": [
    "n_samples = 250*(last_bc+1)\n",
    "# max_fdr = 0.2; false_discovery_control_method = 'by'\n",
    "max_fdr = 0.2; false_discovery_control_method = 'bh'\n",
    "# max_fdr = 0.2; false_discovery_control_method =  None\n",
    "for bs in best_subsets:\n",
    "    fdrs = []\n",
    "    for _ in range(len(y_pre)//n_samples):\n",
    "        X_test = X_pre_top[:, bs]\n",
    "        y_test = y_pre.ravel()\n",
    "        \n",
    "        np.random.seed(random.randint(0, 100))\n",
    "        # sample_indices = sorted(set([np.random.randint(len(y_pre)) for _ in range(n_samples)]))\n",
    "        sample_indices = fpsample.bucket_fps_kdline_sampling(X_test, n_samples=n_samples, h=3) # Farthest Point Sampling (FPS) is better!!!\n",
    "        X_test = X_test[sample_indices]; y_test = y_test[sample_indices]\n",
    "        # FPS + k-DPP\n",
    "        # DPP = FiniteDPP('likelihood', **{'L': X_test.dot(X_test.T)})\n",
    "        # DPP.flush_samples()\n",
    "        # for _ in range(n_samples//(len(bs))):\n",
    "        #     DPP.sample_exact_k_dpp(size=len(bs))\n",
    "        # sample_indices = np.unique(np.ravel(DPP.list_of_samples))\n",
    "        # X_test = X_test[sample_indices]; y_test = y_test[sample_indices]\n",
    "        \n",
    "        manager = stepwise_selective_inference(support_size=X_test.shape[1])\n",
    "        M, p_list = manager.inference(X_test, y_test, np.std(y_test))\n",
    "        if false_discovery_control_method is not None:\n",
    "            p_list = stats.false_discovery_control(p_list, method=false_discovery_control_method)\n",
    "        # print(M, p_list, np.array(p_list) < 0.05)\n",
    "        fdrs.append(subset_fdr(p_list))\n",
    "        \n",
    "    fdrs = np.array(fdrs)\n",
    "    print(fdrs.mean(), stats.wilcoxon(fdrs-max_fdr, alternative='less').pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bbbc74-9744-4a91-92ec-08096e392e40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d42f15-f11f-404e-b90e-c79a6121c4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sindy]",
   "language": "python",
   "name": "conda-env-sindy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
